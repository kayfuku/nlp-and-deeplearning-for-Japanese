{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[-3.14159265]\n",
      " [-3.01336438]\n",
      " [-2.88513611]\n",
      " [-2.75690784]\n",
      " [-2.62867957]\n",
      " [-2.5004513 ]\n",
      " [-2.37222302]\n",
      " [-2.24399475]\n",
      " [-2.11576648]\n",
      " [-1.98753821]]\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "%matplotlib inline\n",
    "\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# reshape() allows to change the shape of array. -1 automatically determine the number of rows or columns. \n",
    "# linspace generates 50 elements by default. \n",
    "x = np.linspace(-np.pi, np.pi).reshape(-1, 1)  # -π to π\n",
    "t = np.cos(x)  \n",
    "\n",
    "print(x[:10])\n",
    "\n",
    "plt.plot(x, t)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /Users/kei/anaconda3/envs/nlp_bot/lib/python3.7/site-packages/keras/backend/tensorflow_backend.py:74: The name tf.get_default_graph is deprecated. Please use tf.compat.v1.get_default_graph instead.\n",
      "\n",
      "WARNING:tensorflow:From /Users/kei/anaconda3/envs/nlp_bot/lib/python3.7/site-packages/keras/backend/tensorflow_backend.py:517: The name tf.placeholder is deprecated. Please use tf.compat.v1.placeholder instead.\n",
      "\n",
      "WARNING:tensorflow:From /Users/kei/anaconda3/envs/nlp_bot/lib/python3.7/site-packages/keras/backend/tensorflow_backend.py:4138: The name tf.random_uniform is deprecated. Please use tf.random.uniform instead.\n",
      "\n",
      "WARNING:tensorflow:From /Users/kei/anaconda3/envs/nlp_bot/lib/python3.7/site-packages/keras/optimizers.py:790: The name tf.train.Optimizer is deprecated. Please use tf.compat.v1.train.Optimizer instead.\n",
      "\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_1 (Dense)              (None, 20)                40        \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 1)                 21        \n",
      "=================================================================\n",
      "Total params: 61\n",
      "Trainable params: 61\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "\n",
    "batch_size = 8  \n",
    "n_in = 1  # Num of neurons in input layer \n",
    "n_mid = 20  # Num of neurons in hidden layer\n",
    "n_out = 1  # Num of neurons in output layer\n",
    "\n",
    "# Create neural network that has input layer, hidden layer, and output layer.  \n",
    "model = Sequential()\n",
    "model.add(Dense(n_mid, input_shape=(n_in,), activation=\"sigmoid\")) \n",
    "model.add(Dense(n_out, activation=\"linear\"))  \n",
    "model.compile(loss=\"mean_squared_error\", optimizer=\"sgd\") \n",
    "print(model.summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /Users/kei/anaconda3/envs/nlp_bot/lib/python3.7/site-packages/keras/backend/tensorflow_backend.py:986: The name tf.assign_add is deprecated. Please use tf.compat.v1.assign_add instead.\n",
      "\n",
      "WARNING:tensorflow:From /Users/kei/anaconda3/envs/nlp_bot/lib/python3.7/site-packages/keras/backend/tensorflow_backend.py:973: The name tf.assign is deprecated. Please use tf.compat.v1.assign instead.\n",
      "\n",
      "WARNING:tensorflow:From /Users/kei/anaconda3/envs/nlp_bot/lib/python3.7/site-packages/keras/backend/tensorflow_backend.py:2741: The name tf.Session is deprecated. Please use tf.compat.v1.Session instead.\n",
      "\n",
      "Train on 45 samples, validate on 5 samples\n",
      "Epoch 1/2000\n",
      "WARNING:tensorflow:From /Users/kei/anaconda3/envs/nlp_bot/lib/python3.7/site-packages/keras/backend/tensorflow_backend.py:174: The name tf.get_default_session is deprecated. Please use tf.compat.v1.get_default_session instead.\n",
      "\n",
      "WARNING:tensorflow:From /Users/kei/anaconda3/envs/nlp_bot/lib/python3.7/site-packages/keras/backend/tensorflow_backend.py:181: The name tf.ConfigProto is deprecated. Please use tf.compat.v1.ConfigProto instead.\n",
      "\n",
      "WARNING:tensorflow:From /Users/kei/anaconda3/envs/nlp_bot/lib/python3.7/site-packages/keras/backend/tensorflow_backend.py:190: The name tf.global_variables is deprecated. Please use tf.compat.v1.global_variables instead.\n",
      "\n",
      "WARNING:tensorflow:From /Users/kei/anaconda3/envs/nlp_bot/lib/python3.7/site-packages/keras/backend/tensorflow_backend.py:199: The name tf.is_variable_initialized is deprecated. Please use tf.compat.v1.is_variable_initialized instead.\n",
      "\n",
      "WARNING:tensorflow:From /Users/kei/anaconda3/envs/nlp_bot/lib/python3.7/site-packages/keras/backend/tensorflow_backend.py:206: The name tf.variables_initializer is deprecated. Please use tf.compat.v1.variables_initializer instead.\n",
      "\n",
      "45/45 [==============================] - 1s 12ms/step - loss: 0.9267 - val_loss: 0.2514\n",
      "Epoch 2/2000\n",
      "45/45 [==============================] - 0s 209us/step - loss: 0.5958 - val_loss: 0.5312\n",
      "Epoch 3/2000\n",
      "45/45 [==============================] - 0s 180us/step - loss: 0.5062 - val_loss: 0.7573\n",
      "Epoch 4/2000\n",
      "45/45 [==============================] - 0s 170us/step - loss: 0.4836 - val_loss: 0.8932\n",
      "Epoch 5/2000\n",
      "45/45 [==============================] - 0s 195us/step - loss: 0.4713 - val_loss: 0.9877\n",
      "Epoch 6/2000\n",
      "45/45 [==============================] - 0s 217us/step - loss: 0.4644 - val_loss: 1.0782\n",
      "Epoch 7/2000\n",
      "45/45 [==============================] - 0s 234us/step - loss: 0.4568 - val_loss: 1.0966\n",
      "Epoch 8/2000\n",
      "45/45 [==============================] - 0s 203us/step - loss: 0.4524 - val_loss: 1.1706\n",
      "Epoch 9/2000\n",
      "45/45 [==============================] - 0s 210us/step - loss: 0.4482 - val_loss: 1.2620\n",
      "Epoch 10/2000\n",
      "45/45 [==============================] - 0s 216us/step - loss: 0.4482 - val_loss: 1.2739\n",
      "Epoch 11/2000\n",
      "45/45 [==============================] - 0s 229us/step - loss: 0.4415 - val_loss: 1.3168\n",
      "Epoch 12/2000\n",
      "45/45 [==============================] - 0s 222us/step - loss: 0.4436 - val_loss: 1.3180\n",
      "Epoch 13/2000\n",
      "45/45 [==============================] - 0s 213us/step - loss: 0.4376 - val_loss: 1.3514\n",
      "Epoch 14/2000\n",
      "45/45 [==============================] - 0s 206us/step - loss: 0.4406 - val_loss: 1.3593\n",
      "Epoch 15/2000\n",
      "45/45 [==============================] - 0s 239us/step - loss: 0.4379 - val_loss: 1.4183\n",
      "Epoch 16/2000\n",
      "45/45 [==============================] - 0s 204us/step - loss: 0.4396 - val_loss: 1.3504\n",
      "Epoch 17/2000\n",
      "45/45 [==============================] - 0s 193us/step - loss: 0.4345 - val_loss: 1.4840\n",
      "Epoch 18/2000\n",
      "45/45 [==============================] - 0s 260us/step - loss: 0.4345 - val_loss: 1.4700\n",
      "Epoch 19/2000\n",
      "45/45 [==============================] - 0s 211us/step - loss: 0.4369 - val_loss: 1.4240\n",
      "Epoch 20/2000\n",
      "45/45 [==============================] - 0s 232us/step - loss: 0.4312 - val_loss: 1.4840\n",
      "Epoch 21/2000\n",
      "45/45 [==============================] - 0s 236us/step - loss: 0.4311 - val_loss: 1.5817\n",
      "Epoch 22/2000\n",
      "45/45 [==============================] - 0s 235us/step - loss: 0.4311 - val_loss: 1.6251\n",
      "Epoch 23/2000\n",
      "45/45 [==============================] - 0s 218us/step - loss: 0.4319 - val_loss: 1.6489\n",
      "Epoch 24/2000\n",
      "45/45 [==============================] - 0s 256us/step - loss: 0.4317 - val_loss: 1.6608\n",
      "Epoch 25/2000\n",
      "45/45 [==============================] - 0s 232us/step - loss: 0.4288 - val_loss: 1.6665\n",
      "Epoch 26/2000\n",
      "45/45 [==============================] - 0s 226us/step - loss: 0.4289 - val_loss: 1.7263\n",
      "Epoch 27/2000\n",
      "45/45 [==============================] - 0s 273us/step - loss: 0.4318 - val_loss: 1.6256\n",
      "Epoch 28/2000\n",
      "45/45 [==============================] - 0s 250us/step - loss: 0.4305 - val_loss: 1.5249\n",
      "Epoch 29/2000\n",
      "45/45 [==============================] - 0s 238us/step - loss: 0.4363 - val_loss: 1.5329\n",
      "Epoch 30/2000\n",
      "45/45 [==============================] - 0s 276us/step - loss: 0.4304 - val_loss: 1.6210\n",
      "Epoch 31/2000\n",
      "45/45 [==============================] - 0s 247us/step - loss: 0.4331 - val_loss: 1.6706\n",
      "Epoch 32/2000\n",
      "45/45 [==============================] - 0s 305us/step - loss: 0.4273 - val_loss: 1.7330\n",
      "Epoch 33/2000\n",
      "45/45 [==============================] - 0s 273us/step - loss: 0.4241 - val_loss: 1.6930\n",
      "Epoch 34/2000\n",
      "45/45 [==============================] - 0s 287us/step - loss: 0.4303 - val_loss: 1.6051\n",
      "Epoch 35/2000\n",
      "45/45 [==============================] - 0s 300us/step - loss: 0.4325 - val_loss: 1.7350\n",
      "Epoch 36/2000\n",
      "45/45 [==============================] - 0s 293us/step - loss: 0.4259 - val_loss: 1.8083\n",
      "Epoch 37/2000\n",
      "45/45 [==============================] - 0s 311us/step - loss: 0.4233 - val_loss: 1.7676\n",
      "Epoch 38/2000\n",
      "45/45 [==============================] - 0s 285us/step - loss: 0.4259 - val_loss: 1.8239\n",
      "Epoch 39/2000\n",
      "45/45 [==============================] - 0s 313us/step - loss: 0.4272 - val_loss: 1.7857\n",
      "Epoch 40/2000\n",
      "45/45 [==============================] - 0s 286us/step - loss: 0.4287 - val_loss: 1.7081\n",
      "Epoch 41/2000\n",
      "45/45 [==============================] - 0s 310us/step - loss: 0.4269 - val_loss: 1.7741\n",
      "Epoch 42/2000\n",
      "45/45 [==============================] - 0s 310us/step - loss: 0.4293 - val_loss: 1.7468\n",
      "Epoch 43/2000\n",
      "45/45 [==============================] - 0s 296us/step - loss: 0.4240 - val_loss: 1.7434\n",
      "Epoch 44/2000\n",
      "45/45 [==============================] - 0s 300us/step - loss: 0.4256 - val_loss: 1.8291\n",
      "Epoch 45/2000\n",
      "45/45 [==============================] - 0s 326us/step - loss: 0.4280 - val_loss: 1.8557\n",
      "Epoch 46/2000\n",
      "45/45 [==============================] - 0s 268us/step - loss: 0.4234 - val_loss: 1.7640\n",
      "Epoch 47/2000\n",
      "45/45 [==============================] - 0s 259us/step - loss: 0.4252 - val_loss: 1.8073\n",
      "Epoch 48/2000\n",
      "45/45 [==============================] - 0s 306us/step - loss: 0.4260 - val_loss: 1.8324\n",
      "Epoch 49/2000\n",
      "45/45 [==============================] - 0s 262us/step - loss: 0.4231 - val_loss: 1.6924\n",
      "Epoch 50/2000\n",
      "45/45 [==============================] - 0s 274us/step - loss: 0.4333 - val_loss: 1.7550\n",
      "Epoch 51/2000\n",
      "45/45 [==============================] - 0s 288us/step - loss: 0.4245 - val_loss: 1.7975\n",
      "Epoch 52/2000\n",
      "45/45 [==============================] - 0s 289us/step - loss: 0.4292 - val_loss: 1.6785\n",
      "Epoch 53/2000\n",
      "45/45 [==============================] - 0s 273us/step - loss: 0.4382 - val_loss: 1.7234\n",
      "Epoch 54/2000\n",
      "45/45 [==============================] - 0s 262us/step - loss: 0.4266 - val_loss: 1.8128\n",
      "Epoch 55/2000\n",
      "45/45 [==============================] - 0s 286us/step - loss: 0.4208 - val_loss: 1.8012\n",
      "Epoch 56/2000\n",
      "45/45 [==============================] - 0s 272us/step - loss: 0.4228 - val_loss: 1.8411\n",
      "Epoch 57/2000\n",
      "45/45 [==============================] - 0s 228us/step - loss: 0.4255 - val_loss: 1.9414\n",
      "Epoch 58/2000\n",
      "45/45 [==============================] - 0s 247us/step - loss: 0.4305 - val_loss: 1.8718\n",
      "Epoch 59/2000\n",
      "45/45 [==============================] - 0s 219us/step - loss: 0.4358 - val_loss: 1.9339\n",
      "Epoch 60/2000\n",
      "45/45 [==============================] - 0s 241us/step - loss: 0.4251 - val_loss: 1.9116\n",
      "Epoch 61/2000\n",
      "45/45 [==============================] - 0s 226us/step - loss: 0.4220 - val_loss: 1.8252\n",
      "Epoch 62/2000\n",
      "45/45 [==============================] - 0s 216us/step - loss: 0.4254 - val_loss: 1.8784\n",
      "Epoch 63/2000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "45/45 [==============================] - 0s 236us/step - loss: 0.4224 - val_loss: 1.8686\n",
      "Epoch 64/2000\n",
      "45/45 [==============================] - 0s 223us/step - loss: 0.4240 - val_loss: 1.9237\n",
      "Epoch 65/2000\n",
      "45/45 [==============================] - 0s 225us/step - loss: 0.4207 - val_loss: 1.8776\n",
      "Epoch 66/2000\n",
      "45/45 [==============================] - 0s 215us/step - loss: 0.4206 - val_loss: 1.8210\n",
      "Epoch 67/2000\n",
      "45/45 [==============================] - 0s 219us/step - loss: 0.4219 - val_loss: 1.9044\n",
      "Epoch 68/2000\n",
      "45/45 [==============================] - 0s 188us/step - loss: 0.4238 - val_loss: 1.9231\n",
      "Epoch 69/2000\n",
      "45/45 [==============================] - 0s 199us/step - loss: 0.4288 - val_loss: 1.7418\n",
      "Epoch 70/2000\n",
      "45/45 [==============================] - 0s 182us/step - loss: 0.4267 - val_loss: 1.7896\n",
      "Epoch 71/2000\n",
      "45/45 [==============================] - 0s 192us/step - loss: 0.4249 - val_loss: 1.8467\n",
      "Epoch 72/2000\n",
      "45/45 [==============================] - 0s 183us/step - loss: 0.4227 - val_loss: 1.8718\n",
      "Epoch 73/2000\n",
      "45/45 [==============================] - 0s 179us/step - loss: 0.4273 - val_loss: 1.8380\n",
      "Epoch 74/2000\n",
      "45/45 [==============================] - 0s 171us/step - loss: 0.4201 - val_loss: 1.8264\n",
      "Epoch 75/2000\n",
      "45/45 [==============================] - 0s 170us/step - loss: 0.4237 - val_loss: 1.8285\n",
      "Epoch 76/2000\n",
      "45/45 [==============================] - 0s 170us/step - loss: 0.4234 - val_loss: 1.8132\n",
      "Epoch 77/2000\n",
      "45/45 [==============================] - 0s 174us/step - loss: 0.4191 - val_loss: 1.8794\n",
      "Epoch 78/2000\n",
      "45/45 [==============================] - 0s 177us/step - loss: 0.4210 - val_loss: 1.8473\n",
      "Epoch 79/2000\n",
      "45/45 [==============================] - 0s 160us/step - loss: 0.4205 - val_loss: 1.8790\n",
      "Epoch 80/2000\n",
      "45/45 [==============================] - 0s 169us/step - loss: 0.4199 - val_loss: 1.8663\n",
      "Epoch 81/2000\n",
      "45/45 [==============================] - 0s 160us/step - loss: 0.4220 - val_loss: 1.8792\n",
      "Epoch 82/2000\n",
      "45/45 [==============================] - 0s 164us/step - loss: 0.4198 - val_loss: 1.8962\n",
      "Epoch 83/2000\n",
      "45/45 [==============================] - 0s 169us/step - loss: 0.4214 - val_loss: 1.8447\n",
      "Epoch 84/2000\n",
      "45/45 [==============================] - 0s 162us/step - loss: 0.4202 - val_loss: 1.7828\n",
      "Epoch 85/2000\n",
      "45/45 [==============================] - 0s 169us/step - loss: 0.4208 - val_loss: 1.8179\n",
      "Epoch 86/2000\n",
      "45/45 [==============================] - 0s 159us/step - loss: 0.4230 - val_loss: 1.7841\n",
      "Epoch 87/2000\n",
      "45/45 [==============================] - 0s 174us/step - loss: 0.4268 - val_loss: 1.7855\n",
      "Epoch 88/2000\n",
      "45/45 [==============================] - 0s 155us/step - loss: 0.4257 - val_loss: 1.7704\n",
      "Epoch 89/2000\n",
      "45/45 [==============================] - 0s 170us/step - loss: 0.4197 - val_loss: 1.7640\n",
      "Epoch 90/2000\n",
      "45/45 [==============================] - 0s 155us/step - loss: 0.4194 - val_loss: 1.8298\n",
      "Epoch 91/2000\n",
      "45/45 [==============================] - 0s 180us/step - loss: 0.4240 - val_loss: 1.8765\n",
      "Epoch 92/2000\n",
      "45/45 [==============================] - 0s 165us/step - loss: 0.4302 - val_loss: 1.7675\n",
      "Epoch 93/2000\n",
      "45/45 [==============================] - 0s 179us/step - loss: 0.4190 - val_loss: 1.8152\n",
      "Epoch 94/2000\n",
      "45/45 [==============================] - 0s 152us/step - loss: 0.4211 - val_loss: 1.8332\n",
      "Epoch 95/2000\n",
      "45/45 [==============================] - 0s 179us/step - loss: 0.4205 - val_loss: 1.8599\n",
      "Epoch 96/2000\n",
      "45/45 [==============================] - 0s 162us/step - loss: 0.4199 - val_loss: 1.8759\n",
      "Epoch 97/2000\n",
      "45/45 [==============================] - 0s 165us/step - loss: 0.4233 - val_loss: 1.8375\n",
      "Epoch 98/2000\n",
      "45/45 [==============================] - 0s 153us/step - loss: 0.4254 - val_loss: 1.7882\n",
      "Epoch 99/2000\n",
      "45/45 [==============================] - 0s 171us/step - loss: 0.4208 - val_loss: 1.7795\n",
      "Epoch 100/2000\n",
      "45/45 [==============================] - 0s 155us/step - loss: 0.4196 - val_loss: 1.8958\n",
      "Epoch 101/2000\n",
      "45/45 [==============================] - 0s 164us/step - loss: 0.4178 - val_loss: 1.8246\n",
      "Epoch 102/2000\n",
      "45/45 [==============================] - 0s 163us/step - loss: 0.4239 - val_loss: 1.9210\n",
      "Epoch 103/2000\n",
      "45/45 [==============================] - 0s 159us/step - loss: 0.4186 - val_loss: 1.8674\n",
      "Epoch 104/2000\n",
      "45/45 [==============================] - 0s 161us/step - loss: 0.4220 - val_loss: 1.9642\n",
      "Epoch 105/2000\n",
      "45/45 [==============================] - 0s 165us/step - loss: 0.4226 - val_loss: 1.8002\n",
      "Epoch 106/2000\n",
      "45/45 [==============================] - 0s 169us/step - loss: 0.4187 - val_loss: 1.8485\n",
      "Epoch 107/2000\n",
      "45/45 [==============================] - 0s 169us/step - loss: 0.4245 - val_loss: 1.9675\n",
      "Epoch 108/2000\n",
      "45/45 [==============================] - 0s 164us/step - loss: 0.4301 - val_loss: 1.9959\n",
      "Epoch 109/2000\n",
      "45/45 [==============================] - 0s 169us/step - loss: 0.4229 - val_loss: 2.0311\n",
      "Epoch 110/2000\n",
      "45/45 [==============================] - 0s 169us/step - loss: 0.4193 - val_loss: 1.8051\n",
      "Epoch 111/2000\n",
      "45/45 [==============================] - 0s 173us/step - loss: 0.4236 - val_loss: 1.8033\n",
      "Epoch 112/2000\n",
      "45/45 [==============================] - 0s 164us/step - loss: 0.4197 - val_loss: 1.8596\n",
      "Epoch 113/2000\n",
      "45/45 [==============================] - 0s 174us/step - loss: 0.4170 - val_loss: 1.8249\n",
      "Epoch 114/2000\n",
      "45/45 [==============================] - 0s 170us/step - loss: 0.4188 - val_loss: 1.7233\n",
      "Epoch 115/2000\n",
      "45/45 [==============================] - 0s 165us/step - loss: 0.4214 - val_loss: 1.7718\n",
      "Epoch 116/2000\n",
      "45/45 [==============================] - 0s 162us/step - loss: 0.4272 - val_loss: 1.7837\n",
      "Epoch 117/2000\n",
      "45/45 [==============================] - 0s 155us/step - loss: 0.4164 - val_loss: 1.8200\n",
      "Epoch 118/2000\n",
      "45/45 [==============================] - 0s 166us/step - loss: 0.4211 - val_loss: 1.9302\n",
      "Epoch 119/2000\n",
      "45/45 [==============================] - 0s 153us/step - loss: 0.4185 - val_loss: 1.8997\n",
      "Epoch 120/2000\n",
      "45/45 [==============================] - 0s 158us/step - loss: 0.4151 - val_loss: 1.8729\n",
      "Epoch 121/2000\n",
      "45/45 [==============================] - 0s 158us/step - loss: 0.4145 - val_loss: 1.8560\n",
      "Epoch 122/2000\n",
      "45/45 [==============================] - 0s 171us/step - loss: 0.4303 - val_loss: 1.8778\n",
      "Epoch 123/2000\n",
      "45/45 [==============================] - 0s 148us/step - loss: 0.4159 - val_loss: 1.8795\n",
      "Epoch 124/2000\n",
      "45/45 [==============================] - 0s 154us/step - loss: 0.4153 - val_loss: 1.9093\n",
      "Epoch 125/2000\n",
      "45/45 [==============================] - 0s 165us/step - loss: 0.4149 - val_loss: 1.8585\n",
      "Epoch 126/2000\n",
      "45/45 [==============================] - 0s 149us/step - loss: 0.4214 - val_loss: 1.9402\n",
      "Epoch 127/2000\n",
      "45/45 [==============================] - 0s 156us/step - loss: 0.4272 - val_loss: 1.9858\n",
      "Epoch 128/2000\n",
      "45/45 [==============================] - 0s 153us/step - loss: 0.4229 - val_loss: 1.8625\n",
      "Epoch 129/2000\n",
      "45/45 [==============================] - 0s 154us/step - loss: 0.4170 - val_loss: 1.8781\n",
      "Epoch 130/2000\n",
      "45/45 [==============================] - 0s 150us/step - loss: 0.4247 - val_loss: 1.7799\n",
      "Epoch 131/2000\n",
      "45/45 [==============================] - 0s 159us/step - loss: 0.4252 - val_loss: 1.9425\n",
      "Epoch 132/2000\n",
      "45/45 [==============================] - 0s 147us/step - loss: 0.4230 - val_loss: 1.9708\n",
      "Epoch 133/2000\n",
      "45/45 [==============================] - 0s 149us/step - loss: 0.4149 - val_loss: 1.8728\n",
      "Epoch 134/2000\n",
      "45/45 [==============================] - 0s 156us/step - loss: 0.4169 - val_loss: 1.9011\n",
      "Epoch 135/2000\n",
      "45/45 [==============================] - 0s 154us/step - loss: 0.4170 - val_loss: 1.8919\n",
      "Epoch 136/2000\n",
      "45/45 [==============================] - 0s 155us/step - loss: 0.4185 - val_loss: 1.8420\n",
      "Epoch 137/2000\n",
      "45/45 [==============================] - 0s 160us/step - loss: 0.4208 - val_loss: 1.9484\n",
      "Epoch 138/2000\n",
      "45/45 [==============================] - 0s 164us/step - loss: 0.4189 - val_loss: 1.9525\n",
      "Epoch 139/2000\n",
      "45/45 [==============================] - 0s 166us/step - loss: 0.4177 - val_loss: 1.9322\n",
      "Epoch 140/2000\n",
      "45/45 [==============================] - 0s 162us/step - loss: 0.4167 - val_loss: 1.9703\n",
      "Epoch 141/2000\n",
      "45/45 [==============================] - 0s 157us/step - loss: 0.4220 - val_loss: 2.0059\n",
      "Epoch 142/2000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "45/45 [==============================] - 0s 162us/step - loss: 0.4203 - val_loss: 1.9212\n",
      "Epoch 143/2000\n",
      "45/45 [==============================] - 0s 150us/step - loss: 0.4158 - val_loss: 1.9667\n",
      "Epoch 144/2000\n",
      "45/45 [==============================] - 0s 164us/step - loss: 0.4232 - val_loss: 1.8289\n",
      "Epoch 145/2000\n",
      "45/45 [==============================] - 0s 154us/step - loss: 0.4124 - val_loss: 1.9206\n",
      "Epoch 146/2000\n",
      "45/45 [==============================] - 0s 165us/step - loss: 0.4191 - val_loss: 1.8126\n",
      "Epoch 147/2000\n",
      "45/45 [==============================] - 0s 156us/step - loss: 0.4161 - val_loss: 1.8557\n",
      "Epoch 148/2000\n",
      "45/45 [==============================] - 0s 161us/step - loss: 0.4154 - val_loss: 1.8508\n",
      "Epoch 149/2000\n",
      "45/45 [==============================] - 0s 156us/step - loss: 0.4134 - val_loss: 1.8211\n",
      "Epoch 150/2000\n",
      "45/45 [==============================] - 0s 143us/step - loss: 0.4128 - val_loss: 1.8138\n",
      "Epoch 151/2000\n",
      "45/45 [==============================] - 0s 167us/step - loss: 0.4135 - val_loss: 1.8065\n",
      "Epoch 152/2000\n",
      "45/45 [==============================] - 0s 148us/step - loss: 0.4189 - val_loss: 1.8671\n",
      "Epoch 153/2000\n",
      "45/45 [==============================] - 0s 175us/step - loss: 0.4182 - val_loss: 1.8478\n",
      "Epoch 154/2000\n",
      "45/45 [==============================] - 0s 149us/step - loss: 0.4181 - val_loss: 1.8643\n",
      "Epoch 155/2000\n",
      "45/45 [==============================] - 0s 166us/step - loss: 0.4172 - val_loss: 1.8223\n",
      "Epoch 156/2000\n",
      "45/45 [==============================] - 0s 162us/step - loss: 0.4217 - val_loss: 1.9021\n",
      "Epoch 157/2000\n",
      "45/45 [==============================] - 0s 169us/step - loss: 0.4154 - val_loss: 1.8499\n",
      "Epoch 158/2000\n",
      "45/45 [==============================] - 0s 151us/step - loss: 0.4168 - val_loss: 1.8181\n",
      "Epoch 159/2000\n",
      "45/45 [==============================] - 0s 158us/step - loss: 0.4155 - val_loss: 1.8408\n",
      "Epoch 160/2000\n",
      "45/45 [==============================] - 0s 146us/step - loss: 0.4183 - val_loss: 1.7930\n",
      "Epoch 161/2000\n",
      "45/45 [==============================] - 0s 156us/step - loss: 0.4226 - val_loss: 1.6663\n",
      "Epoch 162/2000\n",
      "45/45 [==============================] - 0s 147us/step - loss: 0.4178 - val_loss: 1.7657\n",
      "Epoch 163/2000\n",
      "45/45 [==============================] - 0s 151us/step - loss: 0.4131 - val_loss: 1.8310\n",
      "Epoch 164/2000\n",
      "45/45 [==============================] - 0s 164us/step - loss: 0.4146 - val_loss: 1.7574\n",
      "Epoch 165/2000\n",
      "45/45 [==============================] - 0s 149us/step - loss: 0.4170 - val_loss: 1.7351\n",
      "Epoch 166/2000\n",
      "45/45 [==============================] - 0s 167us/step - loss: 0.4261 - val_loss: 1.7573\n",
      "Epoch 167/2000\n",
      "45/45 [==============================] - 0s 160us/step - loss: 0.4146 - val_loss: 1.7178\n",
      "Epoch 168/2000\n",
      "45/45 [==============================] - 0s 176us/step - loss: 0.4143 - val_loss: 1.7576\n",
      "Epoch 169/2000\n",
      "45/45 [==============================] - 0s 156us/step - loss: 0.4215 - val_loss: 1.7351\n",
      "Epoch 170/2000\n",
      "45/45 [==============================] - 0s 165us/step - loss: 0.4151 - val_loss: 1.8424\n",
      "Epoch 171/2000\n",
      "45/45 [==============================] - 0s 159us/step - loss: 0.4103 - val_loss: 1.7581\n",
      "Epoch 172/2000\n",
      "45/45 [==============================] - 0s 163us/step - loss: 0.4153 - val_loss: 1.7256\n",
      "Epoch 173/2000\n",
      "45/45 [==============================] - 0s 159us/step - loss: 0.4178 - val_loss: 1.7878\n",
      "Epoch 174/2000\n",
      "45/45 [==============================] - 0s 159us/step - loss: 0.4134 - val_loss: 1.7849\n",
      "Epoch 175/2000\n",
      "45/45 [==============================] - 0s 158us/step - loss: 0.4125 - val_loss: 1.7956\n",
      "Epoch 176/2000\n",
      "45/45 [==============================] - 0s 157us/step - loss: 0.4231 - val_loss: 1.8567\n",
      "Epoch 177/2000\n",
      "45/45 [==============================] - 0s 149us/step - loss: 0.4121 - val_loss: 1.9518\n",
      "Epoch 178/2000\n",
      "45/45 [==============================] - 0s 142us/step - loss: 0.4126 - val_loss: 1.9285\n",
      "Epoch 179/2000\n",
      "45/45 [==============================] - 0s 162us/step - loss: 0.4117 - val_loss: 1.7756\n",
      "Epoch 180/2000\n",
      "45/45 [==============================] - 0s 149us/step - loss: 0.4168 - val_loss: 1.8134\n",
      "Epoch 181/2000\n",
      "45/45 [==============================] - 0s 161us/step - loss: 0.4164 - val_loss: 1.9266\n",
      "Epoch 182/2000\n",
      "45/45 [==============================] - 0s 153us/step - loss: 0.4164 - val_loss: 1.8164\n",
      "Epoch 183/2000\n",
      "45/45 [==============================] - 0s 163us/step - loss: 0.4109 - val_loss: 1.8120\n",
      "Epoch 184/2000\n",
      "45/45 [==============================] - 0s 162us/step - loss: 0.4136 - val_loss: 1.7275\n",
      "Epoch 185/2000\n",
      "45/45 [==============================] - 0s 168us/step - loss: 0.4150 - val_loss: 1.7286\n",
      "Epoch 186/2000\n",
      "45/45 [==============================] - 0s 163us/step - loss: 0.4180 - val_loss: 1.6805\n",
      "Epoch 187/2000\n",
      "45/45 [==============================] - 0s 155us/step - loss: 0.4144 - val_loss: 1.7768\n",
      "Epoch 188/2000\n",
      "45/45 [==============================] - 0s 144us/step - loss: 0.4098 - val_loss: 1.7972\n",
      "Epoch 189/2000\n",
      "45/45 [==============================] - 0s 146us/step - loss: 0.4137 - val_loss: 1.8874\n",
      "Epoch 190/2000\n",
      "45/45 [==============================] - 0s 163us/step - loss: 0.4197 - val_loss: 1.8702\n",
      "Epoch 191/2000\n",
      "45/45 [==============================] - 0s 152us/step - loss: 0.4116 - val_loss: 1.8172\n",
      "Epoch 192/2000\n",
      "45/45 [==============================] - 0s 175us/step - loss: 0.4080 - val_loss: 1.7859\n",
      "Epoch 193/2000\n",
      "45/45 [==============================] - 0s 157us/step - loss: 0.4120 - val_loss: 1.8183\n",
      "Epoch 194/2000\n",
      "45/45 [==============================] - 0s 167us/step - loss: 0.4134 - val_loss: 1.7816\n",
      "Epoch 195/2000\n",
      "45/45 [==============================] - 0s 157us/step - loss: 0.4160 - val_loss: 1.8159\n",
      "Epoch 196/2000\n",
      "45/45 [==============================] - 0s 171us/step - loss: 0.4125 - val_loss: 1.7754\n",
      "Epoch 197/2000\n",
      "45/45 [==============================] - 0s 154us/step - loss: 0.4101 - val_loss: 1.7616\n",
      "Epoch 198/2000\n",
      "45/45 [==============================] - 0s 167us/step - loss: 0.4086 - val_loss: 1.7428\n",
      "Epoch 199/2000\n",
      "45/45 [==============================] - 0s 161us/step - loss: 0.4149 - val_loss: 1.6846\n",
      "Epoch 200/2000\n",
      "45/45 [==============================] - 0s 167us/step - loss: 0.4190 - val_loss: 1.7723\n",
      "Epoch 201/2000\n",
      "45/45 [==============================] - 0s 157us/step - loss: 0.4114 - val_loss: 1.8152\n",
      "Epoch 202/2000\n",
      "45/45 [==============================] - 0s 161us/step - loss: 0.4097 - val_loss: 1.8026\n",
      "Epoch 203/2000\n",
      "45/45 [==============================] - 0s 154us/step - loss: 0.4114 - val_loss: 1.8304\n",
      "Epoch 204/2000\n",
      "45/45 [==============================] - 0s 157us/step - loss: 0.4111 - val_loss: 1.7967\n",
      "Epoch 205/2000\n",
      "45/45 [==============================] - 0s 152us/step - loss: 0.4078 - val_loss: 1.8324\n",
      "Epoch 206/2000\n",
      "45/45 [==============================] - 0s 151us/step - loss: 0.4076 - val_loss: 1.8615\n",
      "Epoch 207/2000\n",
      "45/45 [==============================] - 0s 157us/step - loss: 0.4106 - val_loss: 1.7967\n",
      "Epoch 208/2000\n",
      "45/45 [==============================] - 0s 151us/step - loss: 0.4085 - val_loss: 1.8719\n",
      "Epoch 209/2000\n",
      "45/45 [==============================] - 0s 160us/step - loss: 0.4078 - val_loss: 1.8212\n",
      "Epoch 210/2000\n",
      "45/45 [==============================] - 0s 149us/step - loss: 0.4089 - val_loss: 1.8374\n",
      "Epoch 211/2000\n",
      "45/45 [==============================] - 0s 158us/step - loss: 0.4095 - val_loss: 1.7308\n",
      "Epoch 212/2000\n",
      "45/45 [==============================] - 0s 155us/step - loss: 0.4061 - val_loss: 1.7255\n",
      "Epoch 213/2000\n",
      "45/45 [==============================] - 0s 154us/step - loss: 0.4050 - val_loss: 1.7944\n",
      "Epoch 214/2000\n",
      "45/45 [==============================] - 0s 154us/step - loss: 0.4078 - val_loss: 1.8957\n",
      "Epoch 215/2000\n",
      "45/45 [==============================] - 0s 148us/step - loss: 0.4160 - val_loss: 1.8589\n",
      "Epoch 216/2000\n",
      "45/45 [==============================] - 0s 161us/step - loss: 0.4143 - val_loss: 1.8613\n",
      "Epoch 217/2000\n",
      "45/45 [==============================] - 0s 143us/step - loss: 0.4073 - val_loss: 1.7666\n",
      "Epoch 218/2000\n",
      "45/45 [==============================] - 0s 165us/step - loss: 0.4107 - val_loss: 1.8047\n",
      "Epoch 219/2000\n",
      "45/45 [==============================] - 0s 143us/step - loss: 0.4059 - val_loss: 1.9049\n",
      "Epoch 220/2000\n",
      "45/45 [==============================] - 0s 173us/step - loss: 0.4185 - val_loss: 1.8467\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 221/2000\n",
      "45/45 [==============================] - 0s 157us/step - loss: 0.4176 - val_loss: 1.7009\n",
      "Epoch 222/2000\n",
      "45/45 [==============================] - 0s 161us/step - loss: 0.4105 - val_loss: 1.7155\n",
      "Epoch 223/2000\n",
      "45/45 [==============================] - 0s 149us/step - loss: 0.4100 - val_loss: 1.7432\n",
      "Epoch 224/2000\n",
      "45/45 [==============================] - 0s 166us/step - loss: 0.4101 - val_loss: 1.8305\n",
      "Epoch 225/2000\n",
      "45/45 [==============================] - 0s 150us/step - loss: 0.4062 - val_loss: 1.8923\n",
      "Epoch 226/2000\n",
      "45/45 [==============================] - 0s 167us/step - loss: 0.4061 - val_loss: 1.7977\n",
      "Epoch 227/2000\n",
      "45/45 [==============================] - 0s 150us/step - loss: 0.4159 - val_loss: 1.7213\n",
      "Epoch 228/2000\n",
      "45/45 [==============================] - 0s 152us/step - loss: 0.4044 - val_loss: 1.7463\n",
      "Epoch 229/2000\n",
      "45/45 [==============================] - 0s 156us/step - loss: 0.4083 - val_loss: 1.7959\n",
      "Epoch 230/2000\n",
      "45/45 [==============================] - 0s 155us/step - loss: 0.4062 - val_loss: 1.8254\n",
      "Epoch 231/2000\n",
      "45/45 [==============================] - 0s 165us/step - loss: 0.4074 - val_loss: 1.7973\n",
      "Epoch 232/2000\n",
      "45/45 [==============================] - 0s 146us/step - loss: 0.4084 - val_loss: 1.7401\n",
      "Epoch 233/2000\n",
      "45/45 [==============================] - 0s 165us/step - loss: 0.4047 - val_loss: 1.7718\n",
      "Epoch 234/2000\n",
      "45/45 [==============================] - 0s 158us/step - loss: 0.4026 - val_loss: 1.7224\n",
      "Epoch 235/2000\n",
      "45/45 [==============================] - 0s 169us/step - loss: 0.4140 - val_loss: 1.8078\n",
      "Epoch 236/2000\n",
      "45/45 [==============================] - 0s 171us/step - loss: 0.4049 - val_loss: 1.8375\n",
      "Epoch 237/2000\n",
      "45/45 [==============================] - 0s 184us/step - loss: 0.4144 - val_loss: 1.7397\n",
      "Epoch 238/2000\n",
      "45/45 [==============================] - 0s 160us/step - loss: 0.4074 - val_loss: 1.7334\n",
      "Epoch 239/2000\n",
      "45/45 [==============================] - 0s 174us/step - loss: 0.4101 - val_loss: 1.7796\n",
      "Epoch 240/2000\n",
      "45/45 [==============================] - 0s 161us/step - loss: 0.4041 - val_loss: 1.7565\n",
      "Epoch 241/2000\n",
      "45/45 [==============================] - 0s 171us/step - loss: 0.4011 - val_loss: 1.8107\n",
      "Epoch 242/2000\n",
      "45/45 [==============================] - 0s 153us/step - loss: 0.4060 - val_loss: 1.8529\n",
      "Epoch 243/2000\n",
      "45/45 [==============================] - 0s 167us/step - loss: 0.4050 - val_loss: 1.8124\n",
      "Epoch 244/2000\n",
      "45/45 [==============================] - 0s 160us/step - loss: 0.4041 - val_loss: 1.8335\n",
      "Epoch 245/2000\n",
      "45/45 [==============================] - 0s 168us/step - loss: 0.4099 - val_loss: 1.7171\n",
      "Epoch 246/2000\n",
      "45/45 [==============================] - 0s 158us/step - loss: 0.4009 - val_loss: 1.7796\n",
      "Epoch 247/2000\n",
      "45/45 [==============================] - 0s 170us/step - loss: 0.4002 - val_loss: 1.7818\n",
      "Epoch 248/2000\n",
      "45/45 [==============================] - 0s 156us/step - loss: 0.4013 - val_loss: 1.8369\n",
      "Epoch 249/2000\n",
      "45/45 [==============================] - 0s 178us/step - loss: 0.4016 - val_loss: 1.7297\n",
      "Epoch 250/2000\n",
      "45/45 [==============================] - 0s 165us/step - loss: 0.4027 - val_loss: 1.8726\n",
      "Epoch 251/2000\n",
      "45/45 [==============================] - 0s 166us/step - loss: 0.4041 - val_loss: 1.8493\n",
      "Epoch 252/2000\n",
      "45/45 [==============================] - 0s 158us/step - loss: 0.3993 - val_loss: 1.8277\n",
      "Epoch 253/2000\n",
      "45/45 [==============================] - 0s 152us/step - loss: 0.4073 - val_loss: 1.8962\n",
      "Epoch 254/2000\n",
      "45/45 [==============================] - 0s 173us/step - loss: 0.4002 - val_loss: 1.8717\n",
      "Epoch 255/2000\n",
      "45/45 [==============================] - 0s 151us/step - loss: 0.4069 - val_loss: 1.8664\n",
      "Epoch 256/2000\n",
      "45/45 [==============================] - 0s 163us/step - loss: 0.4056 - val_loss: 1.9988\n",
      "Epoch 257/2000\n",
      "45/45 [==============================] - 0s 151us/step - loss: 0.4101 - val_loss: 1.9150\n",
      "Epoch 258/2000\n",
      "45/45 [==============================] - 0s 162us/step - loss: 0.4021 - val_loss: 1.8050\n",
      "Epoch 259/2000\n",
      "45/45 [==============================] - 0s 146us/step - loss: 0.4001 - val_loss: 1.8220\n",
      "Epoch 260/2000\n",
      "45/45 [==============================] - 0s 167us/step - loss: 0.4002 - val_loss: 1.8562\n",
      "Epoch 261/2000\n",
      "45/45 [==============================] - 0s 161us/step - loss: 0.4036 - val_loss: 1.7626\n",
      "Epoch 262/2000\n",
      "45/45 [==============================] - 0s 174us/step - loss: 0.4042 - val_loss: 1.6899\n",
      "Epoch 263/2000\n",
      "45/45 [==============================] - 0s 161us/step - loss: 0.4021 - val_loss: 1.7447\n",
      "Epoch 264/2000\n",
      "45/45 [==============================] - 0s 176us/step - loss: 0.4042 - val_loss: 1.7878\n",
      "Epoch 265/2000\n",
      "45/45 [==============================] - 0s 168us/step - loss: 0.4002 - val_loss: 1.7800\n",
      "Epoch 266/2000\n",
      "45/45 [==============================] - 0s 170us/step - loss: 0.3985 - val_loss: 1.7747\n",
      "Epoch 267/2000\n",
      "45/45 [==============================] - 0s 166us/step - loss: 0.4002 - val_loss: 1.7574\n",
      "Epoch 268/2000\n",
      "45/45 [==============================] - 0s 178us/step - loss: 0.4049 - val_loss: 1.6687\n",
      "Epoch 269/2000\n",
      "45/45 [==============================] - 0s 169us/step - loss: 0.4046 - val_loss: 1.6980\n",
      "Epoch 270/2000\n",
      "45/45 [==============================] - 0s 165us/step - loss: 0.4012 - val_loss: 1.8161\n",
      "Epoch 271/2000\n",
      "45/45 [==============================] - 0s 155us/step - loss: 0.3999 - val_loss: 1.7545\n",
      "Epoch 272/2000\n",
      "45/45 [==============================] - 0s 161us/step - loss: 0.4009 - val_loss: 1.6627\n",
      "Epoch 273/2000\n",
      "45/45 [==============================] - 0s 167us/step - loss: 0.4029 - val_loss: 1.6410\n",
      "Epoch 274/2000\n",
      "45/45 [==============================] - 0s 164us/step - loss: 0.4128 - val_loss: 1.7435\n",
      "Epoch 275/2000\n",
      "45/45 [==============================] - 0s 160us/step - loss: 0.4010 - val_loss: 1.6957\n",
      "Epoch 276/2000\n",
      "45/45 [==============================] - 0s 146us/step - loss: 0.4024 - val_loss: 1.6325\n",
      "Epoch 277/2000\n",
      "45/45 [==============================] - 0s 161us/step - loss: 0.4019 - val_loss: 1.7071\n",
      "Epoch 278/2000\n",
      "45/45 [==============================] - 0s 156us/step - loss: 0.3951 - val_loss: 1.6935\n",
      "Epoch 279/2000\n",
      "45/45 [==============================] - 0s 185us/step - loss: 0.4088 - val_loss: 1.6965\n",
      "Epoch 280/2000\n",
      "45/45 [==============================] - 0s 163us/step - loss: 0.3962 - val_loss: 1.7316\n",
      "Epoch 281/2000\n",
      "45/45 [==============================] - 0s 166us/step - loss: 0.3939 - val_loss: 1.7282\n",
      "Epoch 282/2000\n",
      "45/45 [==============================] - 0s 151us/step - loss: 0.3975 - val_loss: 1.7331\n",
      "Epoch 283/2000\n",
      "45/45 [==============================] - 0s 171us/step - loss: 0.3957 - val_loss: 1.8809\n",
      "Epoch 284/2000\n",
      "45/45 [==============================] - 0s 143us/step - loss: 0.3965 - val_loss: 1.8584\n",
      "Epoch 285/2000\n",
      "45/45 [==============================] - 0s 172us/step - loss: 0.3972 - val_loss: 1.7036\n",
      "Epoch 286/2000\n",
      "45/45 [==============================] - 0s 149us/step - loss: 0.3944 - val_loss: 1.7817\n",
      "Epoch 287/2000\n",
      "45/45 [==============================] - 0s 166us/step - loss: 0.3943 - val_loss: 1.6847\n",
      "Epoch 288/2000\n",
      "45/45 [==============================] - 0s 152us/step - loss: 0.3932 - val_loss: 1.8088\n",
      "Epoch 289/2000\n",
      "45/45 [==============================] - 0s 172us/step - loss: 0.3950 - val_loss: 1.7071\n",
      "Epoch 290/2000\n",
      "45/45 [==============================] - 0s 167us/step - loss: 0.4019 - val_loss: 1.8152\n",
      "Epoch 291/2000\n",
      "45/45 [==============================] - 0s 165us/step - loss: 0.3931 - val_loss: 1.7229\n",
      "Epoch 292/2000\n",
      "45/45 [==============================] - 0s 153us/step - loss: 0.3998 - val_loss: 1.6326\n",
      "Epoch 293/2000\n",
      "45/45 [==============================] - 0s 161us/step - loss: 0.3932 - val_loss: 1.6853\n",
      "Epoch 294/2000\n",
      "45/45 [==============================] - 0s 163us/step - loss: 0.3915 - val_loss: 1.6518\n",
      "Epoch 295/2000\n",
      "45/45 [==============================] - 0s 147us/step - loss: 0.3957 - val_loss: 1.6557\n",
      "Epoch 296/2000\n",
      "45/45 [==============================] - 0s 161us/step - loss: 0.3936 - val_loss: 1.6270\n",
      "Epoch 297/2000\n",
      "45/45 [==============================] - 0s 146us/step - loss: 0.3921 - val_loss: 1.6610\n",
      "Epoch 298/2000\n",
      "45/45 [==============================] - 0s 163us/step - loss: 0.3940 - val_loss: 1.7854\n",
      "Epoch 299/2000\n",
      "45/45 [==============================] - 0s 146us/step - loss: 0.3934 - val_loss: 1.6434\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 300/2000\n",
      "45/45 [==============================] - 0s 159us/step - loss: 0.3918 - val_loss: 1.6874\n",
      "Epoch 301/2000\n",
      "45/45 [==============================] - 0s 140us/step - loss: 0.3929 - val_loss: 1.5723\n",
      "Epoch 302/2000\n",
      "45/45 [==============================] - 0s 154us/step - loss: 0.3947 - val_loss: 1.6409\n",
      "Epoch 303/2000\n",
      "45/45 [==============================] - 0s 152us/step - loss: 0.3943 - val_loss: 1.6330\n",
      "Epoch 304/2000\n",
      "45/45 [==============================] - 0s 155us/step - loss: 0.3883 - val_loss: 1.7273\n",
      "Epoch 305/2000\n",
      "45/45 [==============================] - 0s 141us/step - loss: 0.3924 - val_loss: 1.6868\n",
      "Epoch 306/2000\n",
      "45/45 [==============================] - 0s 158us/step - loss: 0.3913 - val_loss: 1.6321\n",
      "Epoch 307/2000\n",
      "45/45 [==============================] - 0s 152us/step - loss: 0.3874 - val_loss: 1.6814\n",
      "Epoch 308/2000\n",
      "45/45 [==============================] - 0s 143us/step - loss: 0.3922 - val_loss: 1.6925\n",
      "Epoch 309/2000\n",
      "45/45 [==============================] - 0s 175us/step - loss: 0.3877 - val_loss: 1.6864\n",
      "Epoch 310/2000\n",
      "45/45 [==============================] - 0s 166us/step - loss: 0.3964 - val_loss: 1.7358\n",
      "Epoch 311/2000\n",
      "45/45 [==============================] - 0s 161us/step - loss: 0.3879 - val_loss: 1.7251\n",
      "Epoch 312/2000\n",
      "45/45 [==============================] - 0s 153us/step - loss: 0.3879 - val_loss: 1.6216\n",
      "Epoch 313/2000\n",
      "45/45 [==============================] - 0s 168us/step - loss: 0.3861 - val_loss: 1.6321\n",
      "Epoch 314/2000\n",
      "45/45 [==============================] - 0s 150us/step - loss: 0.3921 - val_loss: 1.7220\n",
      "Epoch 315/2000\n",
      "45/45 [==============================] - 0s 167us/step - loss: 0.3872 - val_loss: 1.7121\n",
      "Epoch 316/2000\n",
      "45/45 [==============================] - 0s 151us/step - loss: 0.3911 - val_loss: 1.7823\n",
      "Epoch 317/2000\n",
      "45/45 [==============================] - 0s 153us/step - loss: 0.3910 - val_loss: 1.7422\n",
      "Epoch 318/2000\n",
      "45/45 [==============================] - 0s 144us/step - loss: 0.3884 - val_loss: 1.7300\n",
      "Epoch 319/2000\n",
      "45/45 [==============================] - 0s 143us/step - loss: 0.3893 - val_loss: 1.6196\n",
      "Epoch 320/2000\n",
      "45/45 [==============================] - 0s 149us/step - loss: 0.3893 - val_loss: 1.5517\n",
      "Epoch 321/2000\n",
      "45/45 [==============================] - 0s 146us/step - loss: 0.3893 - val_loss: 1.6564\n",
      "Epoch 322/2000\n",
      "45/45 [==============================] - 0s 158us/step - loss: 0.3927 - val_loss: 1.6576\n",
      "Epoch 323/2000\n",
      "45/45 [==============================] - 0s 145us/step - loss: 0.3883 - val_loss: 1.5810\n",
      "Epoch 324/2000\n",
      "45/45 [==============================] - 0s 156us/step - loss: 0.3846 - val_loss: 1.6250\n",
      "Epoch 325/2000\n",
      "45/45 [==============================] - 0s 150us/step - loss: 0.3901 - val_loss: 1.6275\n",
      "Epoch 326/2000\n",
      "45/45 [==============================] - 0s 145us/step - loss: 0.3868 - val_loss: 1.5754\n",
      "Epoch 327/2000\n",
      "45/45 [==============================] - 0s 148us/step - loss: 0.3891 - val_loss: 1.6187\n",
      "Epoch 328/2000\n",
      "45/45 [==============================] - 0s 141us/step - loss: 0.3876 - val_loss: 1.6526\n",
      "Epoch 329/2000\n",
      "45/45 [==============================] - 0s 157us/step - loss: 0.3850 - val_loss: 1.5528\n",
      "Epoch 330/2000\n",
      "45/45 [==============================] - 0s 144us/step - loss: 0.3829 - val_loss: 1.6996\n",
      "Epoch 331/2000\n",
      "45/45 [==============================] - 0s 160us/step - loss: 0.3821 - val_loss: 1.6650\n",
      "Epoch 332/2000\n",
      "45/45 [==============================] - 0s 145us/step - loss: 0.3837 - val_loss: 1.5851\n",
      "Epoch 333/2000\n",
      "45/45 [==============================] - 0s 157us/step - loss: 0.3825 - val_loss: 1.6293\n",
      "Epoch 334/2000\n",
      "45/45 [==============================] - 0s 152us/step - loss: 0.3804 - val_loss: 1.5818\n",
      "Epoch 335/2000\n",
      "45/45 [==============================] - 0s 144us/step - loss: 0.3826 - val_loss: 1.6678\n",
      "Epoch 336/2000\n",
      "45/45 [==============================] - 0s 159us/step - loss: 0.3810 - val_loss: 1.7064\n",
      "Epoch 337/2000\n",
      "45/45 [==============================] - 0s 147us/step - loss: 0.3794 - val_loss: 1.6724\n",
      "Epoch 338/2000\n",
      "45/45 [==============================] - 0s 166us/step - loss: 0.3844 - val_loss: 1.5893\n",
      "Epoch 339/2000\n",
      "45/45 [==============================] - 0s 156us/step - loss: 0.3841 - val_loss: 1.7183\n",
      "Epoch 340/2000\n",
      "45/45 [==============================] - 0s 172us/step - loss: 0.3814 - val_loss: 1.6286\n",
      "Epoch 341/2000\n",
      "45/45 [==============================] - 0s 160us/step - loss: 0.3800 - val_loss: 1.6935\n",
      "Epoch 342/2000\n",
      "45/45 [==============================] - 0s 165us/step - loss: 0.3811 - val_loss: 1.7773\n",
      "Epoch 343/2000\n",
      "45/45 [==============================] - 0s 158us/step - loss: 0.3788 - val_loss: 1.7115\n",
      "Epoch 344/2000\n",
      "45/45 [==============================] - 0s 168us/step - loss: 0.3830 - val_loss: 1.6028\n",
      "Epoch 345/2000\n",
      "45/45 [==============================] - 0s 156us/step - loss: 0.3854 - val_loss: 1.5670\n",
      "Epoch 346/2000\n",
      "45/45 [==============================] - 0s 159us/step - loss: 0.3847 - val_loss: 1.5943\n",
      "Epoch 347/2000\n",
      "45/45 [==============================] - 0s 163us/step - loss: 0.3791 - val_loss: 1.6850\n",
      "Epoch 348/2000\n",
      "45/45 [==============================] - 0s 153us/step - loss: 0.3756 - val_loss: 1.7156\n",
      "Epoch 349/2000\n",
      "45/45 [==============================] - 0s 160us/step - loss: 0.3795 - val_loss: 1.6412\n",
      "Epoch 350/2000\n",
      "45/45 [==============================] - 0s 139us/step - loss: 0.3842 - val_loss: 1.7174\n",
      "Epoch 351/2000\n",
      "45/45 [==============================] - 0s 157us/step - loss: 0.3805 - val_loss: 1.7435\n",
      "Epoch 352/2000\n",
      "45/45 [==============================] - 0s 141us/step - loss: 0.3756 - val_loss: 1.6642\n",
      "Epoch 353/2000\n",
      "45/45 [==============================] - 0s 158us/step - loss: 0.3742 - val_loss: 1.6346\n",
      "Epoch 354/2000\n",
      "45/45 [==============================] - 0s 147us/step - loss: 0.3742 - val_loss: 1.6004\n",
      "Epoch 355/2000\n",
      "45/45 [==============================] - 0s 163us/step - loss: 0.3812 - val_loss: 1.6074\n",
      "Epoch 356/2000\n",
      "45/45 [==============================] - 0s 156us/step - loss: 0.3784 - val_loss: 1.6129\n",
      "Epoch 357/2000\n",
      "45/45 [==============================] - 0s 159us/step - loss: 0.3778 - val_loss: 1.6677\n",
      "Epoch 358/2000\n",
      "45/45 [==============================] - 0s 159us/step - loss: 0.3744 - val_loss: 1.6932\n",
      "Epoch 359/2000\n",
      "45/45 [==============================] - 0s 162us/step - loss: 0.3726 - val_loss: 1.5953\n",
      "Epoch 360/2000\n",
      "45/45 [==============================] - 0s 160us/step - loss: 0.3757 - val_loss: 1.6666\n",
      "Epoch 361/2000\n",
      "45/45 [==============================] - 0s 151us/step - loss: 0.3737 - val_loss: 1.6386\n",
      "Epoch 362/2000\n",
      "45/45 [==============================] - 0s 163us/step - loss: 0.3825 - val_loss: 1.6444\n",
      "Epoch 363/2000\n",
      "45/45 [==============================] - 0s 147us/step - loss: 0.3730 - val_loss: 1.6285\n",
      "Epoch 364/2000\n",
      "45/45 [==============================] - 0s 166us/step - loss: 0.3764 - val_loss: 1.6077\n",
      "Epoch 365/2000\n",
      "45/45 [==============================] - 0s 146us/step - loss: 0.3718 - val_loss: 1.6059\n",
      "Epoch 366/2000\n",
      "45/45 [==============================] - 0s 167us/step - loss: 0.3733 - val_loss: 1.5932\n",
      "Epoch 367/2000\n",
      "45/45 [==============================] - 0s 145us/step - loss: 0.3709 - val_loss: 1.5743\n",
      "Epoch 368/2000\n",
      "45/45 [==============================] - 0s 167us/step - loss: 0.3690 - val_loss: 1.5317\n",
      "Epoch 369/2000\n",
      "45/45 [==============================] - 0s 165us/step - loss: 0.3741 - val_loss: 1.6019\n",
      "Epoch 370/2000\n",
      "45/45 [==============================] - 0s 169us/step - loss: 0.3688 - val_loss: 1.6976\n",
      "Epoch 371/2000\n",
      "45/45 [==============================] - 0s 153us/step - loss: 0.3692 - val_loss: 1.7288\n",
      "Epoch 372/2000\n",
      "45/45 [==============================] - 0s 171us/step - loss: 0.3690 - val_loss: 1.6774\n",
      "Epoch 373/2000\n",
      "45/45 [==============================] - 0s 160us/step - loss: 0.3707 - val_loss: 1.5402\n",
      "Epoch 374/2000\n",
      "45/45 [==============================] - 0s 163us/step - loss: 0.3682 - val_loss: 1.5987\n",
      "Epoch 375/2000\n",
      "45/45 [==============================] - 0s 147us/step - loss: 0.3721 - val_loss: 1.7176\n",
      "Epoch 376/2000\n",
      "45/45 [==============================] - 0s 146us/step - loss: 0.3686 - val_loss: 1.5675\n",
      "Epoch 377/2000\n",
      "45/45 [==============================] - 0s 211us/step - loss: 0.3657 - val_loss: 1.5711\n",
      "Epoch 378/2000\n",
      "45/45 [==============================] - 0s 226us/step - loss: 0.3656 - val_loss: 1.5974\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 379/2000\n",
      "45/45 [==============================] - 0s 256us/step - loss: 0.3691 - val_loss: 1.5052\n",
      "Epoch 380/2000\n",
      "45/45 [==============================] - 0s 241us/step - loss: 0.3669 - val_loss: 1.5495\n",
      "Epoch 381/2000\n",
      "45/45 [==============================] - 0s 215us/step - loss: 0.3695 - val_loss: 1.6253\n",
      "Epoch 382/2000\n",
      "45/45 [==============================] - 0s 211us/step - loss: 0.3643 - val_loss: 1.5120\n",
      "Epoch 383/2000\n",
      "45/45 [==============================] - 0s 185us/step - loss: 0.3616 - val_loss: 1.5889\n",
      "Epoch 384/2000\n",
      "45/45 [==============================] - 0s 186us/step - loss: 0.3667 - val_loss: 1.6783\n",
      "Epoch 385/2000\n",
      "45/45 [==============================] - 0s 183us/step - loss: 0.3646 - val_loss: 1.6775\n",
      "Epoch 386/2000\n",
      "45/45 [==============================] - 0s 186us/step - loss: 0.3640 - val_loss: 1.6233\n",
      "Epoch 387/2000\n",
      "45/45 [==============================] - 0s 178us/step - loss: 0.3661 - val_loss: 1.5733\n",
      "Epoch 388/2000\n",
      "45/45 [==============================] - 0s 175us/step - loss: 0.3632 - val_loss: 1.6026\n",
      "Epoch 389/2000\n",
      "45/45 [==============================] - 0s 186us/step - loss: 0.3663 - val_loss: 1.6833\n",
      "Epoch 390/2000\n",
      "45/45 [==============================] - 0s 183us/step - loss: 0.3623 - val_loss: 1.6371\n",
      "Epoch 391/2000\n",
      "45/45 [==============================] - 0s 168us/step - loss: 0.3600 - val_loss: 1.6657\n",
      "Epoch 392/2000\n",
      "45/45 [==============================] - 0s 179us/step - loss: 0.3590 - val_loss: 1.6028\n",
      "Epoch 393/2000\n",
      "45/45 [==============================] - 0s 196us/step - loss: 0.3574 - val_loss: 1.5646\n",
      "Epoch 394/2000\n",
      "45/45 [==============================] - 0s 201us/step - loss: 0.3592 - val_loss: 1.5270\n",
      "Epoch 395/2000\n",
      "45/45 [==============================] - 0s 181us/step - loss: 0.3586 - val_loss: 1.4687\n",
      "Epoch 396/2000\n",
      "45/45 [==============================] - 0s 215us/step - loss: 0.3562 - val_loss: 1.4872\n",
      "Epoch 397/2000\n",
      "45/45 [==============================] - 0s 183us/step - loss: 0.3558 - val_loss: 1.4786\n",
      "Epoch 398/2000\n",
      "45/45 [==============================] - 0s 202us/step - loss: 0.3555 - val_loss: 1.4476\n",
      "Epoch 399/2000\n",
      "45/45 [==============================] - 0s 165us/step - loss: 0.3550 - val_loss: 1.4501\n",
      "Epoch 400/2000\n",
      "45/45 [==============================] - 0s 188us/step - loss: 0.3562 - val_loss: 1.4932\n",
      "Epoch 401/2000\n",
      "45/45 [==============================] - 0s 232us/step - loss: 0.3576 - val_loss: 1.5964\n",
      "Epoch 402/2000\n",
      "45/45 [==============================] - 0s 218us/step - loss: 0.3541 - val_loss: 1.6004\n",
      "Epoch 403/2000\n",
      "45/45 [==============================] - 0s 217us/step - loss: 0.3547 - val_loss: 1.6347\n",
      "Epoch 404/2000\n",
      "45/45 [==============================] - 0s 180us/step - loss: 0.3549 - val_loss: 1.5919\n",
      "Epoch 405/2000\n",
      "45/45 [==============================] - 0s 192us/step - loss: 0.3561 - val_loss: 1.4376\n",
      "Epoch 406/2000\n",
      "45/45 [==============================] - 0s 186us/step - loss: 0.3609 - val_loss: 1.5457\n",
      "Epoch 407/2000\n",
      "45/45 [==============================] - 0s 187us/step - loss: 0.3555 - val_loss: 1.5454\n",
      "Epoch 408/2000\n",
      "45/45 [==============================] - 0s 182us/step - loss: 0.3525 - val_loss: 1.5541\n",
      "Epoch 409/2000\n",
      "45/45 [==============================] - 0s 208us/step - loss: 0.3500 - val_loss: 1.4898\n",
      "Epoch 410/2000\n",
      "45/45 [==============================] - 0s 213us/step - loss: 0.3491 - val_loss: 1.4862\n",
      "Epoch 411/2000\n",
      "45/45 [==============================] - 0s 184us/step - loss: 0.3545 - val_loss: 1.3952\n",
      "Epoch 412/2000\n",
      "45/45 [==============================] - 0s 178us/step - loss: 0.3496 - val_loss: 1.4251\n",
      "Epoch 413/2000\n",
      "45/45 [==============================] - 0s 224us/step - loss: 0.3558 - val_loss: 1.5165\n",
      "Epoch 414/2000\n",
      "45/45 [==============================] - 0s 172us/step - loss: 0.3556 - val_loss: 1.4674\n",
      "Epoch 415/2000\n",
      "45/45 [==============================] - 0s 218us/step - loss: 0.3493 - val_loss: 1.4246\n",
      "Epoch 416/2000\n",
      "45/45 [==============================] - 0s 181us/step - loss: 0.3441 - val_loss: 1.4638\n",
      "Epoch 417/2000\n",
      "45/45 [==============================] - 0s 191us/step - loss: 0.3490 - val_loss: 1.4073\n",
      "Epoch 418/2000\n",
      "45/45 [==============================] - 0s 167us/step - loss: 0.3442 - val_loss: 1.4826\n",
      "Epoch 419/2000\n",
      "45/45 [==============================] - 0s 207us/step - loss: 0.3500 - val_loss: 1.5765\n",
      "Epoch 420/2000\n",
      "45/45 [==============================] - 0s 189us/step - loss: 0.3482 - val_loss: 1.5523\n",
      "Epoch 421/2000\n",
      "45/45 [==============================] - 0s 169us/step - loss: 0.3461 - val_loss: 1.5112\n",
      "Epoch 422/2000\n",
      "45/45 [==============================] - 0s 209us/step - loss: 0.3435 - val_loss: 1.4777\n",
      "Epoch 423/2000\n",
      "45/45 [==============================] - 0s 171us/step - loss: 0.3457 - val_loss: 1.3197\n",
      "Epoch 424/2000\n",
      "45/45 [==============================] - 0s 193us/step - loss: 0.3457 - val_loss: 1.4223\n",
      "Epoch 425/2000\n",
      "45/45 [==============================] - 0s 187us/step - loss: 0.3448 - val_loss: 1.4117\n",
      "Epoch 426/2000\n",
      "45/45 [==============================] - 0s 203us/step - loss: 0.3420 - val_loss: 1.3749\n",
      "Epoch 427/2000\n",
      "45/45 [==============================] - 0s 207us/step - loss: 0.3418 - val_loss: 1.4340\n",
      "Epoch 428/2000\n",
      "45/45 [==============================] - 0s 191us/step - loss: 0.3426 - val_loss: 1.3619\n",
      "Epoch 429/2000\n",
      "45/45 [==============================] - 0s 224us/step - loss: 0.3399 - val_loss: 1.3357\n",
      "Epoch 430/2000\n",
      "45/45 [==============================] - 0s 196us/step - loss: 0.3382 - val_loss: 1.3681\n",
      "Epoch 431/2000\n",
      "45/45 [==============================] - 0s 207us/step - loss: 0.3397 - val_loss: 1.3964\n",
      "Epoch 432/2000\n",
      "45/45 [==============================] - 0s 181us/step - loss: 0.3424 - val_loss: 1.4070\n",
      "Epoch 433/2000\n",
      "45/45 [==============================] - 0s 194us/step - loss: 0.3375 - val_loss: 1.4924\n",
      "Epoch 434/2000\n",
      "45/45 [==============================] - 0s 185us/step - loss: 0.3393 - val_loss: 1.5235\n",
      "Epoch 435/2000\n",
      "45/45 [==============================] - 0s 180us/step - loss: 0.3388 - val_loss: 1.4808\n",
      "Epoch 436/2000\n",
      "45/45 [==============================] - 0s 208us/step - loss: 0.3370 - val_loss: 1.4118\n",
      "Epoch 437/2000\n",
      "45/45 [==============================] - 0s 194us/step - loss: 0.3336 - val_loss: 1.3589\n",
      "Epoch 438/2000\n",
      "45/45 [==============================] - 0s 198us/step - loss: 0.3329 - val_loss: 1.4033\n",
      "Epoch 439/2000\n",
      "45/45 [==============================] - 0s 221us/step - loss: 0.3309 - val_loss: 1.4387\n",
      "Epoch 440/2000\n",
      "45/45 [==============================] - 0s 190us/step - loss: 0.3348 - val_loss: 1.4216\n",
      "Epoch 441/2000\n",
      "45/45 [==============================] - 0s 216us/step - loss: 0.3304 - val_loss: 1.3358\n",
      "Epoch 442/2000\n",
      "45/45 [==============================] - 0s 196us/step - loss: 0.3311 - val_loss: 1.4119\n",
      "Epoch 443/2000\n",
      "45/45 [==============================] - 0s 201us/step - loss: 0.3283 - val_loss: 1.4646\n",
      "Epoch 444/2000\n",
      "45/45 [==============================] - 0s 214us/step - loss: 0.3278 - val_loss: 1.4367\n",
      "Epoch 445/2000\n",
      "45/45 [==============================] - 0s 197us/step - loss: 0.3293 - val_loss: 1.3827\n",
      "Epoch 446/2000\n",
      "45/45 [==============================] - 0s 207us/step - loss: 0.3305 - val_loss: 1.4318\n",
      "Epoch 447/2000\n",
      "45/45 [==============================] - 0s 201us/step - loss: 0.3267 - val_loss: 1.4215\n",
      "Epoch 448/2000\n",
      "45/45 [==============================] - 0s 203us/step - loss: 0.3333 - val_loss: 1.4626\n",
      "Epoch 449/2000\n",
      "45/45 [==============================] - 0s 193us/step - loss: 0.3274 - val_loss: 1.4077\n",
      "Epoch 450/2000\n",
      "45/45 [==============================] - 0s 173us/step - loss: 0.3249 - val_loss: 1.3859\n",
      "Epoch 451/2000\n",
      "45/45 [==============================] - 0s 193us/step - loss: 0.3222 - val_loss: 1.3726\n",
      "Epoch 452/2000\n",
      "45/45 [==============================] - 0s 187us/step - loss: 0.3228 - val_loss: 1.3781\n",
      "Epoch 453/2000\n",
      "45/45 [==============================] - 0s 209us/step - loss: 0.3228 - val_loss: 1.3883\n",
      "Epoch 454/2000\n",
      "45/45 [==============================] - 0s 195us/step - loss: 0.3214 - val_loss: 1.3469\n",
      "Epoch 455/2000\n",
      "45/45 [==============================] - 0s 210us/step - loss: 0.3210 - val_loss: 1.3038\n",
      "Epoch 456/2000\n",
      "45/45 [==============================] - 0s 218us/step - loss: 0.3227 - val_loss: 1.2955\n",
      "Epoch 457/2000\n",
      "45/45 [==============================] - 0s 205us/step - loss: 0.3242 - val_loss: 1.3996\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 458/2000\n",
      "45/45 [==============================] - 0s 219us/step - loss: 0.3233 - val_loss: 1.3123\n",
      "Epoch 459/2000\n",
      "45/45 [==============================] - 0s 225us/step - loss: 0.3174 - val_loss: 1.3685\n",
      "Epoch 460/2000\n",
      "45/45 [==============================] - 0s 207us/step - loss: 0.3153 - val_loss: 1.2856\n",
      "Epoch 461/2000\n",
      "45/45 [==============================] - 0s 207us/step - loss: 0.3166 - val_loss: 1.2563\n",
      "Epoch 462/2000\n",
      "45/45 [==============================] - 0s 210us/step - loss: 0.3175 - val_loss: 1.3448\n",
      "Epoch 463/2000\n",
      "45/45 [==============================] - 0s 202us/step - loss: 0.3187 - val_loss: 1.2047\n",
      "Epoch 464/2000\n",
      "45/45 [==============================] - 0s 209us/step - loss: 0.3150 - val_loss: 1.2403\n",
      "Epoch 465/2000\n",
      "45/45 [==============================] - 0s 200us/step - loss: 0.3172 - val_loss: 1.3053\n",
      "Epoch 466/2000\n",
      "45/45 [==============================] - 0s 198us/step - loss: 0.3120 - val_loss: 1.2009\n",
      "Epoch 467/2000\n",
      "45/45 [==============================] - 0s 220us/step - loss: 0.3146 - val_loss: 1.2454\n",
      "Epoch 468/2000\n",
      "45/45 [==============================] - 0s 201us/step - loss: 0.3113 - val_loss: 1.3409\n",
      "Epoch 469/2000\n",
      "45/45 [==============================] - 0s 203us/step - loss: 0.3108 - val_loss: 1.2984\n",
      "Epoch 470/2000\n",
      "45/45 [==============================] - 0s 189us/step - loss: 0.3116 - val_loss: 1.2851\n",
      "Epoch 471/2000\n",
      "45/45 [==============================] - 0s 199us/step - loss: 0.3067 - val_loss: 1.2570\n",
      "Epoch 472/2000\n",
      "45/45 [==============================] - 0s 218us/step - loss: 0.3081 - val_loss: 1.3050\n",
      "Epoch 473/2000\n",
      "45/45 [==============================] - 0s 196us/step - loss: 0.3072 - val_loss: 1.2523\n",
      "Epoch 474/2000\n",
      "45/45 [==============================] - 0s 200us/step - loss: 0.3080 - val_loss: 1.2744\n",
      "Epoch 475/2000\n",
      "45/45 [==============================] - 0s 200us/step - loss: 0.3048 - val_loss: 1.1856\n",
      "Epoch 476/2000\n",
      "45/45 [==============================] - 0s 195us/step - loss: 0.3082 - val_loss: 1.2350\n",
      "Epoch 477/2000\n",
      "45/45 [==============================] - 0s 213us/step - loss: 0.3033 - val_loss: 1.2733\n",
      "Epoch 478/2000\n",
      "45/45 [==============================] - 0s 205us/step - loss: 0.3064 - val_loss: 1.2768\n",
      "Epoch 479/2000\n",
      "45/45 [==============================] - 0s 204us/step - loss: 0.3017 - val_loss: 1.2945\n",
      "Epoch 480/2000\n",
      "45/45 [==============================] - 0s 213us/step - loss: 0.3051 - val_loss: 1.3389\n",
      "Epoch 481/2000\n",
      "45/45 [==============================] - 0s 196us/step - loss: 0.2980 - val_loss: 1.3290\n",
      "Epoch 482/2000\n",
      "45/45 [==============================] - 0s 234us/step - loss: 0.2982 - val_loss: 1.3036\n",
      "Epoch 483/2000\n",
      "45/45 [==============================] - 0s 204us/step - loss: 0.2976 - val_loss: 1.2044\n",
      "Epoch 484/2000\n",
      "45/45 [==============================] - 0s 223us/step - loss: 0.2974 - val_loss: 1.2462\n",
      "Epoch 485/2000\n",
      "45/45 [==============================] - 0s 187us/step - loss: 0.2946 - val_loss: 1.2852\n",
      "Epoch 486/2000\n",
      "45/45 [==============================] - 0s 183us/step - loss: 0.2959 - val_loss: 1.3235\n",
      "Epoch 487/2000\n",
      "45/45 [==============================] - 0s 208us/step - loss: 0.2944 - val_loss: 1.3161\n",
      "Epoch 488/2000\n",
      "45/45 [==============================] - 0s 172us/step - loss: 0.2928 - val_loss: 1.2475\n",
      "Epoch 489/2000\n",
      "45/45 [==============================] - 0s 184us/step - loss: 0.2923 - val_loss: 1.1688\n",
      "Epoch 490/2000\n",
      "45/45 [==============================] - 0s 196us/step - loss: 0.2914 - val_loss: 1.2396\n",
      "Epoch 491/2000\n",
      "45/45 [==============================] - 0s 204us/step - loss: 0.2909 - val_loss: 1.2032\n",
      "Epoch 492/2000\n",
      "45/45 [==============================] - 0s 193us/step - loss: 0.2889 - val_loss: 1.2825\n",
      "Epoch 493/2000\n",
      "45/45 [==============================] - 0s 194us/step - loss: 0.2902 - val_loss: 1.2688\n",
      "Epoch 494/2000\n",
      "45/45 [==============================] - 0s 227us/step - loss: 0.2870 - val_loss: 1.2406\n",
      "Epoch 495/2000\n",
      "45/45 [==============================] - 0s 200us/step - loss: 0.2854 - val_loss: 1.2122\n",
      "Epoch 496/2000\n",
      "45/45 [==============================] - 0s 226us/step - loss: 0.2880 - val_loss: 1.2347\n",
      "Epoch 497/2000\n",
      "45/45 [==============================] - 0s 213us/step - loss: 0.2831 - val_loss: 1.2607\n",
      "Epoch 498/2000\n",
      "45/45 [==============================] - 0s 204us/step - loss: 0.2852 - val_loss: 1.1933\n",
      "Epoch 499/2000\n",
      "45/45 [==============================] - 0s 236us/step - loss: 0.2900 - val_loss: 1.1646\n",
      "Epoch 500/2000\n",
      "45/45 [==============================] - 0s 226us/step - loss: 0.2811 - val_loss: 1.1157\n",
      "Epoch 501/2000\n",
      "45/45 [==============================] - 0s 200us/step - loss: 0.2789 - val_loss: 1.1991\n",
      "Epoch 502/2000\n",
      "45/45 [==============================] - 0s 219us/step - loss: 0.2802 - val_loss: 1.1614\n",
      "Epoch 503/2000\n",
      "45/45 [==============================] - 0s 210us/step - loss: 0.2810 - val_loss: 1.1347\n",
      "Epoch 504/2000\n",
      "45/45 [==============================] - 0s 199us/step - loss: 0.2762 - val_loss: 1.1969\n",
      "Epoch 505/2000\n",
      "45/45 [==============================] - 0s 227us/step - loss: 0.2767 - val_loss: 1.2406\n",
      "Epoch 506/2000\n",
      "45/45 [==============================] - 0s 204us/step - loss: 0.2796 - val_loss: 1.2188\n",
      "Epoch 507/2000\n",
      "45/45 [==============================] - 0s 213us/step - loss: 0.2769 - val_loss: 1.1984\n",
      "Epoch 508/2000\n",
      "45/45 [==============================] - 0s 213us/step - loss: 0.2750 - val_loss: 1.1514\n",
      "Epoch 509/2000\n",
      "45/45 [==============================] - 0s 201us/step - loss: 0.2720 - val_loss: 1.1051\n",
      "Epoch 510/2000\n",
      "45/45 [==============================] - 0s 225us/step - loss: 0.2718 - val_loss: 1.1677\n",
      "Epoch 511/2000\n",
      "45/45 [==============================] - 0s 212us/step - loss: 0.2739 - val_loss: 1.0717\n",
      "Epoch 512/2000\n",
      "45/45 [==============================] - 0s 210us/step - loss: 0.2745 - val_loss: 1.0849\n",
      "Epoch 513/2000\n",
      "45/45 [==============================] - 0s 209us/step - loss: 0.2683 - val_loss: 1.1221\n",
      "Epoch 514/2000\n",
      "45/45 [==============================] - 0s 210us/step - loss: 0.2673 - val_loss: 1.1355\n",
      "Epoch 515/2000\n",
      "45/45 [==============================] - 0s 215us/step - loss: 0.2651 - val_loss: 1.1523\n",
      "Epoch 516/2000\n",
      "45/45 [==============================] - 0s 230us/step - loss: 0.2662 - val_loss: 1.2333\n",
      "Epoch 517/2000\n",
      "45/45 [==============================] - 0s 216us/step - loss: 0.2653 - val_loss: 1.1438\n",
      "Epoch 518/2000\n",
      "45/45 [==============================] - 0s 217us/step - loss: 0.2648 - val_loss: 1.1313\n",
      "Epoch 519/2000\n",
      "45/45 [==============================] - 0s 212us/step - loss: 0.2601 - val_loss: 1.1217\n",
      "Epoch 520/2000\n",
      "45/45 [==============================] - 0s 217us/step - loss: 0.2599 - val_loss: 1.1017\n",
      "Epoch 521/2000\n",
      "45/45 [==============================] - 0s 218us/step - loss: 0.2613 - val_loss: 1.0843\n",
      "Epoch 522/2000\n",
      "45/45 [==============================] - 0s 203us/step - loss: 0.2636 - val_loss: 1.0610\n",
      "Epoch 523/2000\n",
      "45/45 [==============================] - 0s 207us/step - loss: 0.2564 - val_loss: 1.1058\n",
      "Epoch 524/2000\n",
      "45/45 [==============================] - 0s 225us/step - loss: 0.2567 - val_loss: 1.1375\n",
      "Epoch 525/2000\n",
      "45/45 [==============================] - 0s 196us/step - loss: 0.2581 - val_loss: 1.0534\n",
      "Epoch 526/2000\n",
      "45/45 [==============================] - 0s 217us/step - loss: 0.2590 - val_loss: 1.0929\n",
      "Epoch 527/2000\n",
      "45/45 [==============================] - 0s 214us/step - loss: 0.2540 - val_loss: 1.0926\n",
      "Epoch 528/2000\n",
      "45/45 [==============================] - 0s 198us/step - loss: 0.2534 - val_loss: 1.0474\n",
      "Epoch 529/2000\n",
      "45/45 [==============================] - 0s 210us/step - loss: 0.2507 - val_loss: 1.0239\n",
      "Epoch 530/2000\n",
      "45/45 [==============================] - 0s 171us/step - loss: 0.2495 - val_loss: 1.0458\n",
      "Epoch 531/2000\n",
      "45/45 [==============================] - 0s 188us/step - loss: 0.2486 - val_loss: 1.0187\n",
      "Epoch 532/2000\n",
      "45/45 [==============================] - 0s 167us/step - loss: 0.2467 - val_loss: 1.0334\n",
      "Epoch 533/2000\n",
      "45/45 [==============================] - 0s 180us/step - loss: 0.2499 - val_loss: 1.0515\n",
      "Epoch 534/2000\n",
      "45/45 [==============================] - 0s 156us/step - loss: 0.2462 - val_loss: 1.0676\n",
      "Epoch 535/2000\n",
      "45/45 [==============================] - 0s 182us/step - loss: 0.2462 - val_loss: 1.0954\n",
      "Epoch 536/2000\n",
      "45/45 [==============================] - 0s 152us/step - loss: 0.2429 - val_loss: 1.0142\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 537/2000\n",
      "45/45 [==============================] - 0s 176us/step - loss: 0.2470 - val_loss: 0.9986\n",
      "Epoch 538/2000\n",
      "45/45 [==============================] - 0s 154us/step - loss: 0.2462 - val_loss: 0.9915\n",
      "Epoch 539/2000\n",
      "45/45 [==============================] - 0s 178us/step - loss: 0.2432 - val_loss: 1.0382\n",
      "Epoch 540/2000\n",
      "45/45 [==============================] - 0s 157us/step - loss: 0.2400 - val_loss: 1.0506\n",
      "Epoch 541/2000\n",
      "45/45 [==============================] - 0s 161us/step - loss: 0.2370 - val_loss: 1.0224\n",
      "Epoch 542/2000\n",
      "45/45 [==============================] - 0s 148us/step - loss: 0.2371 - val_loss: 1.0205\n",
      "Epoch 543/2000\n",
      "45/45 [==============================] - 0s 163us/step - loss: 0.2388 - val_loss: 0.9805\n",
      "Epoch 544/2000\n",
      "45/45 [==============================] - 0s 143us/step - loss: 0.2360 - val_loss: 1.0543\n",
      "Epoch 545/2000\n",
      "45/45 [==============================] - 0s 159us/step - loss: 0.2345 - val_loss: 0.9506\n",
      "Epoch 546/2000\n",
      "45/45 [==============================] - 0s 147us/step - loss: 0.2354 - val_loss: 0.9651\n",
      "Epoch 547/2000\n",
      "45/45 [==============================] - 0s 168us/step - loss: 0.2312 - val_loss: 0.9692\n",
      "Epoch 548/2000\n",
      "45/45 [==============================] - 0s 153us/step - loss: 0.2301 - val_loss: 1.0026\n",
      "Epoch 549/2000\n",
      "45/45 [==============================] - 0s 162us/step - loss: 0.2307 - val_loss: 0.9211\n",
      "Epoch 550/2000\n",
      "45/45 [==============================] - 0s 155us/step - loss: 0.2295 - val_loss: 0.9568\n",
      "Epoch 551/2000\n",
      "45/45 [==============================] - 0s 164us/step - loss: 0.2278 - val_loss: 0.9594\n",
      "Epoch 552/2000\n",
      "45/45 [==============================] - 0s 158us/step - loss: 0.2325 - val_loss: 1.0313\n",
      "Epoch 553/2000\n",
      "45/45 [==============================] - 0s 155us/step - loss: 0.2288 - val_loss: 1.0261\n",
      "Epoch 554/2000\n",
      "45/45 [==============================] - 0s 153us/step - loss: 0.2236 - val_loss: 0.9641\n",
      "Epoch 555/2000\n",
      "45/45 [==============================] - 0s 156us/step - loss: 0.2261 - val_loss: 0.8804\n",
      "Epoch 556/2000\n",
      "45/45 [==============================] - 0s 175us/step - loss: 0.2224 - val_loss: 0.9768\n",
      "Epoch 557/2000\n",
      "45/45 [==============================] - 0s 154us/step - loss: 0.2191 - val_loss: 0.9943\n",
      "Epoch 558/2000\n",
      "45/45 [==============================] - 0s 172us/step - loss: 0.2212 - val_loss: 0.9580\n",
      "Epoch 559/2000\n",
      "45/45 [==============================] - 0s 171us/step - loss: 0.2176 - val_loss: 0.9219\n",
      "Epoch 560/2000\n",
      "45/45 [==============================] - 0s 173us/step - loss: 0.2187 - val_loss: 0.9415\n",
      "Epoch 561/2000\n",
      "45/45 [==============================] - 0s 168us/step - loss: 0.2148 - val_loss: 0.9963\n",
      "Epoch 562/2000\n",
      "45/45 [==============================] - 0s 171us/step - loss: 0.2149 - val_loss: 0.9392\n",
      "Epoch 563/2000\n",
      "45/45 [==============================] - 0s 155us/step - loss: 0.2129 - val_loss: 0.9032\n",
      "Epoch 564/2000\n",
      "45/45 [==============================] - 0s 169us/step - loss: 0.2127 - val_loss: 0.9939\n",
      "Epoch 565/2000\n",
      "45/45 [==============================] - 0s 157us/step - loss: 0.2098 - val_loss: 0.9454\n",
      "Epoch 566/2000\n",
      "45/45 [==============================] - 0s 174us/step - loss: 0.2088 - val_loss: 0.9542\n",
      "Epoch 567/2000\n",
      "45/45 [==============================] - 0s 155us/step - loss: 0.2066 - val_loss: 0.9095\n",
      "Epoch 568/2000\n",
      "45/45 [==============================] - 0s 178us/step - loss: 0.2068 - val_loss: 0.9409\n",
      "Epoch 569/2000\n",
      "45/45 [==============================] - 0s 150us/step - loss: 0.2049 - val_loss: 0.9212\n",
      "Epoch 570/2000\n",
      "45/45 [==============================] - 0s 176us/step - loss: 0.2065 - val_loss: 0.9072\n",
      "Epoch 571/2000\n",
      "45/45 [==============================] - 0s 173us/step - loss: 0.2029 - val_loss: 0.9059\n",
      "Epoch 572/2000\n",
      "45/45 [==============================] - 0s 168us/step - loss: 0.2008 - val_loss: 0.9003\n",
      "Epoch 573/2000\n",
      "45/45 [==============================] - 0s 161us/step - loss: 0.2018 - val_loss: 0.8838\n",
      "Epoch 574/2000\n",
      "45/45 [==============================] - 0s 174us/step - loss: 0.2023 - val_loss: 0.8702\n",
      "Epoch 575/2000\n",
      "45/45 [==============================] - 0s 159us/step - loss: 0.1999 - val_loss: 0.8782\n",
      "Epoch 576/2000\n",
      "45/45 [==============================] - 0s 152us/step - loss: 0.1978 - val_loss: 0.8474\n",
      "Epoch 577/2000\n",
      "45/45 [==============================] - 0s 168us/step - loss: 0.1981 - val_loss: 0.8734\n",
      "Epoch 578/2000\n",
      "45/45 [==============================] - 0s 149us/step - loss: 0.1956 - val_loss: 0.8532\n",
      "Epoch 579/2000\n",
      "45/45 [==============================] - 0s 146us/step - loss: 0.1947 - val_loss: 0.8784\n",
      "Epoch 580/2000\n",
      "45/45 [==============================] - 0s 149us/step - loss: 0.1936 - val_loss: 0.9071\n",
      "Epoch 581/2000\n",
      "45/45 [==============================] - 0s 170us/step - loss: 0.1918 - val_loss: 0.8447\n",
      "Epoch 582/2000\n",
      "45/45 [==============================] - 0s 155us/step - loss: 0.1909 - val_loss: 0.8213\n",
      "Epoch 583/2000\n",
      "45/45 [==============================] - 0s 167us/step - loss: 0.1923 - val_loss: 0.8854\n",
      "Epoch 584/2000\n",
      "45/45 [==============================] - 0s 148us/step - loss: 0.1881 - val_loss: 0.8781\n",
      "Epoch 585/2000\n",
      "45/45 [==============================] - 0s 161us/step - loss: 0.1874 - val_loss: 0.9001\n",
      "Epoch 586/2000\n",
      "45/45 [==============================] - 0s 163us/step - loss: 0.1871 - val_loss: 0.9031\n",
      "Epoch 587/2000\n",
      "45/45 [==============================] - 0s 166us/step - loss: 0.1870 - val_loss: 0.8965\n",
      "Epoch 588/2000\n",
      "45/45 [==============================] - 0s 157us/step - loss: 0.1842 - val_loss: 0.8638\n",
      "Epoch 589/2000\n",
      "45/45 [==============================] - 0s 158us/step - loss: 0.1825 - val_loss: 0.8635\n",
      "Epoch 590/2000\n",
      "45/45 [==============================] - 0s 161us/step - loss: 0.1826 - val_loss: 0.8077\n",
      "Epoch 591/2000\n",
      "45/45 [==============================] - 0s 152us/step - loss: 0.1804 - val_loss: 0.7704\n",
      "Epoch 592/2000\n",
      "45/45 [==============================] - 0s 156us/step - loss: 0.1783 - val_loss: 0.7892\n",
      "Epoch 593/2000\n",
      "45/45 [==============================] - 0s 140us/step - loss: 0.1810 - val_loss: 0.7824\n",
      "Epoch 594/2000\n",
      "45/45 [==============================] - 0s 165us/step - loss: 0.1765 - val_loss: 0.8479\n",
      "Epoch 595/2000\n",
      "45/45 [==============================] - 0s 143us/step - loss: 0.1745 - val_loss: 0.8142\n",
      "Epoch 596/2000\n",
      "45/45 [==============================] - 0s 164us/step - loss: 0.1733 - val_loss: 0.8103\n",
      "Epoch 597/2000\n",
      "45/45 [==============================] - 0s 154us/step - loss: 0.1728 - val_loss: 0.7607\n",
      "Epoch 598/2000\n",
      "45/45 [==============================] - 0s 165us/step - loss: 0.1707 - val_loss: 0.8014\n",
      "Epoch 599/2000\n",
      "45/45 [==============================] - 0s 167us/step - loss: 0.1696 - val_loss: 0.7715\n",
      "Epoch 600/2000\n",
      "45/45 [==============================] - 0s 163us/step - loss: 0.1692 - val_loss: 0.7874\n",
      "Epoch 601/2000\n",
      "45/45 [==============================] - 0s 153us/step - loss: 0.1682 - val_loss: 0.8111\n",
      "Epoch 602/2000\n",
      "45/45 [==============================] - 0s 155us/step - loss: 0.1680 - val_loss: 0.7993\n",
      "Epoch 603/2000\n",
      "45/45 [==============================] - 0s 157us/step - loss: 0.1677 - val_loss: 0.7139\n",
      "Epoch 604/2000\n",
      "45/45 [==============================] - 0s 142us/step - loss: 0.1641 - val_loss: 0.7448\n",
      "Epoch 605/2000\n",
      "45/45 [==============================] - 0s 169us/step - loss: 0.1642 - val_loss: 0.7602\n",
      "Epoch 606/2000\n",
      "45/45 [==============================] - 0s 179us/step - loss: 0.1617 - val_loss: 0.7420\n",
      "Epoch 607/2000\n",
      "45/45 [==============================] - 0s 182us/step - loss: 0.1625 - val_loss: 0.7465\n",
      "Epoch 608/2000\n",
      "45/45 [==============================] - 0s 172us/step - loss: 0.1603 - val_loss: 0.7525\n",
      "Epoch 609/2000\n",
      "45/45 [==============================] - 0s 186us/step - loss: 0.1590 - val_loss: 0.7798\n",
      "Epoch 610/2000\n",
      "45/45 [==============================] - 0s 167us/step - loss: 0.1576 - val_loss: 0.7834\n",
      "Epoch 611/2000\n",
      "45/45 [==============================] - 0s 167us/step - loss: 0.1572 - val_loss: 0.7380\n",
      "Epoch 612/2000\n",
      "45/45 [==============================] - 0s 178us/step - loss: 0.1558 - val_loss: 0.7026\n",
      "Epoch 613/2000\n",
      "45/45 [==============================] - 0s 184us/step - loss: 0.1549 - val_loss: 0.7437\n",
      "Epoch 614/2000\n",
      "45/45 [==============================] - 0s 161us/step - loss: 0.1520 - val_loss: 0.7439\n",
      "Epoch 615/2000\n",
      "45/45 [==============================] - 0s 171us/step - loss: 0.1541 - val_loss: 0.7546\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 616/2000\n",
      "45/45 [==============================] - 0s 174us/step - loss: 0.1506 - val_loss: 0.7327\n",
      "Epoch 617/2000\n",
      "45/45 [==============================] - 0s 175us/step - loss: 0.1504 - val_loss: 0.6934\n",
      "Epoch 618/2000\n",
      "45/45 [==============================] - 0s 161us/step - loss: 0.1488 - val_loss: 0.6602\n",
      "Epoch 619/2000\n",
      "45/45 [==============================] - 0s 192us/step - loss: 0.1482 - val_loss: 0.6602\n",
      "Epoch 620/2000\n",
      "45/45 [==============================] - 0s 212us/step - loss: 0.1467 - val_loss: 0.6650\n",
      "Epoch 621/2000\n",
      "45/45 [==============================] - 0s 187us/step - loss: 0.1458 - val_loss: 0.6572\n",
      "Epoch 622/2000\n",
      "45/45 [==============================] - 0s 204us/step - loss: 0.1471 - val_loss: 0.6840\n",
      "Epoch 623/2000\n",
      "45/45 [==============================] - 0s 194us/step - loss: 0.1437 - val_loss: 0.6986\n",
      "Epoch 624/2000\n",
      "45/45 [==============================] - 0s 190us/step - loss: 0.1433 - val_loss: 0.6626\n",
      "Epoch 625/2000\n",
      "45/45 [==============================] - 0s 207us/step - loss: 0.1400 - val_loss: 0.6695\n",
      "Epoch 626/2000\n",
      "45/45 [==============================] - 0s 174us/step - loss: 0.1400 - val_loss: 0.6661\n",
      "Epoch 627/2000\n",
      "45/45 [==============================] - 0s 210us/step - loss: 0.1421 - val_loss: 0.6634\n",
      "Epoch 628/2000\n",
      "45/45 [==============================] - 0s 160us/step - loss: 0.1378 - val_loss: 0.6120\n",
      "Epoch 629/2000\n",
      "45/45 [==============================] - 0s 167us/step - loss: 0.1373 - val_loss: 0.6149\n",
      "Epoch 630/2000\n",
      "45/45 [==============================] - 0s 201us/step - loss: 0.1353 - val_loss: 0.6081\n",
      "Epoch 631/2000\n",
      "45/45 [==============================] - 0s 199us/step - loss: 0.1371 - val_loss: 0.6044\n",
      "Epoch 632/2000\n",
      "45/45 [==============================] - 0s 191us/step - loss: 0.1339 - val_loss: 0.6426\n",
      "Epoch 633/2000\n",
      "45/45 [==============================] - 0s 185us/step - loss: 0.1326 - val_loss: 0.6124\n",
      "Epoch 634/2000\n",
      "45/45 [==============================] - 0s 185us/step - loss: 0.1310 - val_loss: 0.6413\n",
      "Epoch 635/2000\n",
      "45/45 [==============================] - 0s 182us/step - loss: 0.1307 - val_loss: 0.6270\n",
      "Epoch 636/2000\n",
      "45/45 [==============================] - 0s 203us/step - loss: 0.1322 - val_loss: 0.6353\n",
      "Epoch 637/2000\n",
      "45/45 [==============================] - 0s 171us/step - loss: 0.1318 - val_loss: 0.6244\n",
      "Epoch 638/2000\n",
      "45/45 [==============================] - 0s 176us/step - loss: 0.1299 - val_loss: 0.6189\n",
      "Epoch 639/2000\n",
      "45/45 [==============================] - 0s 169us/step - loss: 0.1258 - val_loss: 0.5838\n",
      "Epoch 640/2000\n",
      "45/45 [==============================] - 0s 195us/step - loss: 0.1253 - val_loss: 0.6055\n",
      "Epoch 641/2000\n",
      "45/45 [==============================] - 0s 170us/step - loss: 0.1232 - val_loss: 0.5923\n",
      "Epoch 642/2000\n",
      "45/45 [==============================] - 0s 186us/step - loss: 0.1241 - val_loss: 0.5673\n",
      "Epoch 643/2000\n",
      "45/45 [==============================] - 0s 161us/step - loss: 0.1229 - val_loss: 0.5590\n",
      "Epoch 644/2000\n",
      "45/45 [==============================] - 0s 180us/step - loss: 0.1201 - val_loss: 0.5590\n",
      "Epoch 645/2000\n",
      "45/45 [==============================] - 0s 172us/step - loss: 0.1195 - val_loss: 0.5682\n",
      "Epoch 646/2000\n",
      "45/45 [==============================] - 0s 191us/step - loss: 0.1181 - val_loss: 0.5816\n",
      "Epoch 647/2000\n",
      "45/45 [==============================] - 0s 186us/step - loss: 0.1181 - val_loss: 0.5388\n",
      "Epoch 648/2000\n",
      "45/45 [==============================] - 0s 186us/step - loss: 0.1171 - val_loss: 0.5542\n",
      "Epoch 649/2000\n",
      "45/45 [==============================] - 0s 169us/step - loss: 0.1157 - val_loss: 0.5810\n",
      "Epoch 650/2000\n",
      "45/45 [==============================] - 0s 167us/step - loss: 0.1143 - val_loss: 0.5661\n",
      "Epoch 651/2000\n",
      "45/45 [==============================] - 0s 175us/step - loss: 0.1135 - val_loss: 0.5496\n",
      "Epoch 652/2000\n",
      "45/45 [==============================] - 0s 179us/step - loss: 0.1134 - val_loss: 0.5486\n",
      "Epoch 653/2000\n",
      "45/45 [==============================] - 0s 167us/step - loss: 0.1129 - val_loss: 0.5440\n",
      "Epoch 654/2000\n",
      "45/45 [==============================] - 0s 159us/step - loss: 0.1127 - val_loss: 0.5115\n",
      "Epoch 655/2000\n",
      "45/45 [==============================] - 0s 169us/step - loss: 0.1128 - val_loss: 0.5348\n",
      "Epoch 656/2000\n",
      "45/45 [==============================] - 0s 182us/step - loss: 0.1118 - val_loss: 0.5247\n",
      "Epoch 657/2000\n",
      "45/45 [==============================] - 0s 173us/step - loss: 0.1084 - val_loss: 0.5568\n",
      "Epoch 658/2000\n",
      "45/45 [==============================] - 0s 163us/step - loss: 0.1071 - val_loss: 0.5348\n",
      "Epoch 659/2000\n",
      "45/45 [==============================] - 0s 192us/step - loss: 0.1076 - val_loss: 0.5591\n",
      "Epoch 660/2000\n",
      "45/45 [==============================] - 0s 174us/step - loss: 0.1054 - val_loss: 0.5576\n",
      "Epoch 661/2000\n",
      "45/45 [==============================] - 0s 167us/step - loss: 0.1035 - val_loss: 0.5317\n",
      "Epoch 662/2000\n",
      "45/45 [==============================] - 0s 164us/step - loss: 0.1029 - val_loss: 0.5394\n",
      "Epoch 663/2000\n",
      "45/45 [==============================] - 0s 194us/step - loss: 0.1022 - val_loss: 0.5252\n",
      "Epoch 664/2000\n",
      "45/45 [==============================] - 0s 162us/step - loss: 0.1016 - val_loss: 0.5073\n",
      "Epoch 665/2000\n",
      "45/45 [==============================] - 0s 166us/step - loss: 0.1027 - val_loss: 0.5051\n",
      "Epoch 666/2000\n",
      "45/45 [==============================] - 0s 173us/step - loss: 0.0994 - val_loss: 0.5290\n",
      "Epoch 667/2000\n",
      "45/45 [==============================] - 0s 200us/step - loss: 0.0984 - val_loss: 0.4954\n",
      "Epoch 668/2000\n",
      "45/45 [==============================] - 0s 168us/step - loss: 0.0990 - val_loss: 0.4940\n",
      "Epoch 669/2000\n",
      "45/45 [==============================] - 0s 169us/step - loss: 0.0967 - val_loss: 0.5077\n",
      "Epoch 670/2000\n",
      "45/45 [==============================] - 0s 161us/step - loss: 0.0963 - val_loss: 0.5061\n",
      "Epoch 671/2000\n",
      "45/45 [==============================] - 0s 190us/step - loss: 0.0945 - val_loss: 0.5317\n",
      "Epoch 672/2000\n",
      "45/45 [==============================] - 0s 170us/step - loss: 0.0940 - val_loss: 0.5169\n",
      "Epoch 673/2000\n",
      "45/45 [==============================] - 0s 198us/step - loss: 0.0941 - val_loss: 0.4741\n",
      "Epoch 674/2000\n",
      "45/45 [==============================] - 0s 181us/step - loss: 0.0930 - val_loss: 0.4967\n",
      "Epoch 675/2000\n",
      "45/45 [==============================] - 0s 174us/step - loss: 0.0927 - val_loss: 0.4688\n",
      "Epoch 676/2000\n",
      "45/45 [==============================] - 0s 198us/step - loss: 0.0910 - val_loss: 0.4590\n",
      "Epoch 677/2000\n",
      "45/45 [==============================] - 0s 188us/step - loss: 0.0896 - val_loss: 0.4732\n",
      "Epoch 678/2000\n",
      "45/45 [==============================] - 0s 190us/step - loss: 0.0898 - val_loss: 0.4980\n",
      "Epoch 679/2000\n",
      "45/45 [==============================] - 0s 202us/step - loss: 0.0880 - val_loss: 0.4709\n",
      "Epoch 680/2000\n",
      "45/45 [==============================] - 0s 190us/step - loss: 0.0881 - val_loss: 0.4547\n",
      "Epoch 681/2000\n",
      "45/45 [==============================] - 0s 203us/step - loss: 0.0865 - val_loss: 0.4404\n",
      "Epoch 682/2000\n",
      "45/45 [==============================] - 0s 189us/step - loss: 0.0863 - val_loss: 0.4226\n",
      "Epoch 683/2000\n",
      "45/45 [==============================] - 0s 207us/step - loss: 0.0849 - val_loss: 0.4419\n",
      "Epoch 684/2000\n",
      "45/45 [==============================] - 0s 201us/step - loss: 0.0840 - val_loss: 0.4341\n",
      "Epoch 685/2000\n",
      "45/45 [==============================] - 0s 189us/step - loss: 0.0834 - val_loss: 0.4291\n",
      "Epoch 686/2000\n",
      "45/45 [==============================] - 0s 193us/step - loss: 0.0824 - val_loss: 0.4334\n",
      "Epoch 687/2000\n",
      "45/45 [==============================] - 0s 181us/step - loss: 0.0820 - val_loss: 0.4477\n",
      "Epoch 688/2000\n",
      "45/45 [==============================] - 0s 205us/step - loss: 0.0817 - val_loss: 0.4315\n",
      "Epoch 689/2000\n",
      "45/45 [==============================] - 0s 180us/step - loss: 0.0800 - val_loss: 0.4326\n",
      "Epoch 690/2000\n",
      "45/45 [==============================] - 0s 200us/step - loss: 0.0796 - val_loss: 0.4405\n",
      "Epoch 691/2000\n",
      "45/45 [==============================] - 0s 189us/step - loss: 0.0780 - val_loss: 0.4488\n",
      "Epoch 692/2000\n",
      "45/45 [==============================] - 0s 190us/step - loss: 0.0779 - val_loss: 0.4044\n",
      "Epoch 693/2000\n",
      "45/45 [==============================] - 0s 203us/step - loss: 0.0776 - val_loss: 0.4356\n",
      "Epoch 694/2000\n",
      "45/45 [==============================] - 0s 179us/step - loss: 0.0764 - val_loss: 0.4466\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 695/2000\n",
      "45/45 [==============================] - 0s 204us/step - loss: 0.0767 - val_loss: 0.4432\n",
      "Epoch 696/2000\n",
      "45/45 [==============================] - 0s 184us/step - loss: 0.0755 - val_loss: 0.4115\n",
      "Epoch 697/2000\n",
      "45/45 [==============================] - 0s 202us/step - loss: 0.0743 - val_loss: 0.4137\n",
      "Epoch 698/2000\n",
      "45/45 [==============================] - 0s 206us/step - loss: 0.0736 - val_loss: 0.4132\n",
      "Epoch 699/2000\n",
      "45/45 [==============================] - 0s 192us/step - loss: 0.0726 - val_loss: 0.4015\n",
      "Epoch 700/2000\n",
      "45/45 [==============================] - 0s 196us/step - loss: 0.0721 - val_loss: 0.4144\n",
      "Epoch 701/2000\n",
      "45/45 [==============================] - 0s 179us/step - loss: 0.0723 - val_loss: 0.4302\n",
      "Epoch 702/2000\n",
      "45/45 [==============================] - 0s 183us/step - loss: 0.0711 - val_loss: 0.4034\n",
      "Epoch 703/2000\n",
      "45/45 [==============================] - 0s 174us/step - loss: 0.0696 - val_loss: 0.3743\n",
      "Epoch 704/2000\n",
      "45/45 [==============================] - 0s 184us/step - loss: 0.0699 - val_loss: 0.3994\n",
      "Epoch 705/2000\n",
      "45/45 [==============================] - 0s 203us/step - loss: 0.0680 - val_loss: 0.3884\n",
      "Epoch 706/2000\n",
      "45/45 [==============================] - 0s 178us/step - loss: 0.0677 - val_loss: 0.3749\n",
      "Epoch 707/2000\n",
      "45/45 [==============================] - 0s 212us/step - loss: 0.0680 - val_loss: 0.3556\n",
      "Epoch 708/2000\n",
      "45/45 [==============================] - 0s 173us/step - loss: 0.0670 - val_loss: 0.3705\n",
      "Epoch 709/2000\n",
      "45/45 [==============================] - 0s 204us/step - loss: 0.0662 - val_loss: 0.3852\n",
      "Epoch 710/2000\n",
      "45/45 [==============================] - 0s 178us/step - loss: 0.0652 - val_loss: 0.3653\n",
      "Epoch 711/2000\n",
      "45/45 [==============================] - 0s 194us/step - loss: 0.0648 - val_loss: 0.3780\n",
      "Epoch 712/2000\n",
      "45/45 [==============================] - 0s 189us/step - loss: 0.0634 - val_loss: 0.3565\n",
      "Epoch 713/2000\n",
      "45/45 [==============================] - 0s 178us/step - loss: 0.0631 - val_loss: 0.3404\n",
      "Epoch 714/2000\n",
      "45/45 [==============================] - 0s 184us/step - loss: 0.0625 - val_loss: 0.3329\n",
      "Epoch 715/2000\n",
      "45/45 [==============================] - 0s 181us/step - loss: 0.0621 - val_loss: 0.3228\n",
      "Epoch 716/2000\n",
      "45/45 [==============================] - 0s 198us/step - loss: 0.0611 - val_loss: 0.3309\n",
      "Epoch 717/2000\n",
      "45/45 [==============================] - 0s 182us/step - loss: 0.0606 - val_loss: 0.3628\n",
      "Epoch 718/2000\n",
      "45/45 [==============================] - 0s 183us/step - loss: 0.0593 - val_loss: 0.3592\n",
      "Epoch 719/2000\n",
      "45/45 [==============================] - 0s 177us/step - loss: 0.0592 - val_loss: 0.3550\n",
      "Epoch 720/2000\n",
      "45/45 [==============================] - 0s 178us/step - loss: 0.0581 - val_loss: 0.3552\n",
      "Epoch 721/2000\n",
      "45/45 [==============================] - 0s 158us/step - loss: 0.0575 - val_loss: 0.3531\n",
      "Epoch 722/2000\n",
      "45/45 [==============================] - 0s 172us/step - loss: 0.0573 - val_loss: 0.3475\n",
      "Epoch 723/2000\n",
      "45/45 [==============================] - 0s 158us/step - loss: 0.0571 - val_loss: 0.3460\n",
      "Epoch 724/2000\n",
      "45/45 [==============================] - 0s 174us/step - loss: 0.0565 - val_loss: 0.3530\n",
      "Epoch 725/2000\n",
      "45/45 [==============================] - 0s 169us/step - loss: 0.0552 - val_loss: 0.3566\n",
      "Epoch 726/2000\n",
      "45/45 [==============================] - 0s 193us/step - loss: 0.0548 - val_loss: 0.3422\n",
      "Epoch 727/2000\n",
      "45/45 [==============================] - 0s 182us/step - loss: 0.0545 - val_loss: 0.3281\n",
      "Epoch 728/2000\n",
      "45/45 [==============================] - 0s 179us/step - loss: 0.0543 - val_loss: 0.3369\n",
      "Epoch 729/2000\n",
      "45/45 [==============================] - 0s 173us/step - loss: 0.0535 - val_loss: 0.3573\n",
      "Epoch 730/2000\n",
      "45/45 [==============================] - 0s 169us/step - loss: 0.0527 - val_loss: 0.3429\n",
      "Epoch 731/2000\n",
      "45/45 [==============================] - 0s 172us/step - loss: 0.0525 - val_loss: 0.3265\n",
      "Epoch 732/2000\n",
      "45/45 [==============================] - 0s 166us/step - loss: 0.0516 - val_loss: 0.3230\n",
      "Epoch 733/2000\n",
      "45/45 [==============================] - 0s 180us/step - loss: 0.0507 - val_loss: 0.3213\n",
      "Epoch 734/2000\n",
      "45/45 [==============================] - 0s 169us/step - loss: 0.0522 - val_loss: 0.3071\n",
      "Epoch 735/2000\n",
      "45/45 [==============================] - 0s 196us/step - loss: 0.0497 - val_loss: 0.3100\n",
      "Epoch 736/2000\n",
      "45/45 [==============================] - 0s 171us/step - loss: 0.0499 - val_loss: 0.3153\n",
      "Epoch 737/2000\n",
      "45/45 [==============================] - 0s 185us/step - loss: 0.0483 - val_loss: 0.3207\n",
      "Epoch 738/2000\n",
      "45/45 [==============================] - 0s 190us/step - loss: 0.0480 - val_loss: 0.3037\n",
      "Epoch 739/2000\n",
      "45/45 [==============================] - 0s 199us/step - loss: 0.0474 - val_loss: 0.3066\n",
      "Epoch 740/2000\n",
      "45/45 [==============================] - 0s 191us/step - loss: 0.0472 - val_loss: 0.3125\n",
      "Epoch 741/2000\n",
      "45/45 [==============================] - 0s 209us/step - loss: 0.0465 - val_loss: 0.3001\n",
      "Epoch 742/2000\n",
      "45/45 [==============================] - 0s 221us/step - loss: 0.0459 - val_loss: 0.3017\n",
      "Epoch 743/2000\n",
      "45/45 [==============================] - 0s 246us/step - loss: 0.0457 - val_loss: 0.3064\n",
      "Epoch 744/2000\n",
      "45/45 [==============================] - 0s 247us/step - loss: 0.0451 - val_loss: 0.3065\n",
      "Epoch 745/2000\n",
      "45/45 [==============================] - 0s 231us/step - loss: 0.0450 - val_loss: 0.3103\n",
      "Epoch 746/2000\n",
      "45/45 [==============================] - 0s 214us/step - loss: 0.0446 - val_loss: 0.3141\n",
      "Epoch 747/2000\n",
      "45/45 [==============================] - 0s 238us/step - loss: 0.0438 - val_loss: 0.3056\n",
      "Epoch 748/2000\n",
      "45/45 [==============================] - 0s 217us/step - loss: 0.0435 - val_loss: 0.2904\n",
      "Epoch 749/2000\n",
      "45/45 [==============================] - 0s 221us/step - loss: 0.0428 - val_loss: 0.2908\n",
      "Epoch 750/2000\n",
      "45/45 [==============================] - 0s 243us/step - loss: 0.0425 - val_loss: 0.2751\n",
      "Epoch 751/2000\n",
      "45/45 [==============================] - 0s 223us/step - loss: 0.0421 - val_loss: 0.2763\n",
      "Epoch 752/2000\n",
      "45/45 [==============================] - 0s 229us/step - loss: 0.0416 - val_loss: 0.2839\n",
      "Epoch 753/2000\n",
      "45/45 [==============================] - 0s 245us/step - loss: 0.0413 - val_loss: 0.2767\n",
      "Epoch 754/2000\n",
      "45/45 [==============================] - 0s 233us/step - loss: 0.0408 - val_loss: 0.2788\n",
      "Epoch 755/2000\n",
      "45/45 [==============================] - 0s 208us/step - loss: 0.0401 - val_loss: 0.2782\n",
      "Epoch 756/2000\n",
      "45/45 [==============================] - 0s 228us/step - loss: 0.0400 - val_loss: 0.2631\n",
      "Epoch 757/2000\n",
      "45/45 [==============================] - 0s 204us/step - loss: 0.0404 - val_loss: 0.2490\n",
      "Epoch 758/2000\n",
      "45/45 [==============================] - 0s 220us/step - loss: 0.0394 - val_loss: 0.2649\n",
      "Epoch 759/2000\n",
      "45/45 [==============================] - 0s 248us/step - loss: 0.0384 - val_loss: 0.2541\n",
      "Epoch 760/2000\n",
      "45/45 [==============================] - 0s 228us/step - loss: 0.0386 - val_loss: 0.2518\n",
      "Epoch 761/2000\n",
      "45/45 [==============================] - 0s 214us/step - loss: 0.0379 - val_loss: 0.2572\n",
      "Epoch 762/2000\n",
      "45/45 [==============================] - 0s 229us/step - loss: 0.0375 - val_loss: 0.2535\n",
      "Epoch 763/2000\n",
      "45/45 [==============================] - 0s 209us/step - loss: 0.0367 - val_loss: 0.2473\n",
      "Epoch 764/2000\n",
      "45/45 [==============================] - 0s 180us/step - loss: 0.0367 - val_loss: 0.2440\n",
      "Epoch 765/2000\n",
      "45/45 [==============================] - 0s 196us/step - loss: 0.0367 - val_loss: 0.2302\n",
      "Epoch 766/2000\n",
      "45/45 [==============================] - 0s 181us/step - loss: 0.0361 - val_loss: 0.2452\n",
      "Epoch 767/2000\n",
      "45/45 [==============================] - 0s 213us/step - loss: 0.0354 - val_loss: 0.2492\n",
      "Epoch 768/2000\n",
      "45/45 [==============================] - 0s 184us/step - loss: 0.0346 - val_loss: 0.2543\n",
      "Epoch 769/2000\n",
      "45/45 [==============================] - 0s 213us/step - loss: 0.0346 - val_loss: 0.2501\n",
      "Epoch 770/2000\n",
      "45/45 [==============================] - 0s 190us/step - loss: 0.0343 - val_loss: 0.2401\n",
      "Epoch 771/2000\n",
      "45/45 [==============================] - 0s 217us/step - loss: 0.0342 - val_loss: 0.2416\n",
      "Epoch 772/2000\n",
      "45/45 [==============================] - 0s 206us/step - loss: 0.0348 - val_loss: 0.2399\n",
      "Epoch 773/2000\n",
      "45/45 [==============================] - 0s 186us/step - loss: 0.0331 - val_loss: 0.2388\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 774/2000\n",
      "45/45 [==============================] - 0s 185us/step - loss: 0.0330 - val_loss: 0.2404\n",
      "Epoch 775/2000\n",
      "45/45 [==============================] - 0s 173us/step - loss: 0.0323 - val_loss: 0.2479\n",
      "Epoch 776/2000\n",
      "45/45 [==============================] - 0s 196us/step - loss: 0.0321 - val_loss: 0.2488\n",
      "Epoch 777/2000\n",
      "45/45 [==============================] - 0s 203us/step - loss: 0.0316 - val_loss: 0.2390\n",
      "Epoch 778/2000\n",
      "45/45 [==============================] - 0s 203us/step - loss: 0.0313 - val_loss: 0.2391\n",
      "Epoch 779/2000\n",
      "45/45 [==============================] - 0s 194us/step - loss: 0.0310 - val_loss: 0.2306\n",
      "Epoch 780/2000\n",
      "45/45 [==============================] - 0s 182us/step - loss: 0.0307 - val_loss: 0.2359\n",
      "Epoch 781/2000\n",
      "45/45 [==============================] - 0s 193us/step - loss: 0.0306 - val_loss: 0.2249\n",
      "Epoch 782/2000\n",
      "45/45 [==============================] - 0s 192us/step - loss: 0.0301 - val_loss: 0.2259\n",
      "Epoch 783/2000\n",
      "45/45 [==============================] - 0s 194us/step - loss: 0.0298 - val_loss: 0.2316\n",
      "Epoch 784/2000\n",
      "45/45 [==============================] - 0s 197us/step - loss: 0.0295 - val_loss: 0.2303\n",
      "Epoch 785/2000\n",
      "45/45 [==============================] - 0s 196us/step - loss: 0.0292 - val_loss: 0.2337\n",
      "Epoch 786/2000\n",
      "45/45 [==============================] - 0s 203us/step - loss: 0.0291 - val_loss: 0.2346\n",
      "Epoch 787/2000\n",
      "45/45 [==============================] - 0s 186us/step - loss: 0.0283 - val_loss: 0.2248\n",
      "Epoch 788/2000\n",
      "45/45 [==============================] - 0s 198us/step - loss: 0.0284 - val_loss: 0.2350\n",
      "Epoch 789/2000\n",
      "45/45 [==============================] - 0s 195us/step - loss: 0.0282 - val_loss: 0.2193\n",
      "Epoch 790/2000\n",
      "45/45 [==============================] - 0s 192us/step - loss: 0.0275 - val_loss: 0.2055\n",
      "Epoch 791/2000\n",
      "45/45 [==============================] - 0s 201us/step - loss: 0.0276 - val_loss: 0.2089\n",
      "Epoch 792/2000\n",
      "45/45 [==============================] - 0s 183us/step - loss: 0.0271 - val_loss: 0.2082\n",
      "Epoch 793/2000\n",
      "45/45 [==============================] - 0s 179us/step - loss: 0.0272 - val_loss: 0.2000\n",
      "Epoch 794/2000\n",
      "45/45 [==============================] - 0s 169us/step - loss: 0.0273 - val_loss: 0.2106\n",
      "Epoch 795/2000\n",
      "45/45 [==============================] - 0s 169us/step - loss: 0.0260 - val_loss: 0.2139\n",
      "Epoch 796/2000\n",
      "45/45 [==============================] - 0s 161us/step - loss: 0.0258 - val_loss: 0.2102\n",
      "Epoch 797/2000\n",
      "45/45 [==============================] - 0s 206us/step - loss: 0.0256 - val_loss: 0.2033\n",
      "Epoch 798/2000\n",
      "45/45 [==============================] - 0s 196us/step - loss: 0.0256 - val_loss: 0.1921\n",
      "Epoch 799/2000\n",
      "45/45 [==============================] - 0s 211us/step - loss: 0.0251 - val_loss: 0.1929\n",
      "Epoch 800/2000\n",
      "45/45 [==============================] - 0s 214us/step - loss: 0.0250 - val_loss: 0.1994\n",
      "Epoch 801/2000\n",
      "45/45 [==============================] - 0s 193us/step - loss: 0.0246 - val_loss: 0.2023\n",
      "Epoch 802/2000\n",
      "45/45 [==============================] - 0s 203us/step - loss: 0.0242 - val_loss: 0.2013\n",
      "Epoch 803/2000\n",
      "45/45 [==============================] - 0s 183us/step - loss: 0.0239 - val_loss: 0.1987\n",
      "Epoch 804/2000\n",
      "45/45 [==============================] - 0s 202us/step - loss: 0.0239 - val_loss: 0.1976\n",
      "Epoch 805/2000\n",
      "45/45 [==============================] - 0s 201us/step - loss: 0.0233 - val_loss: 0.1959\n",
      "Epoch 806/2000\n",
      "45/45 [==============================] - 0s 201us/step - loss: 0.0232 - val_loss: 0.1911\n",
      "Epoch 807/2000\n",
      "45/45 [==============================] - 0s 210us/step - loss: 0.0228 - val_loss: 0.1872\n",
      "Epoch 808/2000\n",
      "45/45 [==============================] - 0s 179us/step - loss: 0.0229 - val_loss: 0.1832\n",
      "Epoch 809/2000\n",
      "45/45 [==============================] - 0s 207us/step - loss: 0.0229 - val_loss: 0.1856\n",
      "Epoch 810/2000\n",
      "45/45 [==============================] - 0s 196us/step - loss: 0.0225 - val_loss: 0.1882\n",
      "Epoch 811/2000\n",
      "45/45 [==============================] - 0s 202us/step - loss: 0.0227 - val_loss: 0.1880\n",
      "Epoch 812/2000\n",
      "45/45 [==============================] - 0s 194us/step - loss: 0.0225 - val_loss: 0.1845\n",
      "Epoch 813/2000\n",
      "45/45 [==============================] - 0s 196us/step - loss: 0.0218 - val_loss: 0.1853\n",
      "Epoch 814/2000\n",
      "45/45 [==============================] - 0s 211us/step - loss: 0.0215 - val_loss: 0.1787\n",
      "Epoch 815/2000\n",
      "45/45 [==============================] - 0s 182us/step - loss: 0.0211 - val_loss: 0.1822\n",
      "Epoch 816/2000\n",
      "45/45 [==============================] - 0s 195us/step - loss: 0.0213 - val_loss: 0.1682\n",
      "Epoch 817/2000\n",
      "45/45 [==============================] - 0s 186us/step - loss: 0.0208 - val_loss: 0.1661\n",
      "Epoch 818/2000\n",
      "45/45 [==============================] - 0s 172us/step - loss: 0.0205 - val_loss: 0.1716\n",
      "Epoch 819/2000\n",
      "45/45 [==============================] - 0s 195us/step - loss: 0.0206 - val_loss: 0.1728\n",
      "Epoch 820/2000\n",
      "45/45 [==============================] - 0s 187us/step - loss: 0.0201 - val_loss: 0.1772\n",
      "Epoch 821/2000\n",
      "45/45 [==============================] - 0s 209us/step - loss: 0.0198 - val_loss: 0.1765\n",
      "Epoch 822/2000\n",
      "45/45 [==============================] - 0s 190us/step - loss: 0.0198 - val_loss: 0.1732\n",
      "Epoch 823/2000\n",
      "45/45 [==============================] - 0s 214us/step - loss: 0.0198 - val_loss: 0.1701\n",
      "Epoch 824/2000\n",
      "45/45 [==============================] - 0s 215us/step - loss: 0.0192 - val_loss: 0.1649\n",
      "Epoch 825/2000\n",
      "45/45 [==============================] - 0s 201us/step - loss: 0.0190 - val_loss: 0.1682\n",
      "Epoch 826/2000\n",
      "45/45 [==============================] - 0s 218us/step - loss: 0.0190 - val_loss: 0.1584\n",
      "Epoch 827/2000\n",
      "45/45 [==============================] - 0s 205us/step - loss: 0.0186 - val_loss: 0.1593\n",
      "Epoch 828/2000\n",
      "45/45 [==============================] - 0s 186us/step - loss: 0.0186 - val_loss: 0.1628\n",
      "Epoch 829/2000\n",
      "45/45 [==============================] - 0s 200us/step - loss: 0.0186 - val_loss: 0.1589\n",
      "Epoch 830/2000\n",
      "45/45 [==============================] - 0s 188us/step - loss: 0.0183 - val_loss: 0.1527\n",
      "Epoch 831/2000\n",
      "45/45 [==============================] - 0s 213us/step - loss: 0.0179 - val_loss: 0.1509\n",
      "Epoch 832/2000\n",
      "45/45 [==============================] - 0s 181us/step - loss: 0.0179 - val_loss: 0.1522\n",
      "Epoch 833/2000\n",
      "45/45 [==============================] - 0s 210us/step - loss: 0.0177 - val_loss: 0.1559\n",
      "Epoch 834/2000\n",
      "45/45 [==============================] - 0s 206us/step - loss: 0.0175 - val_loss: 0.1514\n",
      "Epoch 835/2000\n",
      "45/45 [==============================] - 0s 188us/step - loss: 0.0171 - val_loss: 0.1513\n",
      "Epoch 836/2000\n",
      "45/45 [==============================] - 0s 206us/step - loss: 0.0170 - val_loss: 0.1539\n",
      "Epoch 837/2000\n",
      "45/45 [==============================] - 0s 201us/step - loss: 0.0169 - val_loss: 0.1539\n",
      "Epoch 838/2000\n",
      "45/45 [==============================] - 0s 209us/step - loss: 0.0168 - val_loss: 0.1558\n",
      "Epoch 839/2000\n",
      "45/45 [==============================] - 0s 195us/step - loss: 0.0165 - val_loss: 0.1508\n",
      "Epoch 840/2000\n",
      "45/45 [==============================] - 0s 186us/step - loss: 0.0166 - val_loss: 0.1466\n",
      "Epoch 841/2000\n",
      "45/45 [==============================] - 0s 194us/step - loss: 0.0165 - val_loss: 0.1517\n",
      "Epoch 842/2000\n",
      "45/45 [==============================] - 0s 174us/step - loss: 0.0161 - val_loss: 0.1398\n",
      "Epoch 843/2000\n",
      "45/45 [==============================] - 0s 182us/step - loss: 0.0159 - val_loss: 0.1465\n",
      "Epoch 844/2000\n",
      "45/45 [==============================] - 0s 160us/step - loss: 0.0159 - val_loss: 0.1428\n",
      "Epoch 845/2000\n",
      "45/45 [==============================] - 0s 170us/step - loss: 0.0157 - val_loss: 0.1395\n",
      "Epoch 846/2000\n",
      "45/45 [==============================] - 0s 157us/step - loss: 0.0155 - val_loss: 0.1355\n",
      "Epoch 847/2000\n",
      "45/45 [==============================] - 0s 194us/step - loss: 0.0154 - val_loss: 0.1374\n",
      "Epoch 848/2000\n",
      "45/45 [==============================] - 0s 175us/step - loss: 0.0156 - val_loss: 0.1392\n",
      "Epoch 849/2000\n",
      "45/45 [==============================] - 0s 202us/step - loss: 0.0149 - val_loss: 0.1397\n",
      "Epoch 850/2000\n",
      "45/45 [==============================] - 0s 184us/step - loss: 0.0148 - val_loss: 0.1375\n",
      "Epoch 851/2000\n",
      "45/45 [==============================] - 0s 201us/step - loss: 0.0147 - val_loss: 0.1348\n",
      "Epoch 852/2000\n",
      "45/45 [==============================] - 0s 177us/step - loss: 0.0147 - val_loss: 0.1332\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 853/2000\n",
      "45/45 [==============================] - 0s 196us/step - loss: 0.0145 - val_loss: 0.1375\n",
      "Epoch 854/2000\n",
      "45/45 [==============================] - 0s 190us/step - loss: 0.0143 - val_loss: 0.1307\n",
      "Epoch 855/2000\n",
      "45/45 [==============================] - 0s 176us/step - loss: 0.0143 - val_loss: 0.1373\n",
      "Epoch 856/2000\n",
      "45/45 [==============================] - 0s 186us/step - loss: 0.0143 - val_loss: 0.1420\n",
      "Epoch 857/2000\n",
      "45/45 [==============================] - 0s 178us/step - loss: 0.0142 - val_loss: 0.1427\n",
      "Epoch 858/2000\n",
      "45/45 [==============================] - 0s 191us/step - loss: 0.0139 - val_loss: 0.1339\n",
      "Epoch 859/2000\n",
      "45/45 [==============================] - 0s 183us/step - loss: 0.0143 - val_loss: 0.1301\n",
      "Epoch 860/2000\n",
      "45/45 [==============================] - 0s 196us/step - loss: 0.0138 - val_loss: 0.1262\n",
      "Epoch 861/2000\n",
      "45/45 [==============================] - 0s 193us/step - loss: 0.0135 - val_loss: 0.1282\n",
      "Epoch 862/2000\n",
      "45/45 [==============================] - 0s 198us/step - loss: 0.0134 - val_loss: 0.1328\n",
      "Epoch 863/2000\n",
      "45/45 [==============================] - 0s 190us/step - loss: 0.0131 - val_loss: 0.1276\n",
      "Epoch 864/2000\n",
      "45/45 [==============================] - 0s 173us/step - loss: 0.0131 - val_loss: 0.1307\n",
      "Epoch 865/2000\n",
      "45/45 [==============================] - 0s 194us/step - loss: 0.0130 - val_loss: 0.1221\n",
      "Epoch 866/2000\n",
      "45/45 [==============================] - 0s 169us/step - loss: 0.0129 - val_loss: 0.1235\n",
      "Epoch 867/2000\n",
      "45/45 [==============================] - 0s 176us/step - loss: 0.0127 - val_loss: 0.1215\n",
      "Epoch 868/2000\n",
      "45/45 [==============================] - 0s 170us/step - loss: 0.0126 - val_loss: 0.1221\n",
      "Epoch 869/2000\n",
      "45/45 [==============================] - 0s 183us/step - loss: 0.0124 - val_loss: 0.1219\n",
      "Epoch 870/2000\n",
      "45/45 [==============================] - 0s 190us/step - loss: 0.0124 - val_loss: 0.1286\n",
      "Epoch 871/2000\n",
      "45/45 [==============================] - 0s 169us/step - loss: 0.0126 - val_loss: 0.1265\n",
      "Epoch 872/2000\n",
      "45/45 [==============================] - 0s 183us/step - loss: 0.0123 - val_loss: 0.1232\n",
      "Epoch 873/2000\n",
      "45/45 [==============================] - 0s 169us/step - loss: 0.0121 - val_loss: 0.1220\n",
      "Epoch 874/2000\n",
      "45/45 [==============================] - 0s 176us/step - loss: 0.0120 - val_loss: 0.1187\n",
      "Epoch 875/2000\n",
      "45/45 [==============================] - 0s 154us/step - loss: 0.0124 - val_loss: 0.1185\n",
      "Epoch 876/2000\n",
      "45/45 [==============================] - 0s 163us/step - loss: 0.0117 - val_loss: 0.1151\n",
      "Epoch 877/2000\n",
      "45/45 [==============================] - 0s 158us/step - loss: 0.0116 - val_loss: 0.1097\n",
      "Epoch 878/2000\n",
      "45/45 [==============================] - 0s 161us/step - loss: 0.0118 - val_loss: 0.1159\n",
      "Epoch 879/2000\n",
      "45/45 [==============================] - 0s 162us/step - loss: 0.0115 - val_loss: 0.1184\n",
      "Epoch 880/2000\n",
      "45/45 [==============================] - 0s 156us/step - loss: 0.0114 - val_loss: 0.1195\n",
      "Epoch 881/2000\n",
      "45/45 [==============================] - 0s 167us/step - loss: 0.0112 - val_loss: 0.1157\n",
      "Epoch 882/2000\n",
      "45/45 [==============================] - 0s 156us/step - loss: 0.0112 - val_loss: 0.1163\n",
      "Epoch 883/2000\n",
      "45/45 [==============================] - 0s 166us/step - loss: 0.0112 - val_loss: 0.1114\n",
      "Epoch 884/2000\n",
      "45/45 [==============================] - 0s 153us/step - loss: 0.0110 - val_loss: 0.1078\n",
      "Epoch 885/2000\n",
      "45/45 [==============================] - 0s 172us/step - loss: 0.0109 - val_loss: 0.1131\n",
      "Epoch 886/2000\n",
      "45/45 [==============================] - 0s 162us/step - loss: 0.0107 - val_loss: 0.1125\n",
      "Epoch 887/2000\n",
      "45/45 [==============================] - 0s 179us/step - loss: 0.0108 - val_loss: 0.1159\n",
      "Epoch 888/2000\n",
      "45/45 [==============================] - 0s 151us/step - loss: 0.0108 - val_loss: 0.1131\n",
      "Epoch 889/2000\n",
      "45/45 [==============================] - 0s 171us/step - loss: 0.0106 - val_loss: 0.1121\n",
      "Epoch 890/2000\n",
      "45/45 [==============================] - 0s 153us/step - loss: 0.0106 - val_loss: 0.1058\n",
      "Epoch 891/2000\n",
      "45/45 [==============================] - 0s 164us/step - loss: 0.0104 - val_loss: 0.1035\n",
      "Epoch 892/2000\n",
      "45/45 [==============================] - 0s 142us/step - loss: 0.0103 - val_loss: 0.1066\n",
      "Epoch 893/2000\n",
      "45/45 [==============================] - 0s 170us/step - loss: 0.0101 - val_loss: 0.1054\n",
      "Epoch 894/2000\n",
      "45/45 [==============================] - 0s 147us/step - loss: 0.0101 - val_loss: 0.1035\n",
      "Epoch 895/2000\n",
      "45/45 [==============================] - 0s 160us/step - loss: 0.0103 - val_loss: 0.1018\n",
      "Epoch 896/2000\n",
      "45/45 [==============================] - 0s 163us/step - loss: 0.0100 - val_loss: 0.1053\n",
      "Epoch 897/2000\n",
      "45/45 [==============================] - 0s 153us/step - loss: 0.0099 - val_loss: 0.1004\n",
      "Epoch 898/2000\n",
      "45/45 [==============================] - 0s 164us/step - loss: 0.0098 - val_loss: 0.0978\n",
      "Epoch 899/2000\n",
      "45/45 [==============================] - 0s 152us/step - loss: 0.0097 - val_loss: 0.0978\n",
      "Epoch 900/2000\n",
      "45/45 [==============================] - 0s 164us/step - loss: 0.0099 - val_loss: 0.0974\n",
      "Epoch 901/2000\n",
      "45/45 [==============================] - 0s 143us/step - loss: 0.0098 - val_loss: 0.0913\n",
      "Epoch 902/2000\n",
      "45/45 [==============================] - 0s 171us/step - loss: 0.0096 - val_loss: 0.0984\n",
      "Epoch 903/2000\n",
      "45/45 [==============================] - 0s 150us/step - loss: 0.0095 - val_loss: 0.0946\n",
      "Epoch 904/2000\n",
      "45/45 [==============================] - 0s 162us/step - loss: 0.0095 - val_loss: 0.0956\n",
      "Epoch 905/2000\n",
      "45/45 [==============================] - 0s 148us/step - loss: 0.0092 - val_loss: 0.0949\n",
      "Epoch 906/2000\n",
      "45/45 [==============================] - 0s 168us/step - loss: 0.0093 - val_loss: 0.0922\n",
      "Epoch 907/2000\n",
      "45/45 [==============================] - 0s 154us/step - loss: 0.0091 - val_loss: 0.0941\n",
      "Epoch 908/2000\n",
      "45/45 [==============================] - 0s 161us/step - loss: 0.0090 - val_loss: 0.0938\n",
      "Epoch 909/2000\n",
      "45/45 [==============================] - 0s 152us/step - loss: 0.0090 - val_loss: 0.0894\n",
      "Epoch 910/2000\n",
      "45/45 [==============================] - 0s 154us/step - loss: 0.0090 - val_loss: 0.0938\n",
      "Epoch 911/2000\n",
      "45/45 [==============================] - 0s 160us/step - loss: 0.0089 - val_loss: 0.0980\n",
      "Epoch 912/2000\n",
      "45/45 [==============================] - 0s 152us/step - loss: 0.0088 - val_loss: 0.0923\n",
      "Epoch 913/2000\n",
      "45/45 [==============================] - 0s 175us/step - loss: 0.0087 - val_loss: 0.0909\n",
      "Epoch 914/2000\n",
      "45/45 [==============================] - 0s 163us/step - loss: 0.0087 - val_loss: 0.0920\n",
      "Epoch 915/2000\n",
      "45/45 [==============================] - 0s 174us/step - loss: 0.0086 - val_loss: 0.0882\n",
      "Epoch 916/2000\n",
      "45/45 [==============================] - 0s 152us/step - loss: 0.0085 - val_loss: 0.0882\n",
      "Epoch 917/2000\n",
      "45/45 [==============================] - 0s 167us/step - loss: 0.0085 - val_loss: 0.0879\n",
      "Epoch 918/2000\n",
      "45/45 [==============================] - 0s 151us/step - loss: 0.0084 - val_loss: 0.0899\n",
      "Epoch 919/2000\n",
      "45/45 [==============================] - 0s 173us/step - loss: 0.0083 - val_loss: 0.0868\n",
      "Epoch 920/2000\n",
      "45/45 [==============================] - 0s 152us/step - loss: 0.0083 - val_loss: 0.0862\n",
      "Epoch 921/2000\n",
      "45/45 [==============================] - 0s 167us/step - loss: 0.0082 - val_loss: 0.0858\n",
      "Epoch 922/2000\n",
      "45/45 [==============================] - 0s 147us/step - loss: 0.0082 - val_loss: 0.0877\n",
      "Epoch 923/2000\n",
      "45/45 [==============================] - 0s 162us/step - loss: 0.0082 - val_loss: 0.0901\n",
      "Epoch 924/2000\n",
      "45/45 [==============================] - 0s 151us/step - loss: 0.0082 - val_loss: 0.0882\n",
      "Epoch 925/2000\n",
      "45/45 [==============================] - 0s 157us/step - loss: 0.0080 - val_loss: 0.0878\n",
      "Epoch 926/2000\n",
      "45/45 [==============================] - 0s 157us/step - loss: 0.0080 - val_loss: 0.0884\n",
      "Epoch 927/2000\n",
      "45/45 [==============================] - 0s 147us/step - loss: 0.0079 - val_loss: 0.0849\n",
      "Epoch 928/2000\n",
      "45/45 [==============================] - 0s 158us/step - loss: 0.0079 - val_loss: 0.0863\n",
      "Epoch 929/2000\n",
      "45/45 [==============================] - 0s 152us/step - loss: 0.0079 - val_loss: 0.0863\n",
      "Epoch 930/2000\n",
      "45/45 [==============================] - 0s 173us/step - loss: 0.0078 - val_loss: 0.0834\n",
      "Epoch 931/2000\n",
      "45/45 [==============================] - 0s 152us/step - loss: 0.0077 - val_loss: 0.0852\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 932/2000\n",
      "45/45 [==============================] - 0s 168us/step - loss: 0.0077 - val_loss: 0.0798\n",
      "Epoch 933/2000\n",
      "45/45 [==============================] - 0s 152us/step - loss: 0.0076 - val_loss: 0.0815\n",
      "Epoch 934/2000\n",
      "45/45 [==============================] - 0s 171us/step - loss: 0.0076 - val_loss: 0.0774\n",
      "Epoch 935/2000\n",
      "45/45 [==============================] - 0s 144us/step - loss: 0.0075 - val_loss: 0.0789\n",
      "Epoch 936/2000\n",
      "45/45 [==============================] - 0s 172us/step - loss: 0.0074 - val_loss: 0.0831\n",
      "Epoch 937/2000\n",
      "45/45 [==============================] - 0s 148us/step - loss: 0.0075 - val_loss: 0.0798\n",
      "Epoch 938/2000\n",
      "45/45 [==============================] - 0s 170us/step - loss: 0.0075 - val_loss: 0.0747\n",
      "Epoch 939/2000\n",
      "45/45 [==============================] - 0s 141us/step - loss: 0.0076 - val_loss: 0.0689\n",
      "Epoch 940/2000\n",
      "45/45 [==============================] - 0s 188us/step - loss: 0.0075 - val_loss: 0.0701\n",
      "Epoch 941/2000\n",
      "45/45 [==============================] - 0s 200us/step - loss: 0.0073 - val_loss: 0.0733\n",
      "Epoch 942/2000\n",
      "45/45 [==============================] - 0s 207us/step - loss: 0.0073 - val_loss: 0.0749\n",
      "Epoch 943/2000\n",
      "45/45 [==============================] - 0s 171us/step - loss: 0.0072 - val_loss: 0.0761\n",
      "Epoch 944/2000\n",
      "45/45 [==============================] - 0s 187us/step - loss: 0.0070 - val_loss: 0.0745\n",
      "Epoch 945/2000\n",
      "45/45 [==============================] - 0s 158us/step - loss: 0.0070 - val_loss: 0.0747\n",
      "Epoch 946/2000\n",
      "45/45 [==============================] - 0s 167us/step - loss: 0.0071 - val_loss: 0.0752\n",
      "Epoch 947/2000\n",
      "45/45 [==============================] - 0s 149us/step - loss: 0.0070 - val_loss: 0.0745\n",
      "Epoch 948/2000\n",
      "45/45 [==============================] - 0s 179us/step - loss: 0.0072 - val_loss: 0.0655\n",
      "Epoch 949/2000\n",
      "45/45 [==============================] - 0s 150us/step - loss: 0.0071 - val_loss: 0.0715\n",
      "Epoch 950/2000\n",
      "45/45 [==============================] - 0s 175us/step - loss: 0.0069 - val_loss: 0.0684\n",
      "Epoch 951/2000\n",
      "45/45 [==============================] - 0s 148us/step - loss: 0.0068 - val_loss: 0.0692\n",
      "Epoch 952/2000\n",
      "45/45 [==============================] - 0s 177us/step - loss: 0.0068 - val_loss: 0.0739\n",
      "Epoch 953/2000\n",
      "45/45 [==============================] - 0s 145us/step - loss: 0.0068 - val_loss: 0.0744\n",
      "Epoch 954/2000\n",
      "45/45 [==============================] - 0s 167us/step - loss: 0.0066 - val_loss: 0.0730\n",
      "Epoch 955/2000\n",
      "45/45 [==============================] - 0s 143us/step - loss: 0.0067 - val_loss: 0.0710\n",
      "Epoch 956/2000\n",
      "45/45 [==============================] - 0s 158us/step - loss: 0.0066 - val_loss: 0.0715\n",
      "Epoch 957/2000\n",
      "45/45 [==============================] - 0s 157us/step - loss: 0.0067 - val_loss: 0.0685\n",
      "Epoch 958/2000\n",
      "45/45 [==============================] - 0s 146us/step - loss: 0.0066 - val_loss: 0.0692\n",
      "Epoch 959/2000\n",
      "45/45 [==============================] - 0s 164us/step - loss: 0.0065 - val_loss: 0.0694\n",
      "Epoch 960/2000\n",
      "45/45 [==============================] - 0s 149us/step - loss: 0.0065 - val_loss: 0.0665\n",
      "Epoch 961/2000\n",
      "45/45 [==============================] - 0s 163us/step - loss: 0.0064 - val_loss: 0.0671\n",
      "Epoch 962/2000\n",
      "45/45 [==============================] - 0s 136us/step - loss: 0.0064 - val_loss: 0.0670\n",
      "Epoch 963/2000\n",
      "45/45 [==============================] - 0s 159us/step - loss: 0.0065 - val_loss: 0.0674\n",
      "Epoch 964/2000\n",
      "45/45 [==============================] - 0s 151us/step - loss: 0.0064 - val_loss: 0.0707\n",
      "Epoch 965/2000\n",
      "45/45 [==============================] - 0s 157us/step - loss: 0.0063 - val_loss: 0.0697\n",
      "Epoch 966/2000\n",
      "45/45 [==============================] - 0s 160us/step - loss: 0.0062 - val_loss: 0.0676\n",
      "Epoch 967/2000\n",
      "45/45 [==============================] - 0s 160us/step - loss: 0.0062 - val_loss: 0.0659\n",
      "Epoch 968/2000\n",
      "45/45 [==============================] - 0s 156us/step - loss: 0.0062 - val_loss: 0.0672\n",
      "Epoch 969/2000\n",
      "45/45 [==============================] - 0s 147us/step - loss: 0.0062 - val_loss: 0.0681\n",
      "Epoch 970/2000\n",
      "45/45 [==============================] - 0s 160us/step - loss: 0.0061 - val_loss: 0.0648\n",
      "Epoch 971/2000\n",
      "45/45 [==============================] - 0s 163us/step - loss: 0.0062 - val_loss: 0.0664\n",
      "Epoch 972/2000\n",
      "45/45 [==============================] - 0s 171us/step - loss: 0.0060 - val_loss: 0.0671\n",
      "Epoch 973/2000\n",
      "45/45 [==============================] - 0s 160us/step - loss: 0.0061 - val_loss: 0.0651\n",
      "Epoch 974/2000\n",
      "45/45 [==============================] - 0s 176us/step - loss: 0.0060 - val_loss: 0.0662\n",
      "Epoch 975/2000\n",
      "45/45 [==============================] - 0s 154us/step - loss: 0.0059 - val_loss: 0.0635\n",
      "Epoch 976/2000\n",
      "45/45 [==============================] - 0s 165us/step - loss: 0.0060 - val_loss: 0.0630\n",
      "Epoch 977/2000\n",
      "45/45 [==============================] - 0s 142us/step - loss: 0.0059 - val_loss: 0.0623\n",
      "Epoch 978/2000\n",
      "45/45 [==============================] - 0s 168us/step - loss: 0.0059 - val_loss: 0.0641\n",
      "Epoch 979/2000\n",
      "45/45 [==============================] - 0s 150us/step - loss: 0.0058 - val_loss: 0.0617\n",
      "Epoch 980/2000\n",
      "45/45 [==============================] - 0s 164us/step - loss: 0.0060 - val_loss: 0.0613\n",
      "Epoch 981/2000\n",
      "45/45 [==============================] - 0s 170us/step - loss: 0.0058 - val_loss: 0.0600\n",
      "Epoch 982/2000\n",
      "45/45 [==============================] - 0s 162us/step - loss: 0.0058 - val_loss: 0.0611\n",
      "Epoch 983/2000\n",
      "45/45 [==============================] - 0s 157us/step - loss: 0.0059 - val_loss: 0.0596\n",
      "Epoch 984/2000\n",
      "45/45 [==============================] - 0s 164us/step - loss: 0.0057 - val_loss: 0.0603\n",
      "Epoch 985/2000\n",
      "45/45 [==============================] - 0s 164us/step - loss: 0.0057 - val_loss: 0.0608\n",
      "Epoch 986/2000\n",
      "45/45 [==============================] - 0s 158us/step - loss: 0.0056 - val_loss: 0.0602\n",
      "Epoch 987/2000\n",
      "45/45 [==============================] - 0s 162us/step - loss: 0.0057 - val_loss: 0.0605\n",
      "Epoch 988/2000\n",
      "45/45 [==============================] - 0s 152us/step - loss: 0.0056 - val_loss: 0.0591\n",
      "Epoch 989/2000\n",
      "45/45 [==============================] - 0s 164us/step - loss: 0.0056 - val_loss: 0.0574\n",
      "Epoch 990/2000\n",
      "45/45 [==============================] - 0s 151us/step - loss: 0.0056 - val_loss: 0.0566\n",
      "Epoch 991/2000\n",
      "45/45 [==============================] - 0s 167us/step - loss: 0.0056 - val_loss: 0.0590\n",
      "Epoch 992/2000\n",
      "45/45 [==============================] - 0s 151us/step - loss: 0.0056 - val_loss: 0.0578\n",
      "Epoch 993/2000\n",
      "45/45 [==============================] - 0s 162us/step - loss: 0.0055 - val_loss: 0.0580\n",
      "Epoch 994/2000\n",
      "45/45 [==============================] - 0s 147us/step - loss: 0.0055 - val_loss: 0.0558\n",
      "Epoch 995/2000\n",
      "45/45 [==============================] - 0s 160us/step - loss: 0.0056 - val_loss: 0.0559\n",
      "Epoch 996/2000\n",
      "45/45 [==============================] - 0s 152us/step - loss: 0.0054 - val_loss: 0.0545\n",
      "Epoch 997/2000\n",
      "45/45 [==============================] - 0s 153us/step - loss: 0.0053 - val_loss: 0.0568\n",
      "Epoch 998/2000\n",
      "45/45 [==============================] - 0s 159us/step - loss: 0.0053 - val_loss: 0.0568\n",
      "Epoch 999/2000\n",
      "45/45 [==============================] - 0s 151us/step - loss: 0.0054 - val_loss: 0.0570\n",
      "Epoch 1000/2000\n",
      "45/45 [==============================] - 0s 158us/step - loss: 0.0053 - val_loss: 0.0558\n",
      "Epoch 1001/2000\n",
      "45/45 [==============================] - 0s 146us/step - loss: 0.0053 - val_loss: 0.0568\n",
      "Epoch 1002/2000\n",
      "45/45 [==============================] - 0s 169us/step - loss: 0.0053 - val_loss: 0.0517\n",
      "Epoch 1003/2000\n",
      "45/45 [==============================] - 0s 152us/step - loss: 0.0052 - val_loss: 0.0523\n",
      "Epoch 1004/2000\n",
      "45/45 [==============================] - 0s 170us/step - loss: 0.0052 - val_loss: 0.0514\n",
      "Epoch 1005/2000\n",
      "45/45 [==============================] - 0s 146us/step - loss: 0.0053 - val_loss: 0.0527\n",
      "Epoch 1006/2000\n",
      "45/45 [==============================] - 0s 158us/step - loss: 0.0051 - val_loss: 0.0530\n",
      "Epoch 1007/2000\n",
      "45/45 [==============================] - 0s 171us/step - loss: 0.0052 - val_loss: 0.0559\n",
      "Epoch 1008/2000\n",
      "45/45 [==============================] - 0s 158us/step - loss: 0.0051 - val_loss: 0.0526\n",
      "Epoch 1009/2000\n",
      "45/45 [==============================] - 0s 149us/step - loss: 0.0052 - val_loss: 0.0502\n",
      "Epoch 1010/2000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "45/45 [==============================] - 0s 152us/step - loss: 0.0052 - val_loss: 0.0475\n",
      "Epoch 1011/2000\n",
      "45/45 [==============================] - 0s 171us/step - loss: 0.0052 - val_loss: 0.0460\n",
      "Epoch 1012/2000\n",
      "45/45 [==============================] - 0s 158us/step - loss: 0.0051 - val_loss: 0.0492\n",
      "Epoch 1013/2000\n",
      "45/45 [==============================] - 0s 172us/step - loss: 0.0051 - val_loss: 0.0509\n",
      "Epoch 1014/2000\n",
      "45/45 [==============================] - 0s 166us/step - loss: 0.0050 - val_loss: 0.0525\n",
      "Epoch 1015/2000\n",
      "45/45 [==============================] - 0s 165us/step - loss: 0.0051 - val_loss: 0.0521\n",
      "Epoch 1016/2000\n",
      "45/45 [==============================] - 0s 163us/step - loss: 0.0049 - val_loss: 0.0515\n",
      "Epoch 1017/2000\n",
      "45/45 [==============================] - 0s 167us/step - loss: 0.0050 - val_loss: 0.0523\n",
      "Epoch 1018/2000\n",
      "45/45 [==============================] - 0s 156us/step - loss: 0.0049 - val_loss: 0.0516\n",
      "Epoch 1019/2000\n",
      "45/45 [==============================] - 0s 171us/step - loss: 0.0050 - val_loss: 0.0507\n",
      "Epoch 1020/2000\n",
      "45/45 [==============================] - 0s 152us/step - loss: 0.0048 - val_loss: 0.0506\n",
      "Epoch 1021/2000\n",
      "45/45 [==============================] - 0s 167us/step - loss: 0.0048 - val_loss: 0.0497\n",
      "Epoch 1022/2000\n",
      "45/45 [==============================] - 0s 146us/step - loss: 0.0048 - val_loss: 0.0499\n",
      "Epoch 1023/2000\n",
      "45/45 [==============================] - 0s 173us/step - loss: 0.0048 - val_loss: 0.0509\n",
      "Epoch 1024/2000\n",
      "45/45 [==============================] - 0s 148us/step - loss: 0.0048 - val_loss: 0.0485\n",
      "Epoch 1025/2000\n",
      "45/45 [==============================] - 0s 167us/step - loss: 0.0048 - val_loss: 0.0461\n",
      "Epoch 1026/2000\n",
      "45/45 [==============================] - 0s 148us/step - loss: 0.0048 - val_loss: 0.0474\n",
      "Epoch 1027/2000\n",
      "45/45 [==============================] - 0s 159us/step - loss: 0.0047 - val_loss: 0.0498\n",
      "Epoch 1028/2000\n",
      "45/45 [==============================] - 0s 150us/step - loss: 0.0047 - val_loss: 0.0497\n",
      "Epoch 1029/2000\n",
      "45/45 [==============================] - 0s 155us/step - loss: 0.0048 - val_loss: 0.0485\n",
      "Epoch 1030/2000\n",
      "45/45 [==============================] - 0s 163us/step - loss: 0.0048 - val_loss: 0.0465\n",
      "Epoch 1031/2000\n",
      "45/45 [==============================] - 0s 151us/step - loss: 0.0047 - val_loss: 0.0457\n",
      "Epoch 1032/2000\n",
      "45/45 [==============================] - 0s 162us/step - loss: 0.0047 - val_loss: 0.0467\n",
      "Epoch 1033/2000\n",
      "45/45 [==============================] - 0s 142us/step - loss: 0.0047 - val_loss: 0.0473\n",
      "Epoch 1034/2000\n",
      "45/45 [==============================] - 0s 168us/step - loss: 0.0046 - val_loss: 0.0454\n",
      "Epoch 1035/2000\n",
      "45/45 [==============================] - 0s 146us/step - loss: 0.0046 - val_loss: 0.0463\n",
      "Epoch 1036/2000\n",
      "45/45 [==============================] - 0s 166us/step - loss: 0.0047 - val_loss: 0.0458\n",
      "Epoch 1037/2000\n",
      "45/45 [==============================] - 0s 141us/step - loss: 0.0047 - val_loss: 0.0430\n",
      "Epoch 1038/2000\n",
      "45/45 [==============================] - 0s 152us/step - loss: 0.0046 - val_loss: 0.0421\n",
      "Epoch 1039/2000\n",
      "45/45 [==============================] - 0s 160us/step - loss: 0.0045 - val_loss: 0.0430\n",
      "Epoch 1040/2000\n",
      "45/45 [==============================] - 0s 159us/step - loss: 0.0045 - val_loss: 0.0443\n",
      "Epoch 1041/2000\n",
      "45/45 [==============================] - 0s 160us/step - loss: 0.0046 - val_loss: 0.0428\n",
      "Epoch 1042/2000\n",
      "45/45 [==============================] - 0s 153us/step - loss: 0.0045 - val_loss: 0.0425\n",
      "Epoch 1043/2000\n",
      "45/45 [==============================] - 0s 169us/step - loss: 0.0045 - val_loss: 0.0436\n",
      "Epoch 1044/2000\n",
      "45/45 [==============================] - 0s 157us/step - loss: 0.0045 - val_loss: 0.0451\n",
      "Epoch 1045/2000\n",
      "45/45 [==============================] - 0s 166us/step - loss: 0.0044 - val_loss: 0.0431\n",
      "Epoch 1046/2000\n",
      "45/45 [==============================] - 0s 157us/step - loss: 0.0045 - val_loss: 0.0445\n",
      "Epoch 1047/2000\n",
      "45/45 [==============================] - 0s 166us/step - loss: 0.0044 - val_loss: 0.0439\n",
      "Epoch 1048/2000\n",
      "45/45 [==============================] - 0s 155us/step - loss: 0.0044 - val_loss: 0.0438\n",
      "Epoch 1049/2000\n",
      "45/45 [==============================] - 0s 168us/step - loss: 0.0044 - val_loss: 0.0422\n",
      "Epoch 1050/2000\n",
      "45/45 [==============================] - 0s 144us/step - loss: 0.0044 - val_loss: 0.0434\n",
      "Epoch 1051/2000\n",
      "45/45 [==============================] - 0s 171us/step - loss: 0.0043 - val_loss: 0.0426\n",
      "Epoch 1052/2000\n",
      "45/45 [==============================] - 0s 148us/step - loss: 0.0043 - val_loss: 0.0414\n",
      "Epoch 1053/2000\n",
      "45/45 [==============================] - 0s 166us/step - loss: 0.0043 - val_loss: 0.0412\n",
      "Epoch 1054/2000\n",
      "45/45 [==============================] - 0s 142us/step - loss: 0.0043 - val_loss: 0.0420\n",
      "Epoch 1055/2000\n",
      "45/45 [==============================] - 0s 148us/step - loss: 0.0043 - val_loss: 0.0421\n",
      "Epoch 1056/2000\n",
      "45/45 [==============================] - 0s 165us/step - loss: 0.0043 - val_loss: 0.0417\n",
      "Epoch 1057/2000\n",
      "45/45 [==============================] - 0s 171us/step - loss: 0.0043 - val_loss: 0.0423\n",
      "Epoch 1058/2000\n",
      "45/45 [==============================] - 0s 179us/step - loss: 0.0043 - val_loss: 0.0423\n",
      "Epoch 1059/2000\n",
      "45/45 [==============================] - 0s 178us/step - loss: 0.0044 - val_loss: 0.0428\n",
      "Epoch 1060/2000\n",
      "45/45 [==============================] - 0s 183us/step - loss: 0.0042 - val_loss: 0.0424\n",
      "Epoch 1061/2000\n",
      "45/45 [==============================] - 0s 173us/step - loss: 0.0044 - val_loss: 0.0418\n",
      "Epoch 1062/2000\n",
      "45/45 [==============================] - 0s 183us/step - loss: 0.0042 - val_loss: 0.0401\n",
      "Epoch 1063/2000\n",
      "45/45 [==============================] - 0s 189us/step - loss: 0.0042 - val_loss: 0.0411\n",
      "Epoch 1064/2000\n",
      "45/45 [==============================] - 0s 169us/step - loss: 0.0042 - val_loss: 0.0417\n",
      "Epoch 1065/2000\n",
      "45/45 [==============================] - 0s 166us/step - loss: 0.0041 - val_loss: 0.0413\n",
      "Epoch 1066/2000\n",
      "45/45 [==============================] - 0s 161us/step - loss: 0.0042 - val_loss: 0.0389\n",
      "Epoch 1067/2000\n",
      "45/45 [==============================] - 0s 159us/step - loss: 0.0042 - val_loss: 0.0369\n",
      "Epoch 1068/2000\n",
      "45/45 [==============================] - 0s 151us/step - loss: 0.0042 - val_loss: 0.0387\n",
      "Epoch 1069/2000\n",
      "45/45 [==============================] - 0s 160us/step - loss: 0.0041 - val_loss: 0.0387\n",
      "Epoch 1070/2000\n",
      "45/45 [==============================] - 0s 164us/step - loss: 0.0041 - val_loss: 0.0382\n",
      "Epoch 1071/2000\n",
      "45/45 [==============================] - 0s 149us/step - loss: 0.0041 - val_loss: 0.0376\n",
      "Epoch 1072/2000\n",
      "45/45 [==============================] - 0s 188us/step - loss: 0.0041 - val_loss: 0.0359\n",
      "Epoch 1073/2000\n",
      "45/45 [==============================] - 0s 180us/step - loss: 0.0041 - val_loss: 0.0387\n",
      "Epoch 1074/2000\n",
      "45/45 [==============================] - 0s 176us/step - loss: 0.0041 - val_loss: 0.0398\n",
      "Epoch 1075/2000\n",
      "45/45 [==============================] - 0s 168us/step - loss: 0.0041 - val_loss: 0.0369\n",
      "Epoch 1076/2000\n",
      "45/45 [==============================] - 0s 166us/step - loss: 0.0040 - val_loss: 0.0358\n",
      "Epoch 1077/2000\n",
      "45/45 [==============================] - 0s 156us/step - loss: 0.0040 - val_loss: 0.0344\n",
      "Epoch 1078/2000\n",
      "45/45 [==============================] - 0s 180us/step - loss: 0.0040 - val_loss: 0.0355\n",
      "Epoch 1079/2000\n",
      "45/45 [==============================] - 0s 176us/step - loss: 0.0041 - val_loss: 0.0349\n",
      "Epoch 1080/2000\n",
      "45/45 [==============================] - 0s 185us/step - loss: 0.0040 - val_loss: 0.0355\n",
      "Epoch 1081/2000\n",
      "45/45 [==============================] - 0s 163us/step - loss: 0.0040 - val_loss: 0.0352\n",
      "Epoch 1082/2000\n",
      "45/45 [==============================] - 0s 173us/step - loss: 0.0040 - val_loss: 0.0363\n",
      "Epoch 1083/2000\n",
      "45/45 [==============================] - 0s 160us/step - loss: 0.0040 - val_loss: 0.0366\n",
      "Epoch 1084/2000\n",
      "45/45 [==============================] - 0s 171us/step - loss: 0.0039 - val_loss: 0.0373\n",
      "Epoch 1085/2000\n",
      "45/45 [==============================] - 0s 164us/step - loss: 0.0040 - val_loss: 0.0371\n",
      "Epoch 1086/2000\n",
      "45/45 [==============================] - 0s 177us/step - loss: 0.0039 - val_loss: 0.0363\n",
      "Epoch 1087/2000\n",
      "45/45 [==============================] - 0s 152us/step - loss: 0.0039 - val_loss: 0.0343\n",
      "Epoch 1088/2000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "45/45 [==============================] - 0s 179us/step - loss: 0.0039 - val_loss: 0.0347\n",
      "Epoch 1089/2000\n",
      "45/45 [==============================] - 0s 184us/step - loss: 0.0039 - val_loss: 0.0326\n",
      "Epoch 1090/2000\n",
      "45/45 [==============================] - 0s 152us/step - loss: 0.0039 - val_loss: 0.0322\n",
      "Epoch 1091/2000\n",
      "45/45 [==============================] - 0s 212us/step - loss: 0.0039 - val_loss: 0.0339\n",
      "Epoch 1092/2000\n",
      "45/45 [==============================] - 0s 176us/step - loss: 0.0038 - val_loss: 0.0354\n",
      "Epoch 1093/2000\n",
      "45/45 [==============================] - 0s 182us/step - loss: 0.0038 - val_loss: 0.0344\n",
      "Epoch 1094/2000\n",
      "45/45 [==============================] - 0s 165us/step - loss: 0.0039 - val_loss: 0.0323\n",
      "Epoch 1095/2000\n",
      "45/45 [==============================] - 0s 207us/step - loss: 0.0038 - val_loss: 0.0326\n",
      "Epoch 1096/2000\n",
      "45/45 [==============================] - 0s 165us/step - loss: 0.0039 - val_loss: 0.0329\n",
      "Epoch 1097/2000\n",
      "45/45 [==============================] - 0s 199us/step - loss: 0.0038 - val_loss: 0.0326\n",
      "Epoch 1098/2000\n",
      "45/45 [==============================] - 0s 162us/step - loss: 0.0038 - val_loss: 0.0327\n",
      "Epoch 1099/2000\n",
      "45/45 [==============================] - 0s 177us/step - loss: 0.0038 - val_loss: 0.0307\n",
      "Epoch 1100/2000\n",
      "45/45 [==============================] - 0s 149us/step - loss: 0.0038 - val_loss: 0.0317\n",
      "Epoch 1101/2000\n",
      "45/45 [==============================] - 0s 170us/step - loss: 0.0037 - val_loss: 0.0313\n",
      "Epoch 1102/2000\n",
      "45/45 [==============================] - 0s 145us/step - loss: 0.0037 - val_loss: 0.0314\n",
      "Epoch 1103/2000\n",
      "45/45 [==============================] - 0s 165us/step - loss: 0.0038 - val_loss: 0.0325\n",
      "Epoch 1104/2000\n",
      "45/45 [==============================] - 0s 149us/step - loss: 0.0037 - val_loss: 0.0315\n",
      "Epoch 1105/2000\n",
      "45/45 [==============================] - 0s 170us/step - loss: 0.0038 - val_loss: 0.0300\n",
      "Epoch 1106/2000\n",
      "45/45 [==============================] - 0s 159us/step - loss: 0.0037 - val_loss: 0.0314\n",
      "Epoch 1107/2000\n",
      "45/45 [==============================] - 0s 167us/step - loss: 0.0037 - val_loss: 0.0324\n",
      "Epoch 1108/2000\n",
      "45/45 [==============================] - 0s 167us/step - loss: 0.0037 - val_loss: 0.0323\n",
      "Epoch 1109/2000\n",
      "45/45 [==============================] - 0s 184us/step - loss: 0.0037 - val_loss: 0.0332\n",
      "Epoch 1110/2000\n",
      "45/45 [==============================] - 0s 163us/step - loss: 0.0036 - val_loss: 0.0324\n",
      "Epoch 1111/2000\n",
      "45/45 [==============================] - 0s 168us/step - loss: 0.0037 - val_loss: 0.0310\n",
      "Epoch 1112/2000\n",
      "45/45 [==============================] - 0s 163us/step - loss: 0.0036 - val_loss: 0.0308\n",
      "Epoch 1113/2000\n",
      "45/45 [==============================] - 0s 156us/step - loss: 0.0037 - val_loss: 0.0310\n",
      "Epoch 1114/2000\n",
      "45/45 [==============================] - 0s 183us/step - loss: 0.0036 - val_loss: 0.0301\n",
      "Epoch 1115/2000\n",
      "45/45 [==============================] - 0s 159us/step - loss: 0.0036 - val_loss: 0.0291\n",
      "Epoch 1116/2000\n",
      "45/45 [==============================] - 0s 167us/step - loss: 0.0036 - val_loss: 0.0300\n",
      "Epoch 1117/2000\n",
      "45/45 [==============================] - 0s 160us/step - loss: 0.0036 - val_loss: 0.0307\n",
      "Epoch 1118/2000\n",
      "45/45 [==============================] - 0s 164us/step - loss: 0.0037 - val_loss: 0.0310\n",
      "Epoch 1119/2000\n",
      "45/45 [==============================] - 0s 155us/step - loss: 0.0036 - val_loss: 0.0318\n",
      "Epoch 1120/2000\n",
      "45/45 [==============================] - 0s 172us/step - loss: 0.0037 - val_loss: 0.0313\n",
      "Epoch 1121/2000\n",
      "45/45 [==============================] - 0s 142us/step - loss: 0.0036 - val_loss: 0.0316\n",
      "Epoch 1122/2000\n",
      "45/45 [==============================] - 0s 162us/step - loss: 0.0035 - val_loss: 0.0302\n",
      "Epoch 1123/2000\n",
      "45/45 [==============================] - 0s 142us/step - loss: 0.0035 - val_loss: 0.0313\n",
      "Epoch 1124/2000\n",
      "45/45 [==============================] - 0s 183us/step - loss: 0.0035 - val_loss: 0.0307\n",
      "Epoch 1125/2000\n",
      "45/45 [==============================] - 0s 149us/step - loss: 0.0035 - val_loss: 0.0282\n",
      "Epoch 1126/2000\n",
      "45/45 [==============================] - 0s 173us/step - loss: 0.0035 - val_loss: 0.0279\n",
      "Epoch 1127/2000\n",
      "45/45 [==============================] - 0s 149us/step - loss: 0.0035 - val_loss: 0.0276\n",
      "Epoch 1128/2000\n",
      "45/45 [==============================] - 0s 164us/step - loss: 0.0036 - val_loss: 0.0281\n",
      "Epoch 1129/2000\n",
      "45/45 [==============================] - 0s 151us/step - loss: 0.0036 - val_loss: 0.0280\n",
      "Epoch 1130/2000\n",
      "45/45 [==============================] - 0s 153us/step - loss: 0.0035 - val_loss: 0.0287\n",
      "Epoch 1131/2000\n",
      "45/45 [==============================] - 0s 167us/step - loss: 0.0035 - val_loss: 0.0276\n",
      "Epoch 1132/2000\n",
      "45/45 [==============================] - 0s 156us/step - loss: 0.0035 - val_loss: 0.0286\n",
      "Epoch 1133/2000\n",
      "45/45 [==============================] - 0s 166us/step - loss: 0.0035 - val_loss: 0.0284\n",
      "Epoch 1134/2000\n",
      "45/45 [==============================] - 0s 163us/step - loss: 0.0035 - val_loss: 0.0278\n",
      "Epoch 1135/2000\n",
      "45/45 [==============================] - 0s 162us/step - loss: 0.0034 - val_loss: 0.0275\n",
      "Epoch 1136/2000\n",
      "45/45 [==============================] - 0s 143us/step - loss: 0.0034 - val_loss: 0.0271\n",
      "Epoch 1137/2000\n",
      "45/45 [==============================] - 0s 165us/step - loss: 0.0035 - val_loss: 0.0288\n",
      "Epoch 1138/2000\n",
      "45/45 [==============================] - 0s 153us/step - loss: 0.0035 - val_loss: 0.0276\n",
      "Epoch 1139/2000\n",
      "45/45 [==============================] - 0s 167us/step - loss: 0.0034 - val_loss: 0.0262\n",
      "Epoch 1140/2000\n",
      "45/45 [==============================] - 0s 142us/step - loss: 0.0034 - val_loss: 0.0255\n",
      "Epoch 1141/2000\n",
      "45/45 [==============================] - 0s 190us/step - loss: 0.0034 - val_loss: 0.0253\n",
      "Epoch 1142/2000\n",
      "45/45 [==============================] - 0s 161us/step - loss: 0.0034 - val_loss: 0.0255\n",
      "Epoch 1143/2000\n",
      "45/45 [==============================] - 0s 173us/step - loss: 0.0034 - val_loss: 0.0277\n",
      "Epoch 1144/2000\n",
      "45/45 [==============================] - 0s 150us/step - loss: 0.0034 - val_loss: 0.0270\n",
      "Epoch 1145/2000\n",
      "45/45 [==============================] - 0s 171us/step - loss: 0.0034 - val_loss: 0.0274\n",
      "Epoch 1146/2000\n",
      "45/45 [==============================] - 0s 146us/step - loss: 0.0034 - val_loss: 0.0258\n",
      "Epoch 1147/2000\n",
      "45/45 [==============================] - 0s 159us/step - loss: 0.0034 - val_loss: 0.0243\n",
      "Epoch 1148/2000\n",
      "45/45 [==============================] - 0s 164us/step - loss: 0.0034 - val_loss: 0.0247\n",
      "Epoch 1149/2000\n",
      "45/45 [==============================] - 0s 160us/step - loss: 0.0034 - val_loss: 0.0255\n",
      "Epoch 1150/2000\n",
      "45/45 [==============================] - 0s 161us/step - loss: 0.0033 - val_loss: 0.0256\n",
      "Epoch 1151/2000\n",
      "45/45 [==============================] - 0s 168us/step - loss: 0.0033 - val_loss: 0.0259\n",
      "Epoch 1152/2000\n",
      "45/45 [==============================] - 0s 175us/step - loss: 0.0034 - val_loss: 0.0261\n",
      "Epoch 1153/2000\n",
      "45/45 [==============================] - 0s 156us/step - loss: 0.0034 - val_loss: 0.0259\n",
      "Epoch 1154/2000\n",
      "45/45 [==============================] - 0s 161us/step - loss: 0.0034 - val_loss: 0.0256\n",
      "Epoch 1155/2000\n",
      "45/45 [==============================] - 0s 141us/step - loss: 0.0033 - val_loss: 0.0258\n",
      "Epoch 1156/2000\n",
      "45/45 [==============================] - 0s 177us/step - loss: 0.0033 - val_loss: 0.0248\n",
      "Epoch 1157/2000\n",
      "45/45 [==============================] - 0s 145us/step - loss: 0.0033 - val_loss: 0.0230\n",
      "Epoch 1158/2000\n",
      "45/45 [==============================] - 0s 170us/step - loss: 0.0033 - val_loss: 0.0228\n",
      "Epoch 1159/2000\n",
      "45/45 [==============================] - 0s 147us/step - loss: 0.0033 - val_loss: 0.0245\n",
      "Epoch 1160/2000\n",
      "45/45 [==============================] - 0s 170us/step - loss: 0.0033 - val_loss: 0.0249\n",
      "Epoch 1161/2000\n",
      "45/45 [==============================] - 0s 154us/step - loss: 0.0032 - val_loss: 0.0252\n",
      "Epoch 1162/2000\n",
      "45/45 [==============================] - 0s 167us/step - loss: 0.0032 - val_loss: 0.0246\n",
      "Epoch 1163/2000\n",
      "45/45 [==============================] - 0s 147us/step - loss: 0.0032 - val_loss: 0.0248\n",
      "Epoch 1164/2000\n",
      "45/45 [==============================] - 0s 155us/step - loss: 0.0032 - val_loss: 0.0248\n",
      "Epoch 1165/2000\n",
      "45/45 [==============================] - 0s 164us/step - loss: 0.0032 - val_loss: 0.0250\n",
      "Epoch 1166/2000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "45/45 [==============================] - 0s 144us/step - loss: 0.0032 - val_loss: 0.0238\n",
      "Epoch 1167/2000\n",
      "45/45 [==============================] - 0s 170us/step - loss: 0.0032 - val_loss: 0.0234\n",
      "Epoch 1168/2000\n",
      "45/45 [==============================] - 0s 152us/step - loss: 0.0032 - val_loss: 0.0246\n",
      "Epoch 1169/2000\n",
      "45/45 [==============================] - 0s 160us/step - loss: 0.0032 - val_loss: 0.0234\n",
      "Epoch 1170/2000\n",
      "45/45 [==============================] - 0s 157us/step - loss: 0.0032 - val_loss: 0.0224\n",
      "Epoch 1171/2000\n",
      "45/45 [==============================] - 0s 165us/step - loss: 0.0031 - val_loss: 0.0233\n",
      "Epoch 1172/2000\n",
      "45/45 [==============================] - 0s 144us/step - loss: 0.0032 - val_loss: 0.0245\n",
      "Epoch 1173/2000\n",
      "45/45 [==============================] - 0s 166us/step - loss: 0.0032 - val_loss: 0.0248\n",
      "Epoch 1174/2000\n",
      "45/45 [==============================] - 0s 168us/step - loss: 0.0032 - val_loss: 0.0242\n",
      "Epoch 1175/2000\n",
      "45/45 [==============================] - 0s 189us/step - loss: 0.0032 - val_loss: 0.0235\n",
      "Epoch 1176/2000\n",
      "45/45 [==============================] - 0s 168us/step - loss: 0.0031 - val_loss: 0.0234\n",
      "Epoch 1177/2000\n",
      "45/45 [==============================] - 0s 190us/step - loss: 0.0031 - val_loss: 0.0239\n",
      "Epoch 1178/2000\n",
      "45/45 [==============================] - 0s 172us/step - loss: 0.0032 - val_loss: 0.0246\n",
      "Epoch 1179/2000\n",
      "45/45 [==============================] - 0s 206us/step - loss: 0.0032 - val_loss: 0.0241\n",
      "Epoch 1180/2000\n",
      "45/45 [==============================] - 0s 174us/step - loss: 0.0031 - val_loss: 0.0237\n",
      "Epoch 1181/2000\n",
      "45/45 [==============================] - 0s 179us/step - loss: 0.0031 - val_loss: 0.0233\n",
      "Epoch 1182/2000\n",
      "45/45 [==============================] - 0s 179us/step - loss: 0.0031 - val_loss: 0.0229\n",
      "Epoch 1183/2000\n",
      "45/45 [==============================] - 0s 164us/step - loss: 0.0031 - val_loss: 0.0219\n",
      "Epoch 1184/2000\n",
      "45/45 [==============================] - 0s 168us/step - loss: 0.0031 - val_loss: 0.0215\n",
      "Epoch 1185/2000\n",
      "45/45 [==============================] - 0s 162us/step - loss: 0.0031 - val_loss: 0.0211\n",
      "Epoch 1186/2000\n",
      "45/45 [==============================] - 0s 166us/step - loss: 0.0031 - val_loss: 0.0198\n",
      "Epoch 1187/2000\n",
      "45/45 [==============================] - 0s 182us/step - loss: 0.0031 - val_loss: 0.0200\n",
      "Epoch 1188/2000\n",
      "45/45 [==============================] - 0s 168us/step - loss: 0.0031 - val_loss: 0.0206\n",
      "Epoch 1189/2000\n",
      "45/45 [==============================] - 0s 170us/step - loss: 0.0031 - val_loss: 0.0208\n",
      "Epoch 1190/2000\n",
      "45/45 [==============================] - 0s 159us/step - loss: 0.0030 - val_loss: 0.0215\n",
      "Epoch 1191/2000\n",
      "45/45 [==============================] - 0s 166us/step - loss: 0.0030 - val_loss: 0.0215\n",
      "Epoch 1192/2000\n",
      "45/45 [==============================] - 0s 148us/step - loss: 0.0031 - val_loss: 0.0222\n",
      "Epoch 1193/2000\n",
      "45/45 [==============================] - 0s 168us/step - loss: 0.0031 - val_loss: 0.0199\n",
      "Epoch 1194/2000\n",
      "45/45 [==============================] - 0s 155us/step - loss: 0.0031 - val_loss: 0.0205\n",
      "Epoch 1195/2000\n",
      "45/45 [==============================] - 0s 175us/step - loss: 0.0030 - val_loss: 0.0212\n",
      "Epoch 1196/2000\n",
      "45/45 [==============================] - 0s 158us/step - loss: 0.0030 - val_loss: 0.0211\n",
      "Epoch 1197/2000\n",
      "45/45 [==============================] - 0s 172us/step - loss: 0.0030 - val_loss: 0.0210\n",
      "Epoch 1198/2000\n",
      "45/45 [==============================] - 0s 153us/step - loss: 0.0030 - val_loss: 0.0202\n",
      "Epoch 1199/2000\n",
      "45/45 [==============================] - 0s 175us/step - loss: 0.0030 - val_loss: 0.0215\n",
      "Epoch 1200/2000\n",
      "45/45 [==============================] - 0s 154us/step - loss: 0.0030 - val_loss: 0.0212\n",
      "Epoch 1201/2000\n",
      "45/45 [==============================] - 0s 166us/step - loss: 0.0030 - val_loss: 0.0207\n",
      "Epoch 1202/2000\n",
      "45/45 [==============================] - 0s 148us/step - loss: 0.0030 - val_loss: 0.0205\n",
      "Epoch 1203/2000\n",
      "45/45 [==============================] - 0s 172us/step - loss: 0.0030 - val_loss: 0.0208\n",
      "Epoch 1204/2000\n",
      "45/45 [==============================] - 0s 143us/step - loss: 0.0030 - val_loss: 0.0212\n",
      "Epoch 1205/2000\n",
      "45/45 [==============================] - 0s 156us/step - loss: 0.0030 - val_loss: 0.0212\n",
      "Epoch 1206/2000\n",
      "45/45 [==============================] - 0s 155us/step - loss: 0.0030 - val_loss: 0.0219\n",
      "Epoch 1207/2000\n",
      "45/45 [==============================] - 0s 155us/step - loss: 0.0029 - val_loss: 0.0206\n",
      "Epoch 1208/2000\n",
      "45/45 [==============================] - 0s 168us/step - loss: 0.0030 - val_loss: 0.0207\n",
      "Epoch 1209/2000\n",
      "45/45 [==============================] - 0s 157us/step - loss: 0.0029 - val_loss: 0.0215\n",
      "Epoch 1210/2000\n",
      "45/45 [==============================] - 0s 176us/step - loss: 0.0029 - val_loss: 0.0208\n",
      "Epoch 1211/2000\n",
      "45/45 [==============================] - 0s 156us/step - loss: 0.0029 - val_loss: 0.0208\n",
      "Epoch 1212/2000\n",
      "45/45 [==============================] - 0s 164us/step - loss: 0.0029 - val_loss: 0.0214\n",
      "Epoch 1213/2000\n",
      "45/45 [==============================] - 0s 144us/step - loss: 0.0029 - val_loss: 0.0202\n",
      "Epoch 1214/2000\n",
      "45/45 [==============================] - 0s 169us/step - loss: 0.0029 - val_loss: 0.0194\n",
      "Epoch 1215/2000\n",
      "45/45 [==============================] - 0s 156us/step - loss: 0.0029 - val_loss: 0.0200\n",
      "Epoch 1216/2000\n",
      "45/45 [==============================] - 0s 171us/step - loss: 0.0029 - val_loss: 0.0195\n",
      "Epoch 1217/2000\n",
      "45/45 [==============================] - 0s 161us/step - loss: 0.0029 - val_loss: 0.0199\n",
      "Epoch 1218/2000\n",
      "45/45 [==============================] - 0s 168us/step - loss: 0.0029 - val_loss: 0.0196\n",
      "Epoch 1219/2000\n",
      "45/45 [==============================] - 0s 158us/step - loss: 0.0029 - val_loss: 0.0192\n",
      "Epoch 1220/2000\n",
      "45/45 [==============================] - 0s 174us/step - loss: 0.0030 - val_loss: 0.0201\n",
      "Epoch 1221/2000\n",
      "45/45 [==============================] - 0s 140us/step - loss: 0.0028 - val_loss: 0.0188\n",
      "Epoch 1222/2000\n",
      "45/45 [==============================] - 0s 154us/step - loss: 0.0028 - val_loss: 0.0186\n",
      "Epoch 1223/2000\n",
      "45/45 [==============================] - 0s 158us/step - loss: 0.0029 - val_loss: 0.0204\n",
      "Epoch 1224/2000\n",
      "45/45 [==============================] - 0s 146us/step - loss: 0.0029 - val_loss: 0.0191\n",
      "Epoch 1225/2000\n",
      "45/45 [==============================] - 0s 162us/step - loss: 0.0029 - val_loss: 0.0194\n",
      "Epoch 1226/2000\n",
      "45/45 [==============================] - 0s 156us/step - loss: 0.0029 - val_loss: 0.0178\n",
      "Epoch 1227/2000\n",
      "45/45 [==============================] - 0s 161us/step - loss: 0.0028 - val_loss: 0.0183\n",
      "Epoch 1228/2000\n",
      "45/45 [==============================] - 0s 149us/step - loss: 0.0028 - val_loss: 0.0183\n",
      "Epoch 1229/2000\n",
      "45/45 [==============================] - 0s 159us/step - loss: 0.0028 - val_loss: 0.0187\n",
      "Epoch 1230/2000\n",
      "45/45 [==============================] - 0s 143us/step - loss: 0.0028 - val_loss: 0.0187\n",
      "Epoch 1231/2000\n",
      "45/45 [==============================] - 0s 167us/step - loss: 0.0028 - val_loss: 0.0174\n",
      "Epoch 1232/2000\n",
      "45/45 [==============================] - 0s 148us/step - loss: 0.0028 - val_loss: 0.0172\n",
      "Epoch 1233/2000\n",
      "45/45 [==============================] - 0s 158us/step - loss: 0.0028 - val_loss: 0.0165\n",
      "Epoch 1234/2000\n",
      "45/45 [==============================] - 0s 151us/step - loss: 0.0028 - val_loss: 0.0180\n",
      "Epoch 1235/2000\n",
      "45/45 [==============================] - 0s 156us/step - loss: 0.0028 - val_loss: 0.0168\n",
      "Epoch 1236/2000\n",
      "45/45 [==============================] - 0s 164us/step - loss: 0.0028 - val_loss: 0.0159\n",
      "Epoch 1237/2000\n",
      "45/45 [==============================] - 0s 160us/step - loss: 0.0028 - val_loss: 0.0167\n",
      "Epoch 1238/2000\n",
      "45/45 [==============================] - 0s 162us/step - loss: 0.0028 - val_loss: 0.0169\n",
      "Epoch 1239/2000\n",
      "45/45 [==============================] - 0s 145us/step - loss: 0.0028 - val_loss: 0.0163\n",
      "Epoch 1240/2000\n",
      "45/45 [==============================] - 0s 160us/step - loss: 0.0028 - val_loss: 0.0166\n",
      "Epoch 1241/2000\n",
      "45/45 [==============================] - 0s 152us/step - loss: 0.0028 - val_loss: 0.0173\n",
      "Epoch 1242/2000\n",
      "45/45 [==============================] - 0s 164us/step - loss: 0.0027 - val_loss: 0.0173\n",
      "Epoch 1243/2000\n",
      "45/45 [==============================] - 0s 147us/step - loss: 0.0028 - val_loss: 0.0158\n",
      "Epoch 1244/2000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "45/45 [==============================] - 0s 166us/step - loss: 0.0028 - val_loss: 0.0151\n",
      "Epoch 1245/2000\n",
      "45/45 [==============================] - 0s 160us/step - loss: 0.0028 - val_loss: 0.0152\n",
      "Epoch 1246/2000\n",
      "45/45 [==============================] - 0s 171us/step - loss: 0.0027 - val_loss: 0.0155\n",
      "Epoch 1247/2000\n",
      "45/45 [==============================] - 0s 149us/step - loss: 0.0027 - val_loss: 0.0161\n",
      "Epoch 1248/2000\n",
      "45/45 [==============================] - 0s 168us/step - loss: 0.0027 - val_loss: 0.0158\n",
      "Epoch 1249/2000\n",
      "45/45 [==============================] - 0s 152us/step - loss: 0.0028 - val_loss: 0.0167\n",
      "Epoch 1250/2000\n",
      "45/45 [==============================] - 0s 162us/step - loss: 0.0027 - val_loss: 0.0167\n",
      "Epoch 1251/2000\n",
      "45/45 [==============================] - 0s 153us/step - loss: 0.0027 - val_loss: 0.0172\n",
      "Epoch 1252/2000\n",
      "45/45 [==============================] - 0s 159us/step - loss: 0.0027 - val_loss: 0.0169\n",
      "Epoch 1253/2000\n",
      "45/45 [==============================] - 0s 144us/step - loss: 0.0027 - val_loss: 0.0166\n",
      "Epoch 1254/2000\n",
      "45/45 [==============================] - 0s 146us/step - loss: 0.0027 - val_loss: 0.0153\n",
      "Epoch 1255/2000\n",
      "45/45 [==============================] - 0s 167us/step - loss: 0.0027 - val_loss: 0.0161\n",
      "Epoch 1256/2000\n",
      "45/45 [==============================] - 0s 150us/step - loss: 0.0027 - val_loss: 0.0157\n",
      "Epoch 1257/2000\n",
      "45/45 [==============================] - 0s 168us/step - loss: 0.0027 - val_loss: 0.0163\n",
      "Epoch 1258/2000\n",
      "45/45 [==============================] - 0s 143us/step - loss: 0.0027 - val_loss: 0.0153\n",
      "Epoch 1259/2000\n",
      "45/45 [==============================] - 0s 168us/step - loss: 0.0027 - val_loss: 0.0152\n",
      "Epoch 1260/2000\n",
      "45/45 [==============================] - 0s 141us/step - loss: 0.0027 - val_loss: 0.0162\n",
      "Epoch 1261/2000\n",
      "45/45 [==============================] - 0s 162us/step - loss: 0.0026 - val_loss: 0.0165\n",
      "Epoch 1262/2000\n",
      "45/45 [==============================] - 0s 144us/step - loss: 0.0026 - val_loss: 0.0163\n",
      "Epoch 1263/2000\n",
      "45/45 [==============================] - 0s 151us/step - loss: 0.0027 - val_loss: 0.0174\n",
      "Epoch 1264/2000\n",
      "45/45 [==============================] - 0s 162us/step - loss: 0.0027 - val_loss: 0.0180\n",
      "Epoch 1265/2000\n",
      "45/45 [==============================] - 0s 152us/step - loss: 0.0027 - val_loss: 0.0160\n",
      "Epoch 1266/2000\n",
      "45/45 [==============================] - 0s 172us/step - loss: 0.0027 - val_loss: 0.0159\n",
      "Epoch 1267/2000\n",
      "45/45 [==============================] - 0s 150us/step - loss: 0.0026 - val_loss: 0.0151\n",
      "Epoch 1268/2000\n",
      "45/45 [==============================] - 0s 178us/step - loss: 0.0026 - val_loss: 0.0154\n",
      "Epoch 1269/2000\n",
      "45/45 [==============================] - 0s 160us/step - loss: 0.0026 - val_loss: 0.0154\n",
      "Epoch 1270/2000\n",
      "45/45 [==============================] - 0s 185us/step - loss: 0.0026 - val_loss: 0.0146\n",
      "Epoch 1271/2000\n",
      "45/45 [==============================] - 0s 162us/step - loss: 0.0026 - val_loss: 0.0143\n",
      "Epoch 1272/2000\n",
      "45/45 [==============================] - 0s 181us/step - loss: 0.0026 - val_loss: 0.0140\n",
      "Epoch 1273/2000\n",
      "45/45 [==============================] - 0s 160us/step - loss: 0.0026 - val_loss: 0.0148\n",
      "Epoch 1274/2000\n",
      "45/45 [==============================] - 0s 172us/step - loss: 0.0026 - val_loss: 0.0140\n",
      "Epoch 1275/2000\n",
      "45/45 [==============================] - 0s 149us/step - loss: 0.0026 - val_loss: 0.0139\n",
      "Epoch 1276/2000\n",
      "45/45 [==============================] - 0s 168us/step - loss: 0.0026 - val_loss: 0.0144\n",
      "Epoch 1277/2000\n",
      "45/45 [==============================] - 0s 151us/step - loss: 0.0026 - val_loss: 0.0149\n",
      "Epoch 1278/2000\n",
      "45/45 [==============================] - 0s 216us/step - loss: 0.0026 - val_loss: 0.0148\n",
      "Epoch 1279/2000\n",
      "45/45 [==============================] - 0s 181us/step - loss: 0.0026 - val_loss: 0.0145\n",
      "Epoch 1280/2000\n",
      "45/45 [==============================] - 0s 202us/step - loss: 0.0025 - val_loss: 0.0143\n",
      "Epoch 1281/2000\n",
      "45/45 [==============================] - 0s 176us/step - loss: 0.0025 - val_loss: 0.0143\n",
      "Epoch 1282/2000\n",
      "45/45 [==============================] - 0s 177us/step - loss: 0.0026 - val_loss: 0.0136\n",
      "Epoch 1283/2000\n",
      "45/45 [==============================] - 0s 177us/step - loss: 0.0025 - val_loss: 0.0146\n",
      "Epoch 1284/2000\n",
      "45/45 [==============================] - 0s 157us/step - loss: 0.0025 - val_loss: 0.0140\n",
      "Epoch 1285/2000\n",
      "45/45 [==============================] - 0s 149us/step - loss: 0.0025 - val_loss: 0.0135\n",
      "Epoch 1286/2000\n",
      "45/45 [==============================] - 0s 164us/step - loss: 0.0025 - val_loss: 0.0133\n",
      "Epoch 1287/2000\n",
      "45/45 [==============================] - 0s 143us/step - loss: 0.0025 - val_loss: 0.0141\n",
      "Epoch 1288/2000\n",
      "45/45 [==============================] - 0s 163us/step - loss: 0.0025 - val_loss: 0.0138\n",
      "Epoch 1289/2000\n",
      "45/45 [==============================] - 0s 144us/step - loss: 0.0025 - val_loss: 0.0141\n",
      "Epoch 1290/2000\n",
      "45/45 [==============================] - 0s 167us/step - loss: 0.0025 - val_loss: 0.0129\n",
      "Epoch 1291/2000\n",
      "45/45 [==============================] - 0s 144us/step - loss: 0.0025 - val_loss: 0.0128\n",
      "Epoch 1292/2000\n",
      "45/45 [==============================] - 0s 167us/step - loss: 0.0025 - val_loss: 0.0134\n",
      "Epoch 1293/2000\n",
      "45/45 [==============================] - 0s 152us/step - loss: 0.0026 - val_loss: 0.0129\n",
      "Epoch 1294/2000\n",
      "45/45 [==============================] - 0s 155us/step - loss: 0.0025 - val_loss: 0.0128\n",
      "Epoch 1295/2000\n",
      "45/45 [==============================] - 0s 159us/step - loss: 0.0025 - val_loss: 0.0138\n",
      "Epoch 1296/2000\n",
      "45/45 [==============================] - 0s 147us/step - loss: 0.0025 - val_loss: 0.0145\n",
      "Epoch 1297/2000\n",
      "45/45 [==============================] - 0s 164us/step - loss: 0.0025 - val_loss: 0.0139\n",
      "Epoch 1298/2000\n",
      "45/45 [==============================] - 0s 146us/step - loss: 0.0025 - val_loss: 0.0143\n",
      "Epoch 1299/2000\n",
      "45/45 [==============================] - 0s 163us/step - loss: 0.0025 - val_loss: 0.0141\n",
      "Epoch 1300/2000\n",
      "45/45 [==============================] - 0s 143us/step - loss: 0.0025 - val_loss: 0.0142\n",
      "Epoch 1301/2000\n",
      "45/45 [==============================] - 0s 163us/step - loss: 0.0024 - val_loss: 0.0133\n",
      "Epoch 1302/2000\n",
      "45/45 [==============================] - 0s 150us/step - loss: 0.0025 - val_loss: 0.0134\n",
      "Epoch 1303/2000\n",
      "45/45 [==============================] - 0s 168us/step - loss: 0.0025 - val_loss: 0.0132\n",
      "Epoch 1304/2000\n",
      "45/45 [==============================] - 0s 148us/step - loss: 0.0024 - val_loss: 0.0125\n",
      "Epoch 1305/2000\n",
      "45/45 [==============================] - 0s 154us/step - loss: 0.0025 - val_loss: 0.0133\n",
      "Epoch 1306/2000\n",
      "45/45 [==============================] - 0s 162us/step - loss: 0.0024 - val_loss: 0.0131\n",
      "Epoch 1307/2000\n",
      "45/45 [==============================] - 0s 160us/step - loss: 0.0024 - val_loss: 0.0125\n",
      "Epoch 1308/2000\n",
      "45/45 [==============================] - 0s 161us/step - loss: 0.0024 - val_loss: 0.0124\n",
      "Epoch 1309/2000\n",
      "45/45 [==============================] - 0s 153us/step - loss: 0.0024 - val_loss: 0.0135\n",
      "Epoch 1310/2000\n",
      "45/45 [==============================] - 0s 169us/step - loss: 0.0024 - val_loss: 0.0127\n",
      "Epoch 1311/2000\n",
      "45/45 [==============================] - 0s 154us/step - loss: 0.0024 - val_loss: 0.0136\n",
      "Epoch 1312/2000\n",
      "45/45 [==============================] - 0s 168us/step - loss: 0.0024 - val_loss: 0.0135\n",
      "Epoch 1313/2000\n",
      "45/45 [==============================] - 0s 161us/step - loss: 0.0024 - val_loss: 0.0138\n",
      "Epoch 1314/2000\n",
      "45/45 [==============================] - 0s 168us/step - loss: 0.0025 - val_loss: 0.0123\n",
      "Epoch 1315/2000\n",
      "45/45 [==============================] - 0s 140us/step - loss: 0.0024 - val_loss: 0.0127\n",
      "Epoch 1316/2000\n",
      "45/45 [==============================] - 0s 161us/step - loss: 0.0024 - val_loss: 0.0131\n",
      "Epoch 1317/2000\n",
      "45/45 [==============================] - 0s 145us/step - loss: 0.0024 - val_loss: 0.0130\n",
      "Epoch 1318/2000\n",
      "45/45 [==============================] - 0s 163us/step - loss: 0.0024 - val_loss: 0.0131\n",
      "Epoch 1319/2000\n",
      "45/45 [==============================] - 0s 151us/step - loss: 0.0024 - val_loss: 0.0130\n",
      "Epoch 1320/2000\n",
      "45/45 [==============================] - 0s 149us/step - loss: 0.0024 - val_loss: 0.0135\n",
      "Epoch 1321/2000\n",
      "45/45 [==============================] - 0s 158us/step - loss: 0.0024 - val_loss: 0.0124\n",
      "Epoch 1322/2000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "45/45 [==============================] - 0s 160us/step - loss: 0.0024 - val_loss: 0.0117\n",
      "Epoch 1323/2000\n",
      "45/45 [==============================] - 0s 168us/step - loss: 0.0024 - val_loss: 0.0119\n",
      "Epoch 1324/2000\n",
      "45/45 [==============================] - 0s 159us/step - loss: 0.0024 - val_loss: 0.0123\n",
      "Epoch 1325/2000\n",
      "45/45 [==============================] - 0s 162us/step - loss: 0.0023 - val_loss: 0.0120\n",
      "Epoch 1326/2000\n",
      "45/45 [==============================] - 0s 168us/step - loss: 0.0024 - val_loss: 0.0114\n",
      "Epoch 1327/2000\n",
      "45/45 [==============================] - 0s 158us/step - loss: 0.0024 - val_loss: 0.0117\n",
      "Epoch 1328/2000\n",
      "45/45 [==============================] - 0s 149us/step - loss: 0.0024 - val_loss: 0.0113\n",
      "Epoch 1329/2000\n",
      "45/45 [==============================] - 0s 163us/step - loss: 0.0023 - val_loss: 0.0120\n",
      "Epoch 1330/2000\n",
      "45/45 [==============================] - 0s 140us/step - loss: 0.0024 - val_loss: 0.0116\n",
      "Epoch 1331/2000\n",
      "45/45 [==============================] - 0s 166us/step - loss: 0.0024 - val_loss: 0.0122\n",
      "Epoch 1332/2000\n",
      "45/45 [==============================] - 0s 143us/step - loss: 0.0023 - val_loss: 0.0123\n",
      "Epoch 1333/2000\n",
      "45/45 [==============================] - 0s 166us/step - loss: 0.0024 - val_loss: 0.0125\n",
      "Epoch 1334/2000\n",
      "45/45 [==============================] - 0s 153us/step - loss: 0.0024 - val_loss: 0.0123\n",
      "Epoch 1335/2000\n",
      "45/45 [==============================] - 0s 163us/step - loss: 0.0023 - val_loss: 0.0117\n",
      "Epoch 1336/2000\n",
      "45/45 [==============================] - 0s 145us/step - loss: 0.0023 - val_loss: 0.0120\n",
      "Epoch 1337/2000\n",
      "45/45 [==============================] - 0s 160us/step - loss: 0.0024 - val_loss: 0.0122\n",
      "Epoch 1338/2000\n",
      "45/45 [==============================] - 0s 164us/step - loss: 0.0024 - val_loss: 0.0119\n",
      "Epoch 1339/2000\n",
      "45/45 [==============================] - 0s 155us/step - loss: 0.0023 - val_loss: 0.0110\n",
      "Epoch 1340/2000\n",
      "45/45 [==============================] - 0s 167us/step - loss: 0.0023 - val_loss: 0.0113\n",
      "Epoch 1341/2000\n",
      "45/45 [==============================] - 0s 147us/step - loss: 0.0023 - val_loss: 0.0116\n",
      "Epoch 1342/2000\n",
      "45/45 [==============================] - 0s 170us/step - loss: 0.0023 - val_loss: 0.0109\n",
      "Epoch 1343/2000\n",
      "45/45 [==============================] - 0s 167us/step - loss: 0.0023 - val_loss: 0.0099\n",
      "Epoch 1344/2000\n",
      "45/45 [==============================] - 0s 217us/step - loss: 0.0023 - val_loss: 0.0109\n",
      "Epoch 1345/2000\n",
      "45/45 [==============================] - 0s 199us/step - loss: 0.0023 - val_loss: 0.0111\n",
      "Epoch 1346/2000\n",
      "45/45 [==============================] - 0s 182us/step - loss: 0.0023 - val_loss: 0.0112\n",
      "Epoch 1347/2000\n",
      "45/45 [==============================] - 0s 190us/step - loss: 0.0023 - val_loss: 0.0113\n",
      "Epoch 1348/2000\n",
      "45/45 [==============================] - 0s 164us/step - loss: 0.0023 - val_loss: 0.0119\n",
      "Epoch 1349/2000\n",
      "45/45 [==============================] - 0s 190us/step - loss: 0.0023 - val_loss: 0.0120\n",
      "Epoch 1350/2000\n",
      "45/45 [==============================] - 0s 164us/step - loss: 0.0024 - val_loss: 0.0111\n",
      "Epoch 1351/2000\n",
      "45/45 [==============================] - 0s 180us/step - loss: 0.0022 - val_loss: 0.0107\n",
      "Epoch 1352/2000\n",
      "45/45 [==============================] - 0s 156us/step - loss: 0.0023 - val_loss: 0.0103\n",
      "Epoch 1353/2000\n",
      "45/45 [==============================] - 0s 177us/step - loss: 0.0022 - val_loss: 0.0103\n",
      "Epoch 1354/2000\n",
      "45/45 [==============================] - 0s 153us/step - loss: 0.0022 - val_loss: 0.0101\n",
      "Epoch 1355/2000\n",
      "45/45 [==============================] - 0s 166us/step - loss: 0.0022 - val_loss: 0.0104\n",
      "Epoch 1356/2000\n",
      "45/45 [==============================] - 0s 156us/step - loss: 0.0022 - val_loss: 0.0109\n",
      "Epoch 1357/2000\n",
      "45/45 [==============================] - 0s 175us/step - loss: 0.0023 - val_loss: 0.0106\n",
      "Epoch 1358/2000\n",
      "45/45 [==============================] - 0s 161us/step - loss: 0.0022 - val_loss: 0.0100\n",
      "Epoch 1359/2000\n",
      "45/45 [==============================] - 0s 157us/step - loss: 0.0022 - val_loss: 0.0109\n",
      "Epoch 1360/2000\n",
      "45/45 [==============================] - 0s 163us/step - loss: 0.0023 - val_loss: 0.0098\n",
      "Epoch 1361/2000\n",
      "45/45 [==============================] - 0s 158us/step - loss: 0.0022 - val_loss: 0.0095\n",
      "Epoch 1362/2000\n",
      "45/45 [==============================] - 0s 175us/step - loss: 0.0022 - val_loss: 0.0101\n",
      "Epoch 1363/2000\n",
      "45/45 [==============================] - 0s 167us/step - loss: 0.0023 - val_loss: 0.0104\n",
      "Epoch 1364/2000\n",
      "45/45 [==============================] - 0s 172us/step - loss: 0.0022 - val_loss: 0.0106\n",
      "Epoch 1365/2000\n",
      "45/45 [==============================] - 0s 158us/step - loss: 0.0022 - val_loss: 0.0104\n",
      "Epoch 1366/2000\n",
      "45/45 [==============================] - 0s 172us/step - loss: 0.0022 - val_loss: 0.0102\n",
      "Epoch 1367/2000\n",
      "45/45 [==============================] - 0s 153us/step - loss: 0.0022 - val_loss: 0.0101\n",
      "Epoch 1368/2000\n",
      "45/45 [==============================] - 0s 169us/step - loss: 0.0022 - val_loss: 0.0097\n",
      "Epoch 1369/2000\n",
      "45/45 [==============================] - 0s 148us/step - loss: 0.0022 - val_loss: 0.0094\n",
      "Epoch 1370/2000\n",
      "45/45 [==============================] - 0s 163us/step - loss: 0.0022 - val_loss: 0.0105\n",
      "Epoch 1371/2000\n",
      "45/45 [==============================] - 0s 141us/step - loss: 0.0022 - val_loss: 0.0107\n",
      "Epoch 1372/2000\n",
      "45/45 [==============================] - 0s 168us/step - loss: 0.0022 - val_loss: 0.0108\n",
      "Epoch 1373/2000\n",
      "45/45 [==============================] - 0s 145us/step - loss: 0.0022 - val_loss: 0.0101\n",
      "Epoch 1374/2000\n",
      "45/45 [==============================] - 0s 155us/step - loss: 0.0022 - val_loss: 0.0104\n",
      "Epoch 1375/2000\n",
      "45/45 [==============================] - 0s 156us/step - loss: 0.0022 - val_loss: 0.0100\n",
      "Epoch 1376/2000\n",
      "45/45 [==============================] - 0s 150us/step - loss: 0.0022 - val_loss: 0.0095\n",
      "Epoch 1377/2000\n",
      "45/45 [==============================] - 0s 154us/step - loss: 0.0021 - val_loss: 0.0101\n",
      "Epoch 1378/2000\n",
      "45/45 [==============================] - 0s 142us/step - loss: 0.0021 - val_loss: 0.0097\n",
      "Epoch 1379/2000\n",
      "45/45 [==============================] - 0s 164us/step - loss: 0.0022 - val_loss: 0.0102\n",
      "Epoch 1380/2000\n",
      "45/45 [==============================] - 0s 137us/step - loss: 0.0021 - val_loss: 0.0100\n",
      "Epoch 1381/2000\n",
      "45/45 [==============================] - 0s 168us/step - loss: 0.0022 - val_loss: 0.0092\n",
      "Epoch 1382/2000\n",
      "45/45 [==============================] - 0s 142us/step - loss: 0.0022 - val_loss: 0.0089\n",
      "Epoch 1383/2000\n",
      "45/45 [==============================] - 0s 164us/step - loss: 0.0021 - val_loss: 0.0091\n",
      "Epoch 1384/2000\n",
      "45/45 [==============================] - 0s 160us/step - loss: 0.0021 - val_loss: 0.0089\n",
      "Epoch 1385/2000\n",
      "45/45 [==============================] - 0s 171us/step - loss: 0.0021 - val_loss: 0.0093\n",
      "Epoch 1386/2000\n",
      "45/45 [==============================] - 0s 160us/step - loss: 0.0021 - val_loss: 0.0087\n",
      "Epoch 1387/2000\n",
      "45/45 [==============================] - 0s 170us/step - loss: 0.0022 - val_loss: 0.0096\n",
      "Epoch 1388/2000\n",
      "45/45 [==============================] - 0s 161us/step - loss: 0.0021 - val_loss: 0.0095\n",
      "Epoch 1389/2000\n",
      "45/45 [==============================] - 0s 157us/step - loss: 0.0021 - val_loss: 0.0098\n",
      "Epoch 1390/2000\n",
      "45/45 [==============================] - 0s 181us/step - loss: 0.0021 - val_loss: 0.0101\n",
      "Epoch 1391/2000\n",
      "45/45 [==============================] - 0s 155us/step - loss: 0.0021 - val_loss: 0.0096\n",
      "Epoch 1392/2000\n",
      "45/45 [==============================] - 0s 163us/step - loss: 0.0021 - val_loss: 0.0095\n",
      "Epoch 1393/2000\n",
      "45/45 [==============================] - 0s 158us/step - loss: 0.0021 - val_loss: 0.0093\n",
      "Epoch 1394/2000\n",
      "45/45 [==============================] - 0s 161us/step - loss: 0.0021 - val_loss: 0.0085\n",
      "Epoch 1395/2000\n",
      "45/45 [==============================] - 0s 157us/step - loss: 0.0021 - val_loss: 0.0094\n",
      "Epoch 1396/2000\n",
      "45/45 [==============================] - 0s 168us/step - loss: 0.0021 - val_loss: 0.0086\n",
      "Epoch 1397/2000\n",
      "45/45 [==============================] - 0s 146us/step - loss: 0.0021 - val_loss: 0.0082\n",
      "Epoch 1398/2000\n",
      "45/45 [==============================] - 0s 158us/step - loss: 0.0021 - val_loss: 0.0083\n",
      "Epoch 1399/2000\n",
      "45/45 [==============================] - 0s 141us/step - loss: 0.0021 - val_loss: 0.0086\n",
      "Epoch 1400/2000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "45/45 [==============================] - 0s 162us/step - loss: 0.0021 - val_loss: 0.0086\n",
      "Epoch 1401/2000\n",
      "45/45 [==============================] - 0s 151us/step - loss: 0.0021 - val_loss: 0.0090\n",
      "Epoch 1402/2000\n",
      "45/45 [==============================] - 0s 156us/step - loss: 0.0021 - val_loss: 0.0083\n",
      "Epoch 1403/2000\n",
      "45/45 [==============================] - 0s 158us/step - loss: 0.0021 - val_loss: 0.0085\n",
      "Epoch 1404/2000\n",
      "45/45 [==============================] - 0s 145us/step - loss: 0.0020 - val_loss: 0.0083\n",
      "Epoch 1405/2000\n",
      "45/45 [==============================] - 0s 157us/step - loss: 0.0021 - val_loss: 0.0084\n",
      "Epoch 1406/2000\n",
      "45/45 [==============================] - 0s 145us/step - loss: 0.0021 - val_loss: 0.0083\n",
      "Epoch 1407/2000\n",
      "45/45 [==============================] - 0s 160us/step - loss: 0.0021 - val_loss: 0.0084\n",
      "Epoch 1408/2000\n",
      "45/45 [==============================] - 0s 141us/step - loss: 0.0021 - val_loss: 0.0088\n",
      "Epoch 1409/2000\n",
      "45/45 [==============================] - 0s 170us/step - loss: 0.0020 - val_loss: 0.0085\n",
      "Epoch 1410/2000\n",
      "45/45 [==============================] - 0s 143us/step - loss: 0.0020 - val_loss: 0.0084\n",
      "Epoch 1411/2000\n",
      "45/45 [==============================] - 0s 163us/step - loss: 0.0020 - val_loss: 0.0084\n",
      "Epoch 1412/2000\n",
      "45/45 [==============================] - 0s 145us/step - loss: 0.0021 - val_loss: 0.0084\n",
      "Epoch 1413/2000\n",
      "45/45 [==============================] - 0s 157us/step - loss: 0.0020 - val_loss: 0.0082\n",
      "Epoch 1414/2000\n",
      "45/45 [==============================] - 0s 163us/step - loss: 0.0020 - val_loss: 0.0085\n",
      "Epoch 1415/2000\n",
      "45/45 [==============================] - 0s 169us/step - loss: 0.0020 - val_loss: 0.0086\n",
      "Epoch 1416/2000\n",
      "45/45 [==============================] - 0s 158us/step - loss: 0.0020 - val_loss: 0.0089\n",
      "Epoch 1417/2000\n",
      "45/45 [==============================] - 0s 158us/step - loss: 0.0021 - val_loss: 0.0086\n",
      "Epoch 1418/2000\n",
      "45/45 [==============================] - 0s 160us/step - loss: 0.0020 - val_loss: 0.0079\n",
      "Epoch 1419/2000\n",
      "45/45 [==============================] - 0s 146us/step - loss: 0.0020 - val_loss: 0.0078\n",
      "Epoch 1420/2000\n",
      "45/45 [==============================] - 0s 172us/step - loss: 0.0020 - val_loss: 0.0078\n",
      "Epoch 1421/2000\n",
      "45/45 [==============================] - 0s 152us/step - loss: 0.0020 - val_loss: 0.0084\n",
      "Epoch 1422/2000\n",
      "45/45 [==============================] - 0s 172us/step - loss: 0.0020 - val_loss: 0.0086\n",
      "Epoch 1423/2000\n",
      "45/45 [==============================] - 0s 148us/step - loss: 0.0020 - val_loss: 0.0084\n",
      "Epoch 1424/2000\n",
      "45/45 [==============================] - 0s 175us/step - loss: 0.0020 - val_loss: 0.0085\n",
      "Epoch 1425/2000\n",
      "45/45 [==============================] - 0s 146us/step - loss: 0.0020 - val_loss: 0.0080\n",
      "Epoch 1426/2000\n",
      "45/45 [==============================] - 0s 161us/step - loss: 0.0020 - val_loss: 0.0082\n",
      "Epoch 1427/2000\n",
      "45/45 [==============================] - 0s 162us/step - loss: 0.0020 - val_loss: 0.0075\n",
      "Epoch 1428/2000\n",
      "45/45 [==============================] - 0s 162us/step - loss: 0.0020 - val_loss: 0.0075\n",
      "Epoch 1429/2000\n",
      "45/45 [==============================] - 0s 168us/step - loss: 0.0020 - val_loss: 0.0073\n",
      "Epoch 1430/2000\n",
      "45/45 [==============================] - 0s 172us/step - loss: 0.0020 - val_loss: 0.0070\n",
      "Epoch 1431/2000\n",
      "45/45 [==============================] - 0s 153us/step - loss: 0.0020 - val_loss: 0.0078\n",
      "Epoch 1432/2000\n",
      "45/45 [==============================] - 0s 154us/step - loss: 0.0020 - val_loss: 0.0079\n",
      "Epoch 1433/2000\n",
      "45/45 [==============================] - 0s 162us/step - loss: 0.0020 - val_loss: 0.0076\n",
      "Epoch 1434/2000\n",
      "45/45 [==============================] - 0s 160us/step - loss: 0.0020 - val_loss: 0.0076\n",
      "Epoch 1435/2000\n",
      "45/45 [==============================] - 0s 164us/step - loss: 0.0020 - val_loss: 0.0084\n",
      "Epoch 1436/2000\n",
      "45/45 [==============================] - 0s 158us/step - loss: 0.0019 - val_loss: 0.0077\n",
      "Epoch 1437/2000\n",
      "45/45 [==============================] - 0s 169us/step - loss: 0.0020 - val_loss: 0.0073\n",
      "Epoch 1438/2000\n",
      "45/45 [==============================] - 0s 154us/step - loss: 0.0019 - val_loss: 0.0068\n",
      "Epoch 1439/2000\n",
      "45/45 [==============================] - 0s 167us/step - loss: 0.0020 - val_loss: 0.0069\n",
      "Epoch 1440/2000\n",
      "45/45 [==============================] - 0s 146us/step - loss: 0.0020 - val_loss: 0.0065\n",
      "Epoch 1441/2000\n",
      "45/45 [==============================] - 0s 219us/step - loss: 0.0019 - val_loss: 0.0067\n",
      "Epoch 1442/2000\n",
      "45/45 [==============================] - 0s 174us/step - loss: 0.0019 - val_loss: 0.0068\n",
      "Epoch 1443/2000\n",
      "45/45 [==============================] - 0s 189us/step - loss: 0.0020 - val_loss: 0.0073\n",
      "Epoch 1444/2000\n",
      "45/45 [==============================] - 0s 176us/step - loss: 0.0019 - val_loss: 0.0073\n",
      "Epoch 1445/2000\n",
      "45/45 [==============================] - 0s 180us/step - loss: 0.0020 - val_loss: 0.0075\n",
      "Epoch 1446/2000\n",
      "45/45 [==============================] - 0s 176us/step - loss: 0.0019 - val_loss: 0.0071\n",
      "Epoch 1447/2000\n",
      "45/45 [==============================] - 0s 179us/step - loss: 0.0019 - val_loss: 0.0075\n",
      "Epoch 1448/2000\n",
      "45/45 [==============================] - 0s 180us/step - loss: 0.0019 - val_loss: 0.0075\n",
      "Epoch 1449/2000\n",
      "45/45 [==============================] - 0s 178us/step - loss: 0.0019 - val_loss: 0.0071\n",
      "Epoch 1450/2000\n",
      "45/45 [==============================] - 0s 179us/step - loss: 0.0019 - val_loss: 0.0069\n",
      "Epoch 1451/2000\n",
      "45/45 [==============================] - 0s 180us/step - loss: 0.0019 - val_loss: 0.0070\n",
      "Epoch 1452/2000\n",
      "45/45 [==============================] - 0s 190us/step - loss: 0.0019 - val_loss: 0.0074\n",
      "Epoch 1453/2000\n",
      "45/45 [==============================] - 0s 182us/step - loss: 0.0020 - val_loss: 0.0074\n",
      "Epoch 1454/2000\n",
      "45/45 [==============================] - 0s 196us/step - loss: 0.0019 - val_loss: 0.0075\n",
      "Epoch 1455/2000\n",
      "45/45 [==============================] - 0s 181us/step - loss: 0.0019 - val_loss: 0.0068\n",
      "Epoch 1456/2000\n",
      "45/45 [==============================] - 0s 203us/step - loss: 0.0019 - val_loss: 0.0069\n",
      "Epoch 1457/2000\n",
      "45/45 [==============================] - 0s 190us/step - loss: 0.0019 - val_loss: 0.0070\n",
      "Epoch 1458/2000\n",
      "45/45 [==============================] - 0s 198us/step - loss: 0.0019 - val_loss: 0.0072\n",
      "Epoch 1459/2000\n",
      "45/45 [==============================] - 0s 182us/step - loss: 0.0019 - val_loss: 0.0067\n",
      "Epoch 1460/2000\n",
      "45/45 [==============================] - 0s 179us/step - loss: 0.0019 - val_loss: 0.0068\n",
      "Epoch 1461/2000\n",
      "45/45 [==============================] - 0s 179us/step - loss: 0.0019 - val_loss: 0.0068\n",
      "Epoch 1462/2000\n",
      "45/45 [==============================] - 0s 182us/step - loss: 0.0019 - val_loss: 0.0071\n",
      "Epoch 1463/2000\n",
      "45/45 [==============================] - 0s 185us/step - loss: 0.0019 - val_loss: 0.0068\n",
      "Epoch 1464/2000\n",
      "45/45 [==============================] - 0s 169us/step - loss: 0.0019 - val_loss: 0.0065\n",
      "Epoch 1465/2000\n",
      "45/45 [==============================] - 0s 175us/step - loss: 0.0019 - val_loss: 0.0067\n",
      "Epoch 1466/2000\n",
      "45/45 [==============================] - 0s 159us/step - loss: 0.0019 - val_loss: 0.0067\n",
      "Epoch 1467/2000\n",
      "45/45 [==============================] - 0s 173us/step - loss: 0.0019 - val_loss: 0.0072\n",
      "Epoch 1468/2000\n",
      "45/45 [==============================] - 0s 156us/step - loss: 0.0019 - val_loss: 0.0071\n",
      "Epoch 1469/2000\n",
      "45/45 [==============================] - 0s 164us/step - loss: 0.0019 - val_loss: 0.0069\n",
      "Epoch 1470/2000\n",
      "45/45 [==============================] - 0s 153us/step - loss: 0.0018 - val_loss: 0.0067\n",
      "Epoch 1471/2000\n",
      "45/45 [==============================] - 0s 149us/step - loss: 0.0019 - val_loss: 0.0070\n",
      "Epoch 1472/2000\n",
      "45/45 [==============================] - 0s 176us/step - loss: 0.0018 - val_loss: 0.0068\n",
      "Epoch 1473/2000\n",
      "45/45 [==============================] - 0s 160us/step - loss: 0.0018 - val_loss: 0.0069\n",
      "Epoch 1474/2000\n",
      "45/45 [==============================] - 0s 171us/step - loss: 0.0019 - val_loss: 0.0070\n",
      "Epoch 1475/2000\n",
      "45/45 [==============================] - 0s 161us/step - loss: 0.0019 - val_loss: 0.0068\n",
      "Epoch 1476/2000\n",
      "45/45 [==============================] - 0s 163us/step - loss: 0.0019 - val_loss: 0.0064\n",
      "Epoch 1477/2000\n",
      "45/45 [==============================] - 0s 158us/step - loss: 0.0018 - val_loss: 0.0068\n",
      "Epoch 1478/2000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "45/45 [==============================] - 0s 185us/step - loss: 0.0018 - val_loss: 0.0067\n",
      "Epoch 1479/2000\n",
      "45/45 [==============================] - 0s 152us/step - loss: 0.0019 - val_loss: 0.0067\n",
      "Epoch 1480/2000\n",
      "45/45 [==============================] - 0s 167us/step - loss: 0.0018 - val_loss: 0.0067\n",
      "Epoch 1481/2000\n",
      "45/45 [==============================] - 0s 163us/step - loss: 0.0018 - val_loss: 0.0062\n",
      "Epoch 1482/2000\n",
      "45/45 [==============================] - 0s 166us/step - loss: 0.0018 - val_loss: 0.0065\n",
      "Epoch 1483/2000\n",
      "45/45 [==============================] - 0s 153us/step - loss: 0.0018 - val_loss: 0.0063\n",
      "Epoch 1484/2000\n",
      "45/45 [==============================] - 0s 167us/step - loss: 0.0018 - val_loss: 0.0064\n",
      "Epoch 1485/2000\n",
      "45/45 [==============================] - 0s 144us/step - loss: 0.0018 - val_loss: 0.0058\n",
      "Epoch 1486/2000\n",
      "45/45 [==============================] - 0s 171us/step - loss: 0.0018 - val_loss: 0.0061\n",
      "Epoch 1487/2000\n",
      "45/45 [==============================] - 0s 158us/step - loss: 0.0018 - val_loss: 0.0062\n",
      "Epoch 1488/2000\n",
      "45/45 [==============================] - 0s 179us/step - loss: 0.0018 - val_loss: 0.0059\n",
      "Epoch 1489/2000\n",
      "45/45 [==============================] - 0s 150us/step - loss: 0.0018 - val_loss: 0.0061\n",
      "Epoch 1490/2000\n",
      "45/45 [==============================] - 0s 178us/step - loss: 0.0018 - val_loss: 0.0064\n",
      "Epoch 1491/2000\n",
      "45/45 [==============================] - 0s 151us/step - loss: 0.0018 - val_loss: 0.0057\n",
      "Epoch 1492/2000\n",
      "45/45 [==============================] - 0s 181us/step - loss: 0.0018 - val_loss: 0.0060\n",
      "Epoch 1493/2000\n",
      "45/45 [==============================] - 0s 158us/step - loss: 0.0018 - val_loss: 0.0057\n",
      "Epoch 1494/2000\n",
      "45/45 [==============================] - 0s 166us/step - loss: 0.0018 - val_loss: 0.0060\n",
      "Epoch 1495/2000\n",
      "45/45 [==============================] - 0s 153us/step - loss: 0.0018 - val_loss: 0.0061\n",
      "Epoch 1496/2000\n",
      "45/45 [==============================] - 0s 158us/step - loss: 0.0018 - val_loss: 0.0056\n",
      "Epoch 1497/2000\n",
      "45/45 [==============================] - 0s 159us/step - loss: 0.0018 - val_loss: 0.0060\n",
      "Epoch 1498/2000\n",
      "45/45 [==============================] - 0s 163us/step - loss: 0.0018 - val_loss: 0.0063\n",
      "Epoch 1499/2000\n",
      "45/45 [==============================] - 0s 162us/step - loss: 0.0018 - val_loss: 0.0068\n",
      "Epoch 1500/2000\n",
      "45/45 [==============================] - 0s 156us/step - loss: 0.0018 - val_loss: 0.0060\n",
      "Epoch 1501/2000\n",
      "45/45 [==============================] - 0s 168us/step - loss: 0.0018 - val_loss: 0.0064\n",
      "Epoch 1502/2000\n",
      "45/45 [==============================] - 0s 148us/step - loss: 0.0018 - val_loss: 0.0062\n",
      "Epoch 1503/2000\n",
      "45/45 [==============================] - 0s 169us/step - loss: 0.0018 - val_loss: 0.0065\n",
      "Epoch 1504/2000\n",
      "45/45 [==============================] - 0s 146us/step - loss: 0.0018 - val_loss: 0.0060\n",
      "Epoch 1505/2000\n",
      "45/45 [==============================] - 0s 166us/step - loss: 0.0018 - val_loss: 0.0061\n",
      "Epoch 1506/2000\n",
      "45/45 [==============================] - 0s 145us/step - loss: 0.0017 - val_loss: 0.0058\n",
      "Epoch 1507/2000\n",
      "45/45 [==============================] - 0s 168us/step - loss: 0.0017 - val_loss: 0.0056\n",
      "Epoch 1508/2000\n",
      "45/45 [==============================] - 0s 144us/step - loss: 0.0018 - val_loss: 0.0060\n",
      "Epoch 1509/2000\n",
      "45/45 [==============================] - 0s 164us/step - loss: 0.0017 - val_loss: 0.0059\n",
      "Epoch 1510/2000\n",
      "45/45 [==============================] - 0s 145us/step - loss: 0.0017 - val_loss: 0.0061\n",
      "Epoch 1511/2000\n",
      "45/45 [==============================] - 0s 148us/step - loss: 0.0017 - val_loss: 0.0058\n",
      "Epoch 1512/2000\n",
      "45/45 [==============================] - 0s 164us/step - loss: 0.0017 - val_loss: 0.0056\n",
      "Epoch 1513/2000\n",
      "45/45 [==============================] - 0s 153us/step - loss: 0.0017 - val_loss: 0.0062\n",
      "Epoch 1514/2000\n",
      "45/45 [==============================] - 0s 170us/step - loss: 0.0017 - val_loss: 0.0063\n",
      "Epoch 1515/2000\n",
      "45/45 [==============================] - 0s 154us/step - loss: 0.0017 - val_loss: 0.0059\n",
      "Epoch 1516/2000\n",
      "45/45 [==============================] - 0s 169us/step - loss: 0.0017 - val_loss: 0.0056\n",
      "Epoch 1517/2000\n",
      "45/45 [==============================] - 0s 154us/step - loss: 0.0018 - val_loss: 0.0060\n",
      "Epoch 1518/2000\n",
      "45/45 [==============================] - 0s 169us/step - loss: 0.0017 - val_loss: 0.0059\n",
      "Epoch 1519/2000\n",
      "45/45 [==============================] - 0s 146us/step - loss: 0.0018 - val_loss: 0.0059\n",
      "Epoch 1520/2000\n",
      "45/45 [==============================] - 0s 167us/step - loss: 0.0017 - val_loss: 0.0062\n",
      "Epoch 1521/2000\n",
      "45/45 [==============================] - 0s 146us/step - loss: 0.0018 - val_loss: 0.0057\n",
      "Epoch 1522/2000\n",
      "45/45 [==============================] - 0s 170us/step - loss: 0.0017 - val_loss: 0.0058\n",
      "Epoch 1523/2000\n",
      "45/45 [==============================] - 0s 150us/step - loss: 0.0017 - val_loss: 0.0059\n",
      "Epoch 1524/2000\n",
      "45/45 [==============================] - 0s 156us/step - loss: 0.0017 - val_loss: 0.0054\n",
      "Epoch 1525/2000\n",
      "45/45 [==============================] - 0s 164us/step - loss: 0.0017 - val_loss: 0.0056\n",
      "Epoch 1526/2000\n",
      "45/45 [==============================] - 0s 152us/step - loss: 0.0017 - val_loss: 0.0052\n",
      "Epoch 1527/2000\n",
      "45/45 [==============================] - 0s 165us/step - loss: 0.0017 - val_loss: 0.0054\n",
      "Epoch 1528/2000\n",
      "45/45 [==============================] - 0s 151us/step - loss: 0.0017 - val_loss: 0.0054\n",
      "Epoch 1529/2000\n",
      "45/45 [==============================] - 0s 171us/step - loss: 0.0017 - val_loss: 0.0052\n",
      "Epoch 1530/2000\n",
      "45/45 [==============================] - 0s 154us/step - loss: 0.0017 - val_loss: 0.0052\n",
      "Epoch 1531/2000\n",
      "45/45 [==============================] - 0s 167us/step - loss: 0.0017 - val_loss: 0.0053\n",
      "Epoch 1532/2000\n",
      "45/45 [==============================] - 0s 150us/step - loss: 0.0017 - val_loss: 0.0052\n",
      "Epoch 1533/2000\n",
      "45/45 [==============================] - 0s 169us/step - loss: 0.0017 - val_loss: 0.0054\n",
      "Epoch 1534/2000\n",
      "45/45 [==============================] - 0s 147us/step - loss: 0.0017 - val_loss: 0.0052\n",
      "Epoch 1535/2000\n",
      "45/45 [==============================] - 0s 164us/step - loss: 0.0017 - val_loss: 0.0049\n",
      "Epoch 1536/2000\n",
      "45/45 [==============================] - 0s 153us/step - loss: 0.0017 - val_loss: 0.0048\n",
      "Epoch 1537/2000\n",
      "45/45 [==============================] - 0s 167us/step - loss: 0.0017 - val_loss: 0.0046\n",
      "Epoch 1538/2000\n",
      "45/45 [==============================] - 0s 162us/step - loss: 0.0017 - val_loss: 0.0048\n",
      "Epoch 1539/2000\n",
      "45/45 [==============================] - 0s 157us/step - loss: 0.0017 - val_loss: 0.0048\n",
      "Epoch 1540/2000\n",
      "45/45 [==============================] - 0s 169us/step - loss: 0.0017 - val_loss: 0.0046\n",
      "Epoch 1541/2000\n",
      "45/45 [==============================] - 0s 157us/step - loss: 0.0017 - val_loss: 0.0052\n",
      "Epoch 1542/2000\n",
      "45/45 [==============================] - 0s 165us/step - loss: 0.0017 - val_loss: 0.0049\n",
      "Epoch 1543/2000\n",
      "45/45 [==============================] - 0s 157us/step - loss: 0.0017 - val_loss: 0.0052\n",
      "Epoch 1544/2000\n",
      "45/45 [==============================] - 0s 170us/step - loss: 0.0017 - val_loss: 0.0045\n",
      "Epoch 1545/2000\n",
      "45/45 [==============================] - 0s 150us/step - loss: 0.0016 - val_loss: 0.0047\n",
      "Epoch 1546/2000\n",
      "45/45 [==============================] - 0s 168us/step - loss: 0.0016 - val_loss: 0.0047\n",
      "Epoch 1547/2000\n",
      "45/45 [==============================] - 0s 141us/step - loss: 0.0016 - val_loss: 0.0047\n",
      "Epoch 1548/2000\n",
      "45/45 [==============================] - 0s 161us/step - loss: 0.0017 - val_loss: 0.0046\n",
      "Epoch 1549/2000\n",
      "45/45 [==============================] - 0s 144us/step - loss: 0.0017 - val_loss: 0.0047\n",
      "Epoch 1550/2000\n",
      "45/45 [==============================] - 0s 152us/step - loss: 0.0016 - val_loss: 0.0047\n",
      "Epoch 1551/2000\n",
      "45/45 [==============================] - 0s 162us/step - loss: 0.0016 - val_loss: 0.0048\n",
      "Epoch 1552/2000\n",
      "45/45 [==============================] - 0s 147us/step - loss: 0.0016 - val_loss: 0.0050\n",
      "Epoch 1553/2000\n",
      "45/45 [==============================] - 0s 164us/step - loss: 0.0016 - val_loss: 0.0050\n",
      "Epoch 1554/2000\n",
      "45/45 [==============================] - 0s 162us/step - loss: 0.0016 - val_loss: 0.0048\n",
      "Epoch 1555/2000\n",
      "45/45 [==============================] - 0s 164us/step - loss: 0.0016 - val_loss: 0.0046\n",
      "Epoch 1556/2000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "45/45 [==============================] - 0s 143us/step - loss: 0.0016 - val_loss: 0.0049\n",
      "Epoch 1557/2000\n",
      "45/45 [==============================] - 0s 170us/step - loss: 0.0016 - val_loss: 0.0045\n",
      "Epoch 1558/2000\n",
      "45/45 [==============================] - 0s 161us/step - loss: 0.0016 - val_loss: 0.0046\n",
      "Epoch 1559/2000\n",
      "45/45 [==============================] - 0s 163us/step - loss: 0.0016 - val_loss: 0.0044\n",
      "Epoch 1560/2000\n",
      "45/45 [==============================] - 0s 151us/step - loss: 0.0016 - val_loss: 0.0050\n",
      "Epoch 1561/2000\n",
      "45/45 [==============================] - 0s 168us/step - loss: 0.0016 - val_loss: 0.0049\n",
      "Epoch 1562/2000\n",
      "45/45 [==============================] - 0s 142us/step - loss: 0.0016 - val_loss: 0.0045\n",
      "Epoch 1563/2000\n",
      "45/45 [==============================] - 0s 162us/step - loss: 0.0016 - val_loss: 0.0040\n",
      "Epoch 1564/2000\n",
      "45/45 [==============================] - 0s 144us/step - loss: 0.0016 - val_loss: 0.0046\n",
      "Epoch 1565/2000\n",
      "45/45 [==============================] - 0s 157us/step - loss: 0.0016 - val_loss: 0.0045\n",
      "Epoch 1566/2000\n",
      "45/45 [==============================] - 0s 152us/step - loss: 0.0016 - val_loss: 0.0047\n",
      "Epoch 1567/2000\n",
      "45/45 [==============================] - 0s 152us/step - loss: 0.0016 - val_loss: 0.0043\n",
      "Epoch 1568/2000\n",
      "45/45 [==============================] - 0s 170us/step - loss: 0.0016 - val_loss: 0.0044\n",
      "Epoch 1569/2000\n",
      "45/45 [==============================] - 0s 149us/step - loss: 0.0016 - val_loss: 0.0044\n",
      "Epoch 1570/2000\n",
      "45/45 [==============================] - 0s 170us/step - loss: 0.0016 - val_loss: 0.0046\n",
      "Epoch 1571/2000\n",
      "45/45 [==============================] - 0s 148us/step - loss: 0.0016 - val_loss: 0.0047\n",
      "Epoch 1572/2000\n",
      "45/45 [==============================] - 0s 168us/step - loss: 0.0016 - val_loss: 0.0046\n",
      "Epoch 1573/2000\n",
      "45/45 [==============================] - 0s 144us/step - loss: 0.0016 - val_loss: 0.0048\n",
      "Epoch 1574/2000\n",
      "45/45 [==============================] - 0s 161us/step - loss: 0.0016 - val_loss: 0.0044\n",
      "Epoch 1575/2000\n",
      "45/45 [==============================] - 0s 144us/step - loss: 0.0016 - val_loss: 0.0045\n",
      "Epoch 1576/2000\n",
      "45/45 [==============================] - 0s 153us/step - loss: 0.0016 - val_loss: 0.0043\n",
      "Epoch 1577/2000\n",
      "45/45 [==============================] - 0s 160us/step - loss: 0.0016 - val_loss: 0.0048\n",
      "Epoch 1578/2000\n",
      "45/45 [==============================] - 0s 173us/step - loss: 0.0016 - val_loss: 0.0044\n",
      "Epoch 1579/2000\n",
      "45/45 [==============================] - 0s 164us/step - loss: 0.0016 - val_loss: 0.0045\n",
      "Epoch 1580/2000\n",
      "45/45 [==============================] - 0s 165us/step - loss: 0.0016 - val_loss: 0.0046\n",
      "Epoch 1581/2000\n",
      "45/45 [==============================] - 0s 167us/step - loss: 0.0016 - val_loss: 0.0045\n",
      "Epoch 1582/2000\n",
      "45/45 [==============================] - 0s 160us/step - loss: 0.0015 - val_loss: 0.0043\n",
      "Epoch 1583/2000\n",
      "45/45 [==============================] - 0s 166us/step - loss: 0.0016 - val_loss: 0.0041\n",
      "Epoch 1584/2000\n",
      "45/45 [==============================] - 0s 152us/step - loss: 0.0015 - val_loss: 0.0043\n",
      "Epoch 1585/2000\n",
      "45/45 [==============================] - 0s 168us/step - loss: 0.0016 - val_loss: 0.0044\n",
      "Epoch 1586/2000\n",
      "45/45 [==============================] - 0s 141us/step - loss: 0.0015 - val_loss: 0.0045\n",
      "Epoch 1587/2000\n",
      "45/45 [==============================] - 0s 161us/step - loss: 0.0015 - val_loss: 0.0042\n",
      "Epoch 1588/2000\n",
      "45/45 [==============================] - 0s 143us/step - loss: 0.0015 - val_loss: 0.0041\n",
      "Epoch 1589/2000\n",
      "45/45 [==============================] - 0s 170us/step - loss: 0.0015 - val_loss: 0.0041\n",
      "Epoch 1590/2000\n",
      "45/45 [==============================] - 0s 142us/step - loss: 0.0016 - val_loss: 0.0041\n",
      "Epoch 1591/2000\n",
      "45/45 [==============================] - 0s 170us/step - loss: 0.0015 - val_loss: 0.0044\n",
      "Epoch 1592/2000\n",
      "45/45 [==============================] - 0s 149us/step - loss: 0.0016 - val_loss: 0.0041\n",
      "Epoch 1593/2000\n",
      "45/45 [==============================] - 0s 158us/step - loss: 0.0015 - val_loss: 0.0041\n",
      "Epoch 1594/2000\n",
      "45/45 [==============================] - 0s 157us/step - loss: 0.0015 - val_loss: 0.0042\n",
      "Epoch 1595/2000\n",
      "45/45 [==============================] - 0s 144us/step - loss: 0.0015 - val_loss: 0.0037\n",
      "Epoch 1596/2000\n",
      "45/45 [==============================] - 0s 166us/step - loss: 0.0015 - val_loss: 0.0042\n",
      "Epoch 1597/2000\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.001 - 0s 149us/step - loss: 0.0015 - val_loss: 0.0042\n",
      "Epoch 1598/2000\n",
      "45/45 [==============================] - 0s 172us/step - loss: 0.0015 - val_loss: 0.0041\n",
      "Epoch 1599/2000\n",
      "45/45 [==============================] - 0s 146us/step - loss: 0.0015 - val_loss: 0.0041\n",
      "Epoch 1600/2000\n",
      "45/45 [==============================] - 0s 167us/step - loss: 0.0015 - val_loss: 0.0043\n",
      "Epoch 1601/2000\n",
      "45/45 [==============================] - 0s 157us/step - loss: 0.0015 - val_loss: 0.0041\n",
      "Epoch 1602/2000\n",
      "45/45 [==============================] - 0s 246us/step - loss: 0.0015 - val_loss: 0.0042\n",
      "Epoch 1603/2000\n",
      "45/45 [==============================] - 0s 226us/step - loss: 0.0015 - val_loss: 0.0038\n",
      "Epoch 1604/2000\n",
      "45/45 [==============================] - 0s 204us/step - loss: 0.0015 - val_loss: 0.0038\n",
      "Epoch 1605/2000\n",
      "45/45 [==============================] - 0s 186us/step - loss: 0.0015 - val_loss: 0.0043\n",
      "Epoch 1606/2000\n",
      "45/45 [==============================] - 0s 166us/step - loss: 0.0015 - val_loss: 0.0041\n",
      "Epoch 1607/2000\n",
      "45/45 [==============================] - 0s 174us/step - loss: 0.0015 - val_loss: 0.0038\n",
      "Epoch 1608/2000\n",
      "45/45 [==============================] - 0s 161us/step - loss: 0.0015 - val_loss: 0.0042\n",
      "Epoch 1609/2000\n",
      "45/45 [==============================] - 0s 202us/step - loss: 0.0015 - val_loss: 0.0043\n",
      "Epoch 1610/2000\n",
      "45/45 [==============================] - 0s 163us/step - loss: 0.0015 - val_loss: 0.0041\n",
      "Epoch 1611/2000\n",
      "45/45 [==============================] - 0s 174us/step - loss: 0.0015 - val_loss: 0.0043\n",
      "Epoch 1612/2000\n",
      "45/45 [==============================] - 0s 159us/step - loss: 0.0015 - val_loss: 0.0042\n",
      "Epoch 1613/2000\n",
      "45/45 [==============================] - 0s 169us/step - loss: 0.0015 - val_loss: 0.0043\n",
      "Epoch 1614/2000\n",
      "45/45 [==============================] - 0s 151us/step - loss: 0.0015 - val_loss: 0.0039\n",
      "Epoch 1615/2000\n",
      "45/45 [==============================] - 0s 162us/step - loss: 0.0015 - val_loss: 0.0037\n",
      "Epoch 1616/2000\n",
      "45/45 [==============================] - 0s 153us/step - loss: 0.0015 - val_loss: 0.0037\n",
      "Epoch 1617/2000\n",
      "45/45 [==============================] - 0s 150us/step - loss: 0.0015 - val_loss: 0.0036\n",
      "Epoch 1618/2000\n",
      "45/45 [==============================] - 0s 153us/step - loss: 0.0015 - val_loss: 0.0038\n",
      "Epoch 1619/2000\n",
      "45/45 [==============================] - 0s 151us/step - loss: 0.0015 - val_loss: 0.0038\n",
      "Epoch 1620/2000\n",
      "45/45 [==============================] - 0s 168us/step - loss: 0.0015 - val_loss: 0.0038\n",
      "Epoch 1621/2000\n",
      "45/45 [==============================] - 0s 148us/step - loss: 0.0015 - val_loss: 0.0036\n",
      "Epoch 1622/2000\n",
      "45/45 [==============================] - 0s 163us/step - loss: 0.0015 - val_loss: 0.0037\n",
      "Epoch 1623/2000\n",
      "45/45 [==============================] - 0s 144us/step - loss: 0.0015 - val_loss: 0.0036\n",
      "Epoch 1624/2000\n",
      "45/45 [==============================] - 0s 172us/step - loss: 0.0015 - val_loss: 0.0035\n",
      "Epoch 1625/2000\n",
      "45/45 [==============================] - 0s 139us/step - loss: 0.0015 - val_loss: 0.0034\n",
      "Epoch 1626/2000\n",
      "45/45 [==============================] - 0s 160us/step - loss: 0.0015 - val_loss: 0.0037\n",
      "Epoch 1627/2000\n",
      "45/45 [==============================] - 0s 159us/step - loss: 0.0015 - val_loss: 0.0036\n",
      "Epoch 1628/2000\n",
      "45/45 [==============================] - 0s 154us/step - loss: 0.0014 - val_loss: 0.0034\n",
      "Epoch 1629/2000\n",
      "45/45 [==============================] - 0s 159us/step - loss: 0.0014 - val_loss: 0.0037\n",
      "Epoch 1630/2000\n",
      "45/45 [==============================] - 0s 160us/step - loss: 0.0015 - val_loss: 0.0034\n",
      "Epoch 1631/2000\n",
      "45/45 [==============================] - 0s 154us/step - loss: 0.0015 - val_loss: 0.0033\n",
      "Epoch 1632/2000\n",
      "45/45 [==============================] - 0s 147us/step - loss: 0.0015 - val_loss: 0.0033\n",
      "Epoch 1633/2000\n",
      "45/45 [==============================] - 0s 162us/step - loss: 0.0015 - val_loss: 0.0031\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1634/2000\n",
      "45/45 [==============================] - 0s 149us/step - loss: 0.0014 - val_loss: 0.0034\n",
      "Epoch 1635/2000\n",
      "45/45 [==============================] - 0s 167us/step - loss: 0.0014 - val_loss: 0.0033\n",
      "Epoch 1636/2000\n",
      "45/45 [==============================] - 0s 157us/step - loss: 0.0014 - val_loss: 0.0035\n",
      "Epoch 1637/2000\n",
      "45/45 [==============================] - 0s 172us/step - loss: 0.0014 - val_loss: 0.0034\n",
      "Epoch 1638/2000\n",
      "45/45 [==============================] - 0s 151us/step - loss: 0.0014 - val_loss: 0.0035\n",
      "Epoch 1639/2000\n",
      "45/45 [==============================] - 0s 163us/step - loss: 0.0014 - val_loss: 0.0034\n",
      "Epoch 1640/2000\n",
      "45/45 [==============================] - 0s 155us/step - loss: 0.0014 - val_loss: 0.0032\n",
      "Epoch 1641/2000\n",
      "45/45 [==============================] - 0s 177us/step - loss: 0.0014 - val_loss: 0.0034\n",
      "Epoch 1642/2000\n",
      "45/45 [==============================] - 0s 143us/step - loss: 0.0014 - val_loss: 0.0033\n",
      "Epoch 1643/2000\n",
      "45/45 [==============================] - 0s 171us/step - loss: 0.0014 - val_loss: 0.0034\n",
      "Epoch 1644/2000\n",
      "45/45 [==============================] - 0s 137us/step - loss: 0.0014 - val_loss: 0.0037\n",
      "Epoch 1645/2000\n",
      "45/45 [==============================] - 0s 163us/step - loss: 0.0014 - val_loss: 0.0035\n",
      "Epoch 1646/2000\n",
      "45/45 [==============================] - 0s 146us/step - loss: 0.0014 - val_loss: 0.0032\n",
      "Epoch 1647/2000\n",
      "45/45 [==============================] - 0s 149us/step - loss: 0.0014 - val_loss: 0.0033\n",
      "Epoch 1648/2000\n",
      "45/45 [==============================] - 0s 159us/step - loss: 0.0014 - val_loss: 0.0034\n",
      "Epoch 1649/2000\n",
      "45/45 [==============================] - 0s 150us/step - loss: 0.0014 - val_loss: 0.0033\n",
      "Epoch 1650/2000\n",
      "45/45 [==============================] - 0s 168us/step - loss: 0.0014 - val_loss: 0.0033\n",
      "Epoch 1651/2000\n",
      "45/45 [==============================] - 0s 158us/step - loss: 0.0014 - val_loss: 0.0032\n",
      "Epoch 1652/2000\n",
      "45/45 [==============================] - 0s 163us/step - loss: 0.0014 - val_loss: 0.0030\n",
      "Epoch 1653/2000\n",
      "45/45 [==============================] - 0s 148us/step - loss: 0.0014 - val_loss: 0.0028\n",
      "Epoch 1654/2000\n",
      "45/45 [==============================] - 0s 170us/step - loss: 0.0014 - val_loss: 0.0030\n",
      "Epoch 1655/2000\n",
      "45/45 [==============================] - 0s 152us/step - loss: 0.0014 - val_loss: 0.0030\n",
      "Epoch 1656/2000\n",
      "45/45 [==============================] - 0s 170us/step - loss: 0.0014 - val_loss: 0.0031\n",
      "Epoch 1657/2000\n",
      "45/45 [==============================] - 0s 146us/step - loss: 0.0014 - val_loss: 0.0033\n",
      "Epoch 1658/2000\n",
      "45/45 [==============================] - 0s 160us/step - loss: 0.0014 - val_loss: 0.0033\n",
      "Epoch 1659/2000\n",
      "45/45 [==============================] - 0s 148us/step - loss: 0.0014 - val_loss: 0.0033\n",
      "Epoch 1660/2000\n",
      "45/45 [==============================] - 0s 154us/step - loss: 0.0014 - val_loss: 0.0035\n",
      "Epoch 1661/2000\n",
      "45/45 [==============================] - 0s 147us/step - loss: 0.0014 - val_loss: 0.0035\n",
      "Epoch 1662/2000\n",
      "45/45 [==============================] - 0s 143us/step - loss: 0.0014 - val_loss: 0.0030\n",
      "Epoch 1663/2000\n",
      "45/45 [==============================] - 0s 164us/step - loss: 0.0014 - val_loss: 0.0030\n",
      "Epoch 1664/2000\n",
      "45/45 [==============================] - 0s 139us/step - loss: 0.0014 - val_loss: 0.0032\n",
      "Epoch 1665/2000\n",
      "45/45 [==============================] - 0s 169us/step - loss: 0.0014 - val_loss: 0.0031\n",
      "Epoch 1666/2000\n",
      "45/45 [==============================] - 0s 151us/step - loss: 0.0014 - val_loss: 0.0032\n",
      "Epoch 1667/2000\n",
      "45/45 [==============================] - 0s 171us/step - loss: 0.0014 - val_loss: 0.0031\n",
      "Epoch 1668/2000\n",
      "45/45 [==============================] - 0s 148us/step - loss: 0.0014 - val_loss: 0.0029\n",
      "Epoch 1669/2000\n",
      "45/45 [==============================] - 0s 160us/step - loss: 0.0014 - val_loss: 0.0032\n",
      "Epoch 1670/2000\n",
      "45/45 [==============================] - 0s 157us/step - loss: 0.0014 - val_loss: 0.0032\n",
      "Epoch 1671/2000\n",
      "45/45 [==============================] - 0s 172us/step - loss: 0.0014 - val_loss: 0.0032\n",
      "Epoch 1672/2000\n",
      "45/45 [==============================] - 0s 159us/step - loss: 0.0014 - val_loss: 0.0033\n",
      "Epoch 1673/2000\n",
      "45/45 [==============================] - 0s 163us/step - loss: 0.0014 - val_loss: 0.0031\n",
      "Epoch 1674/2000\n",
      "45/45 [==============================] - 0s 173us/step - loss: 0.0014 - val_loss: 0.0034\n",
      "Epoch 1675/2000\n",
      "45/45 [==============================] - 0s 157us/step - loss: 0.0014 - val_loss: 0.0032\n",
      "Epoch 1676/2000\n",
      "45/45 [==============================] - 0s 164us/step - loss: 0.0014 - val_loss: 0.0028\n",
      "Epoch 1677/2000\n",
      "45/45 [==============================] - 0s 147us/step - loss: 0.0014 - val_loss: 0.0030\n",
      "Epoch 1678/2000\n",
      "45/45 [==============================] - 0s 181us/step - loss: 0.0014 - val_loss: 0.0027\n",
      "Epoch 1679/2000\n",
      "45/45 [==============================] - 0s 155us/step - loss: 0.0014 - val_loss: 0.0029\n",
      "Epoch 1680/2000\n",
      "45/45 [==============================] - 0s 164us/step - loss: 0.0014 - val_loss: 0.0031\n",
      "Epoch 1681/2000\n",
      "45/45 [==============================] - 0s 143us/step - loss: 0.0014 - val_loss: 0.0033\n",
      "Epoch 1682/2000\n",
      "45/45 [==============================] - 0s 169us/step - loss: 0.0014 - val_loss: 0.0031\n",
      "Epoch 1683/2000\n",
      "45/45 [==============================] - 0s 140us/step - loss: 0.0013 - val_loss: 0.0029\n",
      "Epoch 1684/2000\n",
      "45/45 [==============================] - 0s 154us/step - loss: 0.0013 - val_loss: 0.0028\n",
      "Epoch 1685/2000\n",
      "45/45 [==============================] - 0s 158us/step - loss: 0.0013 - val_loss: 0.0028\n",
      "Epoch 1686/2000\n",
      "45/45 [==============================] - 0s 149us/step - loss: 0.0013 - val_loss: 0.0028\n",
      "Epoch 1687/2000\n",
      "45/45 [==============================] - 0s 164us/step - loss: 0.0013 - val_loss: 0.0029\n",
      "Epoch 1688/2000\n",
      "45/45 [==============================] - 0s 148us/step - loss: 0.0013 - val_loss: 0.0026\n",
      "Epoch 1689/2000\n",
      "45/45 [==============================] - 0s 162us/step - loss: 0.0013 - val_loss: 0.0027\n",
      "Epoch 1690/2000\n",
      "45/45 [==============================] - 0s 148us/step - loss: 0.0014 - val_loss: 0.0027\n",
      "Epoch 1691/2000\n",
      "45/45 [==============================] - 0s 170us/step - loss: 0.0013 - val_loss: 0.0027\n",
      "Epoch 1692/2000\n",
      "45/45 [==============================] - 0s 155us/step - loss: 0.0013 - val_loss: 0.0029\n",
      "Epoch 1693/2000\n",
      "45/45 [==============================] - 0s 166us/step - loss: 0.0013 - val_loss: 0.0029\n",
      "Epoch 1694/2000\n",
      "45/45 [==============================] - 0s 148us/step - loss: 0.0013 - val_loss: 0.0029\n",
      "Epoch 1695/2000\n",
      "45/45 [==============================] - 0s 162us/step - loss: 0.0013 - val_loss: 0.0031\n",
      "Epoch 1696/2000\n",
      "45/45 [==============================] - 0s 151us/step - loss: 0.0013 - val_loss: 0.0029\n",
      "Epoch 1697/2000\n",
      "45/45 [==============================] - 0s 158us/step - loss: 0.0013 - val_loss: 0.0030\n",
      "Epoch 1698/2000\n",
      "45/45 [==============================] - 0s 170us/step - loss: 0.0013 - val_loss: 0.0029\n",
      "Epoch 1699/2000\n",
      "45/45 [==============================] - 0s 156us/step - loss: 0.0014 - val_loss: 0.0026\n",
      "Epoch 1700/2000\n",
      "45/45 [==============================] - 0s 156us/step - loss: 0.0013 - val_loss: 0.0027\n",
      "Epoch 1701/2000\n",
      "45/45 [==============================] - 0s 152us/step - loss: 0.0013 - val_loss: 0.0028\n",
      "Epoch 1702/2000\n",
      "45/45 [==============================] - 0s 168us/step - loss: 0.0013 - val_loss: 0.0028\n",
      "Epoch 1703/2000\n",
      "45/45 [==============================] - 0s 155us/step - loss: 0.0013 - val_loss: 0.0028\n",
      "Epoch 1704/2000\n",
      "45/45 [==============================] - 0s 163us/step - loss: 0.0013 - val_loss: 0.0028\n",
      "Epoch 1705/2000\n",
      "45/45 [==============================] - 0s 159us/step - loss: 0.0013 - val_loss: 0.0029\n",
      "Epoch 1706/2000\n",
      "45/45 [==============================] - 0s 178us/step - loss: 0.0013 - val_loss: 0.0027\n",
      "Epoch 1707/2000\n",
      "45/45 [==============================] - 0s 149us/step - loss: 0.0013 - val_loss: 0.0026\n",
      "Epoch 1708/2000\n",
      "45/45 [==============================] - 0s 169us/step - loss: 0.0013 - val_loss: 0.0026\n",
      "Epoch 1709/2000\n",
      "45/45 [==============================] - 0s 146us/step - loss: 0.0013 - val_loss: 0.0027\n",
      "Epoch 1710/2000\n",
      "45/45 [==============================] - 0s 157us/step - loss: 0.0013 - val_loss: 0.0026\n",
      "Epoch 1711/2000\n",
      "45/45 [==============================] - 0s 149us/step - loss: 0.0013 - val_loss: 0.0026\n",
      "Epoch 1712/2000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "45/45 [==============================] - 0s 151us/step - loss: 0.0013 - val_loss: 0.0028\n",
      "Epoch 1713/2000\n",
      "45/45 [==============================] - 0s 163us/step - loss: 0.0013 - val_loss: 0.0027\n",
      "Epoch 1714/2000\n",
      "45/45 [==============================] - 0s 152us/step - loss: 0.0013 - val_loss: 0.0026\n",
      "Epoch 1715/2000\n",
      "45/45 [==============================] - 0s 162us/step - loss: 0.0013 - val_loss: 0.0028\n",
      "Epoch 1716/2000\n",
      "45/45 [==============================] - 0s 152us/step - loss: 0.0013 - val_loss: 0.0027\n",
      "Epoch 1717/2000\n",
      "45/45 [==============================] - 0s 153us/step - loss: 0.0013 - val_loss: 0.0026\n",
      "Epoch 1718/2000\n",
      "45/45 [==============================] - 0s 138us/step - loss: 0.0013 - val_loss: 0.0026\n",
      "Epoch 1719/2000\n",
      "45/45 [==============================] - 0s 170us/step - loss: 0.0013 - val_loss: 0.0027\n",
      "Epoch 1720/2000\n",
      "45/45 [==============================] - 0s 151us/step - loss: 0.0013 - val_loss: 0.0027\n",
      "Epoch 1721/2000\n",
      "45/45 [==============================] - 0s 177us/step - loss: 0.0013 - val_loss: 0.0027\n",
      "Epoch 1722/2000\n",
      "45/45 [==============================] - 0s 146us/step - loss: 0.0013 - val_loss: 0.0027\n",
      "Epoch 1723/2000\n",
      "45/45 [==============================] - 0s 170us/step - loss: 0.0013 - val_loss: 0.0028\n",
      "Epoch 1724/2000\n",
      "45/45 [==============================] - 0s 141us/step - loss: 0.0013 - val_loss: 0.0028\n",
      "Epoch 1725/2000\n",
      "45/45 [==============================] - 0s 160us/step - loss: 0.0013 - val_loss: 0.0025\n",
      "Epoch 1726/2000\n",
      "45/45 [==============================] - 0s 158us/step - loss: 0.0013 - val_loss: 0.0026\n",
      "Epoch 1727/2000\n",
      "45/45 [==============================] - 0s 151us/step - loss: 0.0013 - val_loss: 0.0024\n",
      "Epoch 1728/2000\n",
      "45/45 [==============================] - 0s 173us/step - loss: 0.0013 - val_loss: 0.0024\n",
      "Epoch 1729/2000\n",
      "45/45 [==============================] - 0s 150us/step - loss: 0.0013 - val_loss: 0.0024\n",
      "Epoch 1730/2000\n",
      "45/45 [==============================] - 0s 169us/step - loss: 0.0013 - val_loss: 0.0025\n",
      "Epoch 1731/2000\n",
      "45/45 [==============================] - 0s 156us/step - loss: 0.0013 - val_loss: 0.0025\n",
      "Epoch 1732/2000\n",
      "45/45 [==============================] - 0s 170us/step - loss: 0.0013 - val_loss: 0.0024\n",
      "Epoch 1733/2000\n",
      "45/45 [==============================] - 0s 155us/step - loss: 0.0013 - val_loss: 0.0026\n",
      "Epoch 1734/2000\n",
      "45/45 [==============================] - 0s 169us/step - loss: 0.0013 - val_loss: 0.0025\n",
      "Epoch 1735/2000\n",
      "45/45 [==============================] - 0s 151us/step - loss: 0.0013 - val_loss: 0.0024\n",
      "Epoch 1736/2000\n",
      "45/45 [==============================] - 0s 165us/step - loss: 0.0013 - val_loss: 0.0024\n",
      "Epoch 1737/2000\n",
      "45/45 [==============================] - 0s 153us/step - loss: 0.0012 - val_loss: 0.0025\n",
      "Epoch 1738/2000\n",
      "45/45 [==============================] - 0s 170us/step - loss: 0.0013 - val_loss: 0.0026\n",
      "Epoch 1739/2000\n",
      "45/45 [==============================] - 0s 139us/step - loss: 0.0013 - val_loss: 0.0025\n",
      "Epoch 1740/2000\n",
      "45/45 [==============================] - 0s 164us/step - loss: 0.0012 - val_loss: 0.0024\n",
      "Epoch 1741/2000\n",
      "45/45 [==============================] - 0s 152us/step - loss: 0.0012 - val_loss: 0.0023\n",
      "Epoch 1742/2000\n",
      "45/45 [==============================] - 0s 161us/step - loss: 0.0012 - val_loss: 0.0023\n",
      "Epoch 1743/2000\n",
      "45/45 [==============================] - 0s 171us/step - loss: 0.0012 - val_loss: 0.0022\n",
      "Epoch 1744/2000\n",
      "45/45 [==============================] - 0s 151us/step - loss: 0.0013 - val_loss: 0.0024\n",
      "Epoch 1745/2000\n",
      "45/45 [==============================] - 0s 163us/step - loss: 0.0012 - val_loss: 0.0022\n",
      "Epoch 1746/2000\n",
      "45/45 [==============================] - 0s 150us/step - loss: 0.0013 - val_loss: 0.0022\n",
      "Epoch 1747/2000\n",
      "45/45 [==============================] - 0s 182us/step - loss: 0.0012 - val_loss: 0.0025\n",
      "Epoch 1748/2000\n",
      "45/45 [==============================] - 0s 154us/step - loss: 0.0012 - val_loss: 0.0024\n",
      "Epoch 1749/2000\n",
      "45/45 [==============================] - 0s 175us/step - loss: 0.0012 - val_loss: 0.0023\n",
      "Epoch 1750/2000\n",
      "45/45 [==============================] - 0s 157us/step - loss: 0.0012 - val_loss: 0.0025\n",
      "Epoch 1751/2000\n",
      "45/45 [==============================] - 0s 165us/step - loss: 0.0013 - val_loss: 0.0026\n",
      "Epoch 1752/2000\n",
      "45/45 [==============================] - 0s 144us/step - loss: 0.0012 - val_loss: 0.0025\n",
      "Epoch 1753/2000\n",
      "45/45 [==============================] - 0s 174us/step - loss: 0.0012 - val_loss: 0.0024\n",
      "Epoch 1754/2000\n",
      "45/45 [==============================] - 0s 155us/step - loss: 0.0012 - val_loss: 0.0025\n",
      "Epoch 1755/2000\n",
      "45/45 [==============================] - 0s 171us/step - loss: 0.0012 - val_loss: 0.0022\n",
      "Epoch 1756/2000\n",
      "45/45 [==============================] - 0s 151us/step - loss: 0.0012 - val_loss: 0.0023\n",
      "Epoch 1757/2000\n",
      "45/45 [==============================] - 0s 161us/step - loss: 0.0012 - val_loss: 0.0023\n",
      "Epoch 1758/2000\n",
      "45/45 [==============================] - 0s 150us/step - loss: 0.0012 - val_loss: 0.0022\n",
      "Epoch 1759/2000\n",
      "45/45 [==============================] - 0s 155us/step - loss: 0.0012 - val_loss: 0.0022\n",
      "Epoch 1760/2000\n",
      "45/45 [==============================] - 0s 153us/step - loss: 0.0012 - val_loss: 0.0023\n",
      "Epoch 1761/2000\n",
      "45/45 [==============================] - 0s 143us/step - loss: 0.0012 - val_loss: 0.0022\n",
      "Epoch 1762/2000\n",
      "45/45 [==============================] - 0s 165us/step - loss: 0.0012 - val_loss: 0.0023\n",
      "Epoch 1763/2000\n",
      "45/45 [==============================] - 0s 141us/step - loss: 0.0012 - val_loss: 0.0022\n",
      "Epoch 1764/2000\n",
      "45/45 [==============================] - 0s 165us/step - loss: 0.0012 - val_loss: 0.0022\n",
      "Epoch 1765/2000\n",
      "45/45 [==============================] - 0s 147us/step - loss: 0.0012 - val_loss: 0.0024\n",
      "Epoch 1766/2000\n",
      "45/45 [==============================] - 0s 164us/step - loss: 0.0012 - val_loss: 0.0024\n",
      "Epoch 1767/2000\n",
      "45/45 [==============================] - 0s 145us/step - loss: 0.0012 - val_loss: 0.0022\n",
      "Epoch 1768/2000\n",
      "45/45 [==============================] - 0s 146us/step - loss: 0.0012 - val_loss: 0.0022\n",
      "Epoch 1769/2000\n",
      "45/45 [==============================] - 0s 154us/step - loss: 0.0012 - val_loss: 0.0023\n",
      "Epoch 1770/2000\n",
      "45/45 [==============================] - 0s 145us/step - loss: 0.0012 - val_loss: 0.0021\n",
      "Epoch 1771/2000\n",
      "45/45 [==============================] - 0s 166us/step - loss: 0.0012 - val_loss: 0.0022\n",
      "Epoch 1772/2000\n",
      "45/45 [==============================] - 0s 153us/step - loss: 0.0012 - val_loss: 0.0021\n",
      "Epoch 1773/2000\n",
      "45/45 [==============================] - 0s 165us/step - loss: 0.0012 - val_loss: 0.0021\n",
      "Epoch 1774/2000\n",
      "45/45 [==============================] - 0s 157us/step - loss: 0.0012 - val_loss: 0.0021\n",
      "Epoch 1775/2000\n",
      "45/45 [==============================] - 0s 171us/step - loss: 0.0012 - val_loss: 0.0022\n",
      "Epoch 1776/2000\n",
      "45/45 [==============================] - 0s 144us/step - loss: 0.0012 - val_loss: 0.0021\n",
      "Epoch 1777/2000\n",
      "45/45 [==============================] - 0s 159us/step - loss: 0.0012 - val_loss: 0.0020\n",
      "Epoch 1778/2000\n",
      "45/45 [==============================] - 0s 151us/step - loss: 0.0012 - val_loss: 0.0021\n",
      "Epoch 1779/2000\n",
      "45/45 [==============================] - 0s 151us/step - loss: 0.0012 - val_loss: 0.0021\n",
      "Epoch 1780/2000\n",
      "45/45 [==============================] - 0s 160us/step - loss: 0.0012 - val_loss: 0.0022\n",
      "Epoch 1781/2000\n",
      "45/45 [==============================] - 0s 146us/step - loss: 0.0012 - val_loss: 0.0019\n",
      "Epoch 1782/2000\n",
      "45/45 [==============================] - 0s 160us/step - loss: 0.0012 - val_loss: 0.0020\n",
      "Epoch 1783/2000\n",
      "45/45 [==============================] - 0s 190us/step - loss: 0.0012 - val_loss: 0.0019\n",
      "Epoch 1784/2000\n",
      "45/45 [==============================] - 0s 178us/step - loss: 0.0012 - val_loss: 0.0021\n",
      "Epoch 1785/2000\n",
      "45/45 [==============================] - 0s 176us/step - loss: 0.0012 - val_loss: 0.0020\n",
      "Epoch 1786/2000\n",
      "45/45 [==============================] - 0s 167us/step - loss: 0.0012 - val_loss: 0.0022\n",
      "Epoch 1787/2000\n",
      "45/45 [==============================] - 0s 153us/step - loss: 0.0012 - val_loss: 0.0024\n",
      "Epoch 1788/2000\n",
      "45/45 [==============================] - 0s 162us/step - loss: 0.0012 - val_loss: 0.0021\n",
      "Epoch 1789/2000\n",
      "45/45 [==============================] - 0s 142us/step - loss: 0.0012 - val_loss: 0.0020\n",
      "Epoch 1790/2000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "45/45 [==============================] - 0s 167us/step - loss: 0.0012 - val_loss: 0.0022\n",
      "Epoch 1791/2000\n",
      "45/45 [==============================] - 0s 144us/step - loss: 0.0012 - val_loss: 0.0020\n",
      "Epoch 1792/2000\n",
      "45/45 [==============================] - 0s 154us/step - loss: 0.0012 - val_loss: 0.0020\n",
      "Epoch 1793/2000\n",
      "45/45 [==============================] - 0s 152us/step - loss: 0.0012 - val_loss: 0.0020\n",
      "Epoch 1794/2000\n",
      "45/45 [==============================] - 0s 169us/step - loss: 0.0012 - val_loss: 0.0021\n",
      "Epoch 1795/2000\n",
      "45/45 [==============================] - 0s 136us/step - loss: 0.0011 - val_loss: 0.0021\n",
      "Epoch 1796/2000\n",
      "45/45 [==============================] - 0s 155us/step - loss: 0.0012 - val_loss: 0.0020\n",
      "Epoch 1797/2000\n",
      "45/45 [==============================] - 0s 146us/step - loss: 0.0011 - val_loss: 0.0020\n",
      "Epoch 1798/2000\n",
      "45/45 [==============================] - 0s 165us/step - loss: 0.0012 - val_loss: 0.0019\n",
      "Epoch 1799/2000\n",
      "45/45 [==============================] - 0s 177us/step - loss: 0.0012 - val_loss: 0.0019\n",
      "Epoch 1800/2000\n",
      "45/45 [==============================] - 0s 156us/step - loss: 0.0012 - val_loss: 0.0020\n",
      "Epoch 1801/2000\n",
      "45/45 [==============================] - 0s 165us/step - loss: 0.0012 - val_loss: 0.0021\n",
      "Epoch 1802/2000\n",
      "45/45 [==============================] - 0s 157us/step - loss: 0.0011 - val_loss: 0.0022\n",
      "Epoch 1803/2000\n",
      "45/45 [==============================] - 0s 181us/step - loss: 0.0012 - val_loss: 0.0020\n",
      "Epoch 1804/2000\n",
      "45/45 [==============================] - 0s 179us/step - loss: 0.0011 - val_loss: 0.0020\n",
      "Epoch 1805/2000\n",
      "45/45 [==============================] - 0s 175us/step - loss: 0.0011 - val_loss: 0.0021\n",
      "Epoch 1806/2000\n",
      "45/45 [==============================] - 0s 162us/step - loss: 0.0011 - val_loss: 0.0019\n",
      "Epoch 1807/2000\n",
      "45/45 [==============================] - 0s 169us/step - loss: 0.0012 - val_loss: 0.0018\n",
      "Epoch 1808/2000\n",
      "45/45 [==============================] - 0s 149us/step - loss: 0.0011 - val_loss: 0.0019\n",
      "Epoch 1809/2000\n",
      "45/45 [==============================] - 0s 167us/step - loss: 0.0011 - val_loss: 0.0020\n",
      "Epoch 1810/2000\n",
      "45/45 [==============================] - 0s 148us/step - loss: 0.0011 - val_loss: 0.0021\n",
      "Epoch 1811/2000\n",
      "45/45 [==============================] - 0s 171us/step - loss: 0.0011 - val_loss: 0.0021\n",
      "Epoch 1812/2000\n",
      "45/45 [==============================] - 0s 151us/step - loss: 0.0011 - val_loss: 0.0021\n",
      "Epoch 1813/2000\n",
      "45/45 [==============================] - 0s 163us/step - loss: 0.0011 - val_loss: 0.0020\n",
      "Epoch 1814/2000\n",
      "45/45 [==============================] - 0s 147us/step - loss: 0.0011 - val_loss: 0.0020\n",
      "Epoch 1815/2000\n",
      "45/45 [==============================] - 0s 158us/step - loss: 0.0011 - val_loss: 0.0021\n",
      "Epoch 1816/2000\n",
      "45/45 [==============================] - 0s 145us/step - loss: 0.0011 - val_loss: 0.0020\n",
      "Epoch 1817/2000\n",
      "45/45 [==============================] - 0s 148us/step - loss: 0.0011 - val_loss: 0.0019\n",
      "Epoch 1818/2000\n",
      "45/45 [==============================] - 0s 154us/step - loss: 0.0011 - val_loss: 0.0018\n",
      "Epoch 1819/2000\n",
      "45/45 [==============================] - 0s 145us/step - loss: 0.0011 - val_loss: 0.0018\n",
      "Epoch 1820/2000\n",
      "45/45 [==============================] - 0s 163us/step - loss: 0.0011 - val_loss: 0.0019\n",
      "Epoch 1821/2000\n",
      "45/45 [==============================] - 0s 136us/step - loss: 0.0011 - val_loss: 0.0019\n",
      "Epoch 1822/2000\n",
      "45/45 [==============================] - 0s 162us/step - loss: 0.0011 - val_loss: 0.0019\n",
      "Epoch 1823/2000\n",
      "45/45 [==============================] - 0s 140us/step - loss: 0.0011 - val_loss: 0.0018\n",
      "Epoch 1824/2000\n",
      "45/45 [==============================] - 0s 152us/step - loss: 0.0011 - val_loss: 0.0018\n",
      "Epoch 1825/2000\n",
      "45/45 [==============================] - 0s 154us/step - loss: 0.0011 - val_loss: 0.0018\n",
      "Epoch 1826/2000\n",
      "45/45 [==============================] - 0s 149us/step - loss: 0.0011 - val_loss: 0.0018\n",
      "Epoch 1827/2000\n",
      "45/45 [==============================] - 0s 163us/step - loss: 0.0011 - val_loss: 0.0018\n",
      "Epoch 1828/2000\n",
      "45/45 [==============================] - 0s 149us/step - loss: 0.0011 - val_loss: 0.0018\n",
      "Epoch 1829/2000\n",
      "45/45 [==============================] - 0s 171us/step - loss: 0.0011 - val_loss: 0.0018\n",
      "Epoch 1830/2000\n",
      "45/45 [==============================] - 0s 161us/step - loss: 0.0011 - val_loss: 0.0019\n",
      "Epoch 1831/2000\n",
      "45/45 [==============================] - 0s 179us/step - loss: 0.0011 - val_loss: 0.0019\n",
      "Epoch 1832/2000\n",
      "45/45 [==============================] - 0s 160us/step - loss: 0.0011 - val_loss: 0.0018\n",
      "Epoch 1833/2000\n",
      "45/45 [==============================] - 0s 171us/step - loss: 0.0011 - val_loss: 0.0018\n",
      "Epoch 1834/2000\n",
      "45/45 [==============================] - 0s 164us/step - loss: 0.0011 - val_loss: 0.0018\n",
      "Epoch 1835/2000\n",
      "45/45 [==============================] - 0s 175us/step - loss: 0.0011 - val_loss: 0.0019\n",
      "Epoch 1836/2000\n",
      "45/45 [==============================] - 0s 160us/step - loss: 0.0011 - val_loss: 0.0018\n",
      "Epoch 1837/2000\n",
      "45/45 [==============================] - 0s 193us/step - loss: 0.0011 - val_loss: 0.0018\n",
      "Epoch 1838/2000\n",
      "45/45 [==============================] - 0s 164us/step - loss: 0.0011 - val_loss: 0.0017\n",
      "Epoch 1839/2000\n",
      "45/45 [==============================] - 0s 215us/step - loss: 0.0011 - val_loss: 0.0018\n",
      "Epoch 1840/2000\n",
      "45/45 [==============================] - 0s 161us/step - loss: 0.0011 - val_loss: 0.0018\n",
      "Epoch 1841/2000\n",
      "45/45 [==============================] - 0s 178us/step - loss: 0.0011 - val_loss: 0.0019\n",
      "Epoch 1842/2000\n",
      "45/45 [==============================] - 0s 170us/step - loss: 0.0011 - val_loss: 0.0018\n",
      "Epoch 1843/2000\n",
      "45/45 [==============================] - 0s 169us/step - loss: 0.0011 - val_loss: 0.0019\n",
      "Epoch 1844/2000\n",
      "45/45 [==============================] - 0s 169us/step - loss: 0.0011 - val_loss: 0.0018\n",
      "Epoch 1845/2000\n",
      "45/45 [==============================] - 0s 162us/step - loss: 0.0011 - val_loss: 0.0019\n",
      "Epoch 1846/2000\n",
      "45/45 [==============================] - 0s 154us/step - loss: 0.0011 - val_loss: 0.0019\n",
      "Epoch 1847/2000\n",
      "45/45 [==============================] - 0s 168us/step - loss: 0.0011 - val_loss: 0.0018\n",
      "Epoch 1848/2000\n",
      "45/45 [==============================] - 0s 154us/step - loss: 0.0011 - val_loss: 0.0018\n",
      "Epoch 1849/2000\n",
      "45/45 [==============================] - 0s 167us/step - loss: 0.0011 - val_loss: 0.0019\n",
      "Epoch 1850/2000\n",
      "45/45 [==============================] - 0s 152us/step - loss: 0.0011 - val_loss: 0.0018\n",
      "Epoch 1851/2000\n",
      "45/45 [==============================] - 0s 170us/step - loss: 0.0011 - val_loss: 0.0018\n",
      "Epoch 1852/2000\n",
      "45/45 [==============================] - 0s 143us/step - loss: 0.0011 - val_loss: 0.0018\n",
      "Epoch 1853/2000\n",
      "45/45 [==============================] - 0s 163us/step - loss: 0.0011 - val_loss: 0.0017\n",
      "Epoch 1854/2000\n",
      "45/45 [==============================] - 0s 144us/step - loss: 0.0011 - val_loss: 0.0017\n",
      "Epoch 1855/2000\n",
      "45/45 [==============================] - 0s 158us/step - loss: 0.0011 - val_loss: 0.0017\n",
      "Epoch 1856/2000\n",
      "45/45 [==============================] - 0s 165us/step - loss: 0.0011 - val_loss: 0.0017\n",
      "Epoch 1857/2000\n",
      "45/45 [==============================] - 0s 160us/step - loss: 0.0011 - val_loss: 0.0017\n",
      "Epoch 1858/2000\n",
      "45/45 [==============================] - 0s 165us/step - loss: 0.0011 - val_loss: 0.0017\n",
      "Epoch 1859/2000\n",
      "45/45 [==============================] - 0s 162us/step - loss: 0.0011 - val_loss: 0.0018\n",
      "Epoch 1860/2000\n",
      "45/45 [==============================] - 0s 166us/step - loss: 0.0011 - val_loss: 0.0017\n",
      "Epoch 1861/2000\n",
      "45/45 [==============================] - 0s 158us/step - loss: 0.0011 - val_loss: 0.0018\n",
      "Epoch 1862/2000\n",
      "45/45 [==============================] - 0s 162us/step - loss: 0.0011 - val_loss: 0.0016\n",
      "Epoch 1863/2000\n",
      "45/45 [==============================] - 0s 150us/step - loss: 0.0011 - val_loss: 0.0018\n",
      "Epoch 1864/2000\n",
      "45/45 [==============================] - 0s 170us/step - loss: 0.0011 - val_loss: 0.0018\n",
      "Epoch 1865/2000\n",
      "45/45 [==============================] - 0s 150us/step - loss: 0.0011 - val_loss: 0.0018\n",
      "Epoch 1866/2000\n",
      "45/45 [==============================] - 0s 166us/step - loss: 0.0011 - val_loss: 0.0017\n",
      "Epoch 1867/2000\n",
      "45/45 [==============================] - 0s 143us/step - loss: 0.0011 - val_loss: 0.0017\n",
      "Epoch 1868/2000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "45/45 [==============================] - 0s 158us/step - loss: 0.0010 - val_loss: 0.0017\n",
      "Epoch 1869/2000\n",
      "45/45 [==============================] - 0s 145us/step - loss: 0.0011 - val_loss: 0.0017\n",
      "Epoch 1870/2000\n",
      "45/45 [==============================] - 0s 155us/step - loss: 0.0011 - val_loss: 0.0017\n",
      "Epoch 1871/2000\n",
      "45/45 [==============================] - 0s 178us/step - loss: 0.0011 - val_loss: 0.0017\n",
      "Epoch 1872/2000\n",
      "45/45 [==============================] - 0s 177us/step - loss: 0.0011 - val_loss: 0.0017\n",
      "Epoch 1873/2000\n",
      "45/45 [==============================] - 0s 153us/step - loss: 0.0010 - val_loss: 0.0017\n",
      "Epoch 1874/2000\n",
      "45/45 [==============================] - 0s 163us/step - loss: 0.0011 - val_loss: 0.0017\n",
      "Epoch 1875/2000\n",
      "45/45 [==============================] - 0s 152us/step - loss: 0.0011 - val_loss: 0.0016\n",
      "Epoch 1876/2000\n",
      "45/45 [==============================] - 0s 156us/step - loss: 0.0011 - val_loss: 0.0016\n",
      "Epoch 1877/2000\n",
      "45/45 [==============================] - 0s 165us/step - loss: 0.0010 - val_loss: 0.0016\n",
      "Epoch 1878/2000\n",
      "45/45 [==============================] - 0s 160us/step - loss: 0.0010 - val_loss: 0.0016\n",
      "Epoch 1879/2000\n",
      "45/45 [==============================] - 0s 165us/step - loss: 0.0010 - val_loss: 0.0017\n",
      "Epoch 1880/2000\n",
      "45/45 [==============================] - 0s 148us/step - loss: 0.0010 - val_loss: 0.0017\n",
      "Epoch 1881/2000\n",
      "45/45 [==============================] - 0s 167us/step - loss: 0.0010 - val_loss: 0.0017\n",
      "Epoch 1882/2000\n",
      "45/45 [==============================] - 0s 150us/step - loss: 0.0010 - val_loss: 0.0017\n",
      "Epoch 1883/2000\n",
      "45/45 [==============================] - 0s 164us/step - loss: 0.0010 - val_loss: 0.0017\n",
      "Epoch 1884/2000\n",
      "45/45 [==============================] - 0s 142us/step - loss: 0.0010 - val_loss: 0.0017\n",
      "Epoch 1885/2000\n",
      "45/45 [==============================] - 0s 164us/step - loss: 0.0010 - val_loss: 0.0017\n",
      "Epoch 1886/2000\n",
      "45/45 [==============================] - 0s 142us/step - loss: 0.0011 - val_loss: 0.0017\n",
      "Epoch 1887/2000\n",
      "45/45 [==============================] - 0s 158us/step - loss: 0.0010 - val_loss: 0.0017\n",
      "Epoch 1888/2000\n",
      "45/45 [==============================] - 0s 148us/step - loss: 0.0010 - val_loss: 0.0017\n",
      "Epoch 1889/2000\n",
      "45/45 [==============================] - 0s 160us/step - loss: 0.0010 - val_loss: 0.0017\n",
      "Epoch 1890/2000\n",
      "45/45 [==============================] - 0s 171us/step - loss: 0.0010 - val_loss: 0.0018\n",
      "Epoch 1891/2000\n",
      "45/45 [==============================] - 0s 153us/step - loss: 0.0010 - val_loss: 0.0018\n",
      "Epoch 1892/2000\n",
      "45/45 [==============================] - 0s 162us/step - loss: 0.0010 - val_loss: 0.0017\n",
      "Epoch 1893/2000\n",
      "45/45 [==============================] - 0s 140us/step - loss: 0.0010 - val_loss: 0.0017\n",
      "Epoch 1894/2000\n",
      "45/45 [==============================] - 0s 163us/step - loss: 0.0010 - val_loss: 0.0017\n",
      "Epoch 1895/2000\n",
      "45/45 [==============================] - 0s 137us/step - loss: 0.0010 - val_loss: 0.0016\n",
      "Epoch 1896/2000\n",
      "45/45 [==============================] - 0s 160us/step - loss: 0.0010 - val_loss: 0.0017\n",
      "Epoch 1897/2000\n",
      "45/45 [==============================] - 0s 150us/step - loss: 0.0010 - val_loss: 0.0017\n",
      "Epoch 1898/2000\n",
      "45/45 [==============================] - 0s 159us/step - loss: 0.0010 - val_loss: 0.0017\n",
      "Epoch 1899/2000\n",
      "45/45 [==============================] - 0s 161us/step - loss: 0.0010 - val_loss: 0.0017\n",
      "Epoch 1900/2000\n",
      "45/45 [==============================] - 0s 154us/step - loss: 0.0010 - val_loss: 0.0017\n",
      "Epoch 1901/2000\n",
      "45/45 [==============================] - 0s 164us/step - loss: 0.0010 - val_loss: 0.0017\n",
      "Epoch 1902/2000\n",
      "45/45 [==============================] - 0s 158us/step - loss: 0.0010 - val_loss: 0.0016\n",
      "Epoch 1903/2000\n",
      "45/45 [==============================] - 0s 170us/step - loss: 0.0010 - val_loss: 0.0016\n",
      "Epoch 1904/2000\n",
      "45/45 [==============================] - 0s 152us/step - loss: 0.0010 - val_loss: 0.0017\n",
      "Epoch 1905/2000\n",
      "45/45 [==============================] - 0s 183us/step - loss: 0.0010 - val_loss: 0.0017\n",
      "Epoch 1906/2000\n",
      "45/45 [==============================] - 0s 161us/step - loss: 0.0010 - val_loss: 0.0017\n",
      "Epoch 1907/2000\n",
      "45/45 [==============================] - 0s 173us/step - loss: 0.0010 - val_loss: 0.0017\n",
      "Epoch 1908/2000\n",
      "45/45 [==============================] - 0s 157us/step - loss: 0.0010 - val_loss: 0.0016\n",
      "Epoch 1909/2000\n",
      "45/45 [==============================] - 0s 176us/step - loss: 0.0010 - val_loss: 0.0017\n",
      "Epoch 1910/2000\n",
      "45/45 [==============================] - 0s 140us/step - loss: 0.0010 - val_loss: 0.0017\n",
      "Epoch 1911/2000\n",
      "45/45 [==============================] - 0s 174us/step - loss: 9.9989e-04 - val_loss: 0.0016\n",
      "Epoch 1912/2000\n",
      "45/45 [==============================] - 0s 159us/step - loss: 9.9982e-04 - val_loss: 0.0016\n",
      "Epoch 1913/2000\n",
      "45/45 [==============================] - 0s 183us/step - loss: 9.9288e-04 - val_loss: 0.0016\n",
      "Epoch 1914/2000\n",
      "45/45 [==============================] - 0s 157us/step - loss: 9.9847e-04 - val_loss: 0.0016\n",
      "Epoch 1915/2000\n",
      "45/45 [==============================] - 0s 172us/step - loss: 0.0010 - val_loss: 0.0016\n",
      "Epoch 1916/2000\n",
      "45/45 [==============================] - 0s 150us/step - loss: 9.8911e-04 - val_loss: 0.0016\n",
      "Epoch 1917/2000\n",
      "45/45 [==============================] - 0s 172us/step - loss: 9.9128e-04 - val_loss: 0.0016\n",
      "Epoch 1918/2000\n",
      "45/45 [==============================] - 0s 153us/step - loss: 9.8581e-04 - val_loss: 0.0016\n",
      "Epoch 1919/2000\n",
      "45/45 [==============================] - 0s 171us/step - loss: 9.8778e-04 - val_loss: 0.0016\n",
      "Epoch 1920/2000\n",
      "45/45 [==============================] - 0s 161us/step - loss: 9.7901e-04 - val_loss: 0.0016\n",
      "Epoch 1921/2000\n",
      "45/45 [==============================] - 0s 165us/step - loss: 0.0010 - val_loss: 0.0016\n",
      "Epoch 1922/2000\n",
      "45/45 [==============================] - 0s 159us/step - loss: 0.0010 - val_loss: 0.0017\n",
      "Epoch 1923/2000\n",
      "45/45 [==============================] - 0s 161us/step - loss: 9.8989e-04 - val_loss: 0.0016\n",
      "Epoch 1924/2000\n",
      "45/45 [==============================] - 0s 170us/step - loss: 9.9372e-04 - val_loss: 0.0016\n",
      "Epoch 1925/2000\n",
      "45/45 [==============================] - 0s 175us/step - loss: 9.7204e-04 - val_loss: 0.0016\n",
      "Epoch 1926/2000\n",
      "45/45 [==============================] - 0s 161us/step - loss: 9.8624e-04 - val_loss: 0.0016\n",
      "Epoch 1927/2000\n",
      "45/45 [==============================] - 0s 161us/step - loss: 9.7605e-04 - val_loss: 0.0016\n",
      "Epoch 1928/2000\n",
      "45/45 [==============================] - 0s 172us/step - loss: 9.8774e-04 - val_loss: 0.0016\n",
      "Epoch 1929/2000\n",
      "45/45 [==============================] - 0s 172us/step - loss: 9.8513e-04 - val_loss: 0.0016\n",
      "Epoch 1930/2000\n",
      "45/45 [==============================] - 0s 168us/step - loss: 9.7859e-04 - val_loss: 0.0017\n",
      "Epoch 1931/2000\n",
      "45/45 [==============================] - 0s 158us/step - loss: 9.7409e-04 - val_loss: 0.0017\n",
      "Epoch 1932/2000\n",
      "45/45 [==============================] - 0s 163us/step - loss: 9.7839e-04 - val_loss: 0.0016\n",
      "Epoch 1933/2000\n",
      "45/45 [==============================] - 0s 155us/step - loss: 9.7602e-04 - val_loss: 0.0017\n",
      "Epoch 1934/2000\n",
      "45/45 [==============================] - 0s 177us/step - loss: 9.8909e-04 - val_loss: 0.0017\n",
      "Epoch 1935/2000\n",
      "45/45 [==============================] - 0s 151us/step - loss: 9.7561e-04 - val_loss: 0.0017\n",
      "Epoch 1936/2000\n",
      "45/45 [==============================] - 0s 172us/step - loss: 9.8324e-04 - val_loss: 0.0017\n",
      "Epoch 1937/2000\n",
      "45/45 [==============================] - 0s 155us/step - loss: 9.8207e-04 - val_loss: 0.0017\n",
      "Epoch 1938/2000\n",
      "45/45 [==============================] - 0s 178us/step - loss: 9.7591e-04 - val_loss: 0.0017\n",
      "Epoch 1939/2000\n",
      "45/45 [==============================] - 0s 153us/step - loss: 9.9586e-04 - val_loss: 0.0016\n",
      "Epoch 1940/2000\n",
      "45/45 [==============================] - 0s 171us/step - loss: 9.6211e-04 - val_loss: 0.0016\n",
      "Epoch 1941/2000\n",
      "45/45 [==============================] - 0s 146us/step - loss: 9.6100e-04 - val_loss: 0.0016\n",
      "Epoch 1942/2000\n",
      "45/45 [==============================] - 0s 172us/step - loss: 9.8680e-04 - val_loss: 0.0016\n",
      "Epoch 1943/2000\n",
      "45/45 [==============================] - 0s 147us/step - loss: 9.5428e-04 - val_loss: 0.0016\n",
      "Epoch 1944/2000\n",
      "45/45 [==============================] - 0s 154us/step - loss: 9.6972e-04 - val_loss: 0.0016\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1945/2000\n",
      "45/45 [==============================] - 0s 162us/step - loss: 9.5612e-04 - val_loss: 0.0015\n",
      "Epoch 1946/2000\n",
      "45/45 [==============================] - 0s 170us/step - loss: 9.5692e-04 - val_loss: 0.0016\n",
      "Epoch 1947/2000\n",
      "45/45 [==============================] - 0s 171us/step - loss: 9.5119e-04 - val_loss: 0.0016\n",
      "Epoch 1948/2000\n",
      "45/45 [==============================] - 0s 192us/step - loss: 9.5430e-04 - val_loss: 0.0016\n",
      "Epoch 1949/2000\n",
      "45/45 [==============================] - 0s 154us/step - loss: 9.7763e-04 - val_loss: 0.0015\n",
      "Epoch 1950/2000\n",
      "45/45 [==============================] - 0s 176us/step - loss: 9.6344e-04 - val_loss: 0.0016\n",
      "Epoch 1951/2000\n",
      "45/45 [==============================] - 0s 154us/step - loss: 9.4521e-04 - val_loss: 0.0016\n",
      "Epoch 1952/2000\n",
      "45/45 [==============================] - 0s 172us/step - loss: 9.6235e-04 - val_loss: 0.0016\n",
      "Epoch 1953/2000\n",
      "45/45 [==============================] - 0s 150us/step - loss: 9.5291e-04 - val_loss: 0.0016\n",
      "Epoch 1954/2000\n",
      "45/45 [==============================] - 0s 161us/step - loss: 9.4742e-04 - val_loss: 0.0016\n",
      "Epoch 1955/2000\n",
      "45/45 [==============================] - 0s 162us/step - loss: 9.4043e-04 - val_loss: 0.0016\n",
      "Epoch 1956/2000\n",
      "45/45 [==============================] - 0s 167us/step - loss: 9.4152e-04 - val_loss: 0.0016\n",
      "Epoch 1957/2000\n",
      "45/45 [==============================] - 0s 174us/step - loss: 9.3853e-04 - val_loss: 0.0016\n",
      "Epoch 1958/2000\n",
      "45/45 [==============================] - 0s 173us/step - loss: 9.3822e-04 - val_loss: 0.0016\n",
      "Epoch 1959/2000\n",
      "45/45 [==============================] - 0s 167us/step - loss: 9.3453e-04 - val_loss: 0.0016\n",
      "Epoch 1960/2000\n",
      "45/45 [==============================] - 0s 167us/step - loss: 9.4423e-04 - val_loss: 0.0016\n",
      "Epoch 1961/2000\n",
      "45/45 [==============================] - 0s 168us/step - loss: 9.4384e-04 - val_loss: 0.0016\n",
      "Epoch 1962/2000\n",
      "45/45 [==============================] - 0s 166us/step - loss: 9.3277e-04 - val_loss: 0.0016\n",
      "Epoch 1963/2000\n",
      "45/45 [==============================] - 0s 168us/step - loss: 9.3599e-04 - val_loss: 0.0015\n",
      "Epoch 1964/2000\n",
      "45/45 [==============================] - 0s 161us/step - loss: 9.5575e-04 - val_loss: 0.0016\n",
      "Epoch 1965/2000\n",
      "45/45 [==============================] - 0s 165us/step - loss: 9.3888e-04 - val_loss: 0.0016\n",
      "Epoch 1966/2000\n",
      "45/45 [==============================] - 0s 153us/step - loss: 9.4542e-04 - val_loss: 0.0016\n",
      "Epoch 1967/2000\n",
      "45/45 [==============================] - 0s 174us/step - loss: 9.3151e-04 - val_loss: 0.0016\n",
      "Epoch 1968/2000\n",
      "45/45 [==============================] - 0s 161us/step - loss: 9.4310e-04 - val_loss: 0.0016\n",
      "Epoch 1969/2000\n",
      "45/45 [==============================] - 0s 178us/step - loss: 9.4361e-04 - val_loss: 0.0016\n",
      "Epoch 1970/2000\n",
      "45/45 [==============================] - 0s 161us/step - loss: 9.3541e-04 - val_loss: 0.0016\n",
      "Epoch 1971/2000\n",
      "45/45 [==============================] - 0s 171us/step - loss: 9.3110e-04 - val_loss: 0.0016\n",
      "Epoch 1972/2000\n",
      "45/45 [==============================] - 0s 169us/step - loss: 9.2251e-04 - val_loss: 0.0016\n",
      "Epoch 1973/2000\n",
      "45/45 [==============================] - 0s 182us/step - loss: 9.2206e-04 - val_loss: 0.0016\n",
      "Epoch 1974/2000\n",
      "45/45 [==============================] - 0s 156us/step - loss: 9.1937e-04 - val_loss: 0.0016\n",
      "Epoch 1975/2000\n",
      "45/45 [==============================] - 0s 170us/step - loss: 9.2909e-04 - val_loss: 0.0015\n",
      "Epoch 1976/2000\n",
      "45/45 [==============================] - 0s 150us/step - loss: 9.1945e-04 - val_loss: 0.0016\n",
      "Epoch 1977/2000\n",
      "45/45 [==============================] - 0s 170us/step - loss: 9.2181e-04 - val_loss: 0.0016\n",
      "Epoch 1978/2000\n",
      "45/45 [==============================] - 0s 147us/step - loss: 9.1550e-04 - val_loss: 0.0016\n",
      "Epoch 1979/2000\n",
      "45/45 [==============================] - 0s 175us/step - loss: 9.2197e-04 - val_loss: 0.0016\n",
      "Epoch 1980/2000\n",
      "45/45 [==============================] - 0s 148us/step - loss: 9.1278e-04 - val_loss: 0.0016\n",
      "Epoch 1981/2000\n",
      "45/45 [==============================] - 0s 175us/step - loss: 9.2274e-04 - val_loss: 0.0016\n",
      "Epoch 1982/2000\n",
      "45/45 [==============================] - 0s 160us/step - loss: 9.2616e-04 - val_loss: 0.0016\n",
      "Epoch 1983/2000\n",
      "45/45 [==============================] - 0s 169us/step - loss: 9.0934e-04 - val_loss: 0.0016\n",
      "Epoch 1984/2000\n",
      "45/45 [==============================] - 0s 152us/step - loss: 9.1440e-04 - val_loss: 0.0016\n",
      "Epoch 1985/2000\n",
      "45/45 [==============================] - 0s 164us/step - loss: 9.0934e-04 - val_loss: 0.0016\n",
      "Epoch 1986/2000\n",
      "45/45 [==============================] - 0s 164us/step - loss: 9.2869e-04 - val_loss: 0.0016\n",
      "Epoch 1987/2000\n",
      "45/45 [==============================] - 0s 176us/step - loss: 9.0394e-04 - val_loss: 0.0016\n",
      "Epoch 1988/2000\n",
      "45/45 [==============================] - 0s 162us/step - loss: 9.2502e-04 - val_loss: 0.0016\n",
      "Epoch 1989/2000\n",
      "45/45 [==============================] - 0s 149us/step - loss: 9.1246e-04 - val_loss: 0.0016\n",
      "Epoch 1990/2000\n",
      "45/45 [==============================] - 0s 171us/step - loss: 9.1136e-04 - val_loss: 0.0016\n",
      "Epoch 1991/2000\n",
      "45/45 [==============================] - 0s 154us/step - loss: 9.0228e-04 - val_loss: 0.0016\n",
      "Epoch 1992/2000\n",
      "45/45 [==============================] - 0s 174us/step - loss: 9.0526e-04 - val_loss: 0.0016\n",
      "Epoch 1993/2000\n",
      "45/45 [==============================] - 0s 161us/step - loss: 9.0257e-04 - val_loss: 0.0016\n",
      "Epoch 1994/2000\n",
      "45/45 [==============================] - 0s 166us/step - loss: 9.0437e-04 - val_loss: 0.0016\n",
      "Epoch 1995/2000\n",
      "45/45 [==============================] - 0s 155us/step - loss: 9.0929e-04 - val_loss: 0.0016\n",
      "Epoch 1996/2000\n",
      "45/45 [==============================] - 0s 174us/step - loss: 9.0752e-04 - val_loss: 0.0016\n",
      "Epoch 1997/2000\n",
      "45/45 [==============================] - 0s 152us/step - loss: 9.1383e-04 - val_loss: 0.0016\n",
      "Epoch 1998/2000\n",
      "45/45 [==============================] - 0s 193us/step - loss: 8.9732e-04 - val_loss: 0.0016\n",
      "Epoch 1999/2000\n",
      "45/45 [==============================] - 0s 166us/step - loss: 9.0052e-04 - val_loss: 0.0016\n",
      "Epoch 2000/2000\n",
      "45/45 [==============================] - 0s 182us/step - loss: 8.9897e-04 - val_loss: 0.0016\n"
     ]
    }
   ],
   "source": [
    "history = model.fit(x, t, batch_size=batch_size, epochs=2000, validation_split=0.1)  # Use 10 % of data as testing. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "loss = history.history['loss']  # training error\n",
    "vloss = history.history['val_loss']  # test error\n",
    "\n",
    "plt.plot(np.arange(len(loss)), loss, label='training')\n",
    "plt.plot(np.arange(len(vloss)), vloss, label='test')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(x, model.predict(x), label='predicted')  \n",
    "plt.plot(x, t, label='true value')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
